{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef5f067",
   "metadata": {
    "papermill": {
     "duration": 0.039994,
     "end_time": "2023-12-22T12:28:58.952711",
     "exception": false,
     "start_time": "2023-12-22T12:28:58.912717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First of all, we import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2c6132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:28:59.033308Z",
     "iopub.status.busy": "2023-12-22T12:28:59.032901Z",
     "iopub.status.idle": "2023-12-22T12:30:18.069098Z",
     "shell.execute_reply": "2023-12-22T12:30:18.068018Z"
    },
    "papermill": {
     "duration": 79.080418,
     "end_time": "2023-12-22T12:30:18.073108",
     "exception": false,
     "start_time": "2023-12-22T12:28:58.992690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting greek-stemmer-pos\r\n",
      "  Downloading greek_stemmer_pos-1.1.2-py3-none-any.whl (19 kB)\r\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from greek-stemmer-pos) (7.4.3)\r\n",
      "Collecting pytest-cov (from greek-stemmer-pos)\r\n",
      "  Obtaining dependency information for pytest-cov from https://files.pythonhosted.org/packages/a7/4b/8b78d126e275efa2379b1c2e09dc52cf70df16fc3b90613ef82531499d73/pytest_cov-4.1.0-py3-none-any.whl.metadata\r\n",
      "  Downloading pytest_cov-4.1.0-py3-none-any.whl.metadata (26 kB)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (2.0.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (21.3)\r\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (1.2.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (1.1.3)\r\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest->greek-stemmer-pos) (2.0.1)\r\n",
      "Collecting coverage[toml]>=5.2.1 (from pytest-cov->greek-stemmer-pos)\r\n",
      "  Obtaining dependency information for coverage[toml]>=5.2.1 from https://files.pythonhosted.org/packages/94/1b/bd597a07755b233822760c9998d603218ca4b3151b6d5048e9fd0a5bf572/coverage-7.3.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading coverage-7.3.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->pytest->greek-stemmer-pos) (3.0.9)\r\n",
      "Downloading pytest_cov-4.1.0-py3-none-any.whl (21 kB)\r\n",
      "Downloading coverage-7.3.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.4/228.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: coverage, pytest-cov, greek-stemmer-pos\r\n",
      "Successfully installed coverage-7.3.4 greek-stemmer-pos-1.1.2 pytest-cov-4.1.0\r\n",
      "Requirement already satisfied: smart_open in /opt/conda/lib/python3.10/site-packages (6.3.0)\r\n",
      "Collecting smart_open\r\n",
      "  Obtaining dependency information for smart_open from https://files.pythonhosted.org/packages/fc/d9/d97f1db64b09278aba64e8c81b5d322d436132df5741c518f3823824fae0/smart_open-6.4.0-py3-none-any.whl.metadata\r\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\r\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.2)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\r\n",
      "Collecting nltk\r\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.24.3)\r\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.11.3)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.3.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.8.8)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.1)\r\n",
      "Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: smart_open, nltk\r\n",
      "  Attempting uninstall: smart_open\r\n",
      "    Found existing installation: smart-open 6.3.0\r\n",
      "    Uninstalling smart-open-6.3.0:\r\n",
      "      Successfully uninstalled smart-open-6.3.0\r\n",
      "  Attempting uninstall: nltk\r\n",
      "    Found existing installation: nltk 3.2.4\r\n",
      "    Uninstalling nltk-3.2.4:\r\n",
      "      Successfully uninstalled nltk-3.2.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nltk-3.8.1 smart_open-6.4.0\r\n",
      "Requirement already satisfied: preprocessing in /opt/conda/lib/python3.10/site-packages (0.1.13)\r\n",
      "Collecting nltk==3.2.4 (from preprocessing)\r\n",
      "  Downloading nltk-3.2.4.tar.gz (1.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: sphinx-rtd-theme==0.2.4 in /opt/conda/lib/python3.10/site-packages (from preprocessing) (0.2.4)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk==3.2.4->preprocessing) (1.16.0)\r\n",
      "Building wheels for collected packages: nltk\r\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.2.4-py3-none-any.whl size=1367708 sha256=9674d3f8c8c335b90aedf9d48ea4c8c6e11a9bb04bff4580bb234be4abc6bdc5\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0e/8c/42/bcd0934b61ecf4cef964ccc9881888cca0841ec72266e99de1\r\n",
      "Successfully built nltk\r\n",
      "Installing collected packages: nltk\r\n",
      "  Attempting uninstall: nltk\r\n",
      "    Found existing installation: nltk 3.8.1\r\n",
      "    Uninstalling nltk-3.8.1:\r\n",
      "      Successfully uninstalled nltk-3.8.1\r\n",
      "Successfully installed nltk-3.2.4\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0+cpu)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.24.3)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.2)\r\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.24.3)\r\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.11.3)\r\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (6.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install greek-stemmer-pos\n",
    "!pip install --upgrade smart_open gensim nltk\n",
    "!pip install --upgrade preprocessing\n",
    "!pip install torch numpy\n",
    "!pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4b8b74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:30:18.218974Z",
     "iopub.status.busy": "2023-12-22T12:30:18.218526Z",
     "iopub.status.idle": "2023-12-22T12:30:31.978759Z",
     "shell.execute_reply": "2023-12-22T12:30:31.977707Z"
    },
    "papermill": {
     "duration": 13.86618,
     "end_time": "2023-12-22T12:30:31.982155",
     "exception": false,
     "start_time": "2023-12-22T12:30:18.115975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.24.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e066194b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:30:32.079735Z",
     "iopub.status.busy": "2023-12-22T12:30:32.079311Z",
     "iopub.status.idle": "2023-12-22T12:31:20.750041Z",
     "shell.execute_reply": "2023-12-22T12:31:20.749039Z"
    },
    "papermill": {
     "duration": 48.719627,
     "end_time": "2023-12-22T12:31:20.752851",
     "exception": false,
     "start_time": "2023-12-22T12:30:32.033224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (1.26.15)\r\n",
      "Requirement already satisfied: Jinja2 in /opt/conda/lib/python3.10/site-packages (3.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2) (2.1.3)\r\n",
      "Collecting numpy==1.23.0\r\n",
      "  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: numpy\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.24.3\r\n",
      "    Uninstalling numpy-1.24.3:\r\n",
      "      Successfully uninstalled numpy-1.24.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.1 which is incompatible.\r\n",
      "chex 0.1.84 requires numpy>=1.24.1, but you have numpy 1.23.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.0 which is incompatible.\r\n",
      "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\r\n",
      "tensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed numpy-1.23.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install urllib3\n",
    "!pip install -U Jinja2\n",
    "!pip install numpy==1.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece98b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:31:20.844658Z",
     "iopub.status.busy": "2023-12-22T12:31:20.844194Z",
     "iopub.status.idle": "2023-12-22T12:31:22.130086Z",
     "shell.execute_reply": "2023-12-22T12:31:22.129090Z"
    },
    "papermill": {
     "duration": 1.335435,
     "end_time": "2023-12-22T12:31:22.132744",
     "exception": false,
     "start_time": "2023-12-22T12:31:20.797309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = \"/kaggle/input/ys19-2023-assignment-2/train_set.csv\"\n",
    "valid_path = \"/kaggle/input/ys19-2023-assignment-2/valid_set.csv\"\n",
    "\n",
    "# Read the CSV files\n",
    "data = pd.read_csv(file_path)\n",
    "valid = pd.read_csv(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd308c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:31:22.223888Z",
     "iopub.status.busy": "2023-12-22T12:31:22.223479Z",
     "iopub.status.idle": "2023-12-22T12:31:22.309485Z",
     "shell.execute_reply": "2023-12-22T12:31:22.308295Z"
    },
    "papermill": {
     "duration": 0.134735,
     "end_time": "2023-12-22T12:31:22.312087",
     "exception": false,
     "start_time": "2023-12-22T12:31:22.177352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment  hashtag_count\n",
      "0  NEGATIVE          10962\n",
      "1   NEUTRAL          12102\n",
      "2  POSITIVE          11319\n"
     ]
    }
   ],
   "source": [
    "data['hashtag_count'] = data['Text'].str.count('#')\n",
    "result = data.groupby('Sentiment')['hashtag_count'].sum().reset_index()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4543ca6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:31:22.403169Z",
     "iopub.status.busy": "2023-12-22T12:31:22.402749Z",
     "iopub.status.idle": "2023-12-22T12:31:22.475405Z",
     "shell.execute_reply": "2023-12-22T12:31:22.474383Z"
    },
    "papermill": {
     "duration": 0.1211,
     "end_time": "2023-12-22T12:31:22.477887",
     "exception": false,
     "start_time": "2023-12-22T12:31:22.356787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sentiment  hashtag_count\n",
      "0  NEGATIVE           6535\n",
      "1   NEUTRAL           5577\n",
      "2  POSITIVE           5760\n"
     ]
    }
   ],
   "source": [
    "data['hashtag_count'] = data['Text'].str.count('@')\n",
    "result = data.groupby('Sentiment')['hashtag_count'].sum().reset_index()\n",
    "print(result)\n",
    "data = data.drop('hashtag_count',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0ca48",
   "metadata": {
    "papermill": {
     "duration": 0.045663,
     "end_time": "2023-12-22T12:31:22.568970",
     "exception": false,
     "start_time": "2023-12-22T12:31:22.523307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First we will do all the preprocessing that we did in the first assginement, but this time we wont remove special characters, I think the results might be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b849b05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:31:22.661663Z",
     "iopub.status.busy": "2023-12-22T12:31:22.661103Z",
     "iopub.status.idle": "2023-12-22T12:31:45.767795Z",
     "shell.execute_reply": "2023-12-22T12:31:45.766681Z"
    },
    "papermill": {
     "duration": 23.156549,
     "end_time": "2023-12-22T12:31:45.770757",
     "exception": false,
     "start_time": "2023-12-22T12:31:22.614208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   New_ID                                               Text Sentiment   Party\n",
      "0   35027  #απολυμανση_κοριοι #απεντομωση_κοριοσ #απολυμα...   NEUTRAL  SYRIZA\n",
      "1    9531  εξι νε επιστολ τ μακεδονι «καινε» τ νδ - μητσο...  NEGATIVE      ND\n",
      "2   14146      ισχυρ κκε, δυναμ λα στ βουλ στ καθημεριν αγων  POSITIVE     KKE\n",
      "3   28716  @five2nds @anthi7vas μνημονιακοτατ #μερα25 #εκ...   NEUTRAL     KKE\n",
      "4   32886  @ai_katerina αυτ εινα συγκλονιστικ εινα ψυχασθ...   NEUTRAL  SYRIZA\n",
      "5   12112  @tou_diaolou εχ δικιο, αντι να παιζ εαμ ελλασ,...  NEGATIVE  SYRIZA\n",
      "6   13115                             προκλητικ ολ τσιπρ σκα  POSITIVE  SYRIZA\n",
      "7   21431  @ksyrizohunter θ π \"αλλιωσ\"; μητσοτακ δηλως \"ε...  POSITIVE      ND\n",
      "8   12593  ραπισμ αντετοκουμπ υποκρισι μητσοτακη: εξι χρο...  POSITIVE      ND\n",
      "9   19725  @nikospappas16 @atsipras @kmitsotakis ξερ τους...  POSITIVE      ND\n",
      "   New_ID                                               Text Sentiment  \\\n",
      "0     435  @glinard @teza_tereza @adonisgeorgiadi @atsipr...  POSITIVE   \n",
      "1    3061  τσιπρασ: ζητησαμ απο αντιπολιτευς να συμμετεχ ...  NEGATIVE   \n",
      "2    2161  σωστ ελληνασ, δημοκρατησ, ελλην εξωτερικ ερχετ...  NEGATIVE   \n",
      "3    1271  @30__kai ναι βλεπ αυτ ενδιαφερ τους μητσοτακηδ...  POSITIVE   \n",
      "4    4396  συνεντευξ μητσοτακ alpha: υπο αιρες 13η συνταξ...   NEUTRAL   \n",
      "5    1102  εκλογικ περιπτερ συριζα - προοδευτικ συμμαχι σ...  POSITIVE   \n",
      "6    1567  επιτακτικ αναγκ τ κυβερνης κ. μητσοτακ καθαρς ...  POSITIVE   \n",
      "7    4093  times λονδιν τσιπρα: πως απο λαικιστ σωτηρ εγι...   NEUTRAL   \n",
      "8    3026  @dimi_zaharakis @sspithess παντ να ξερ συστημ ...  NEGATIVE   \n",
      "9    2473  @manosvoularinos εμετικο!!! στ νδ να βλεπ καλ ...  NEGATIVE   \n",
      "\n",
      "      Party  \n",
      "0    SYRIZA  \n",
      "1    SYRIZA  \n",
      "2        ND  \n",
      "3        ND  \n",
      "4        ND  \n",
      "5    SYRIZA  \n",
      "6  ELL_LYSI  \n",
      "7    SYRIZA  \n",
      "8        ND  \n",
      "9        ND  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "data['Text'] = data['Text'].apply(lambda x: x.lower())\n",
    "valid['Text'] = valid['Text'].apply(lambda x: x.lower())\n",
    "greek_stopwords = [\n",
    "    'και', 'το', 'η', 'της', 'του', 'τα', 'σε', 'με', 'για', 'ειναι',\n",
    "    'στο', 'απο', 'που', 'οι', 'την', 'ενα', 'μετα', 'εχει', 'δεν',\n",
    "    'ειναι', 'μια', 'αυτο', 'εναν', 'αλλα', 'ο', 'μη', 'οτι', 'πως',\n",
    "    'απο', 'στην', 'στον', 'τι', 'αυτη', 'των', 'αυτα', 'οταν', 'πολυ',\n",
    "    'μας', 'ειναι', 'πριν', 'οτι', 'μονο', 'αυτος', 'τοτε', 'μεταξυ',\n",
    "    'πολλα', 'οποτε', 'παρα', 'εαν', 'γυρω', 'αυτην', 'εκεινος', 'περισσοτερο',\n",
    "    'προς', 'πολυ', 'τελικα', 'ολοι'\n",
    "]\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()  # Split the text into words\n",
    "    words = [word for word in words if word.lower() not in greek_stopwords]\n",
    "    return ' '.join(words)\n",
    "valid['Text'] = valid['Text'].apply(remove_stopwords)\n",
    "data['Text'] = data['Text'].apply(remove_stopwords)\n",
    "url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "def remove_urls(text):\n",
    "    return re.sub(url_pattern, '', text)\n",
    "valid['Text'] = valid['Text'].apply(remove_urls)\n",
    "data['Text'] = data['Text'].apply(remove_urls)\n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub('ό', 'ο', x))  \n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub('έ', 'ε', x))  \n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub('ί', 'ι', x))  \n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub('ή', 'η', x))  \n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub('ύ', 'υ', x))  \n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub('ώ', 'ω', x))  \n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub('ά', 'α', x))  \n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub('ς', 'σ', x))  \n",
    "\n",
    "valid['Text'] = valid['Text'].apply(lambda x: re.sub('ό', 'ο', x))  \n",
    "valid['Text'] = valid['Text'].apply(lambda x: re.sub('έ', 'ε', x))  \n",
    "valid['Text'] = valid['Text'].apply(lambda x: re.sub('ί', 'ι', x))  \n",
    "valid['Text'] = valid['Text'].apply(lambda x: re.sub('ή', 'η', x))  \n",
    "valid['Text'] = valid['Text'].apply(lambda x: re.sub('ύ', 'υ', x))  \n",
    "valid['Text'] = valid['Text'].apply(lambda x: re.sub('ώ', 'ω', x))  \n",
    "valid['Text'] = valid['Text'].apply(lambda x: re.sub('ά', 'α', x))  \n",
    "valid['Text'] = valid['Text'].apply(lambda x: re.sub('ς', 'σ', x))\n",
    "\n",
    "from greek_stemmer import stemmer\n",
    "\n",
    "# Define a function to perform stemming on the tweets\n",
    "def stem_greek_text(text):\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem_word(word,\"NNN\") for word in words]\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "    return stemmed_text\n",
    "\n",
    "\n",
    "# Apply the stem_greek_text function to the 'tweets' column\n",
    "data['Text'] = data['Text'].apply(stem_greek_text)\n",
    "valid['Text'] = valid['Text'].apply(stem_greek_text)\n",
    "data['Text'] = data['Text'].apply(lambda x: x.lower())\n",
    "valid['Text'] = valid['Text'].apply(lambda x: x.lower())\n",
    "print(data.head(10))\n",
    "print(valid.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf6a14",
   "metadata": {
    "papermill": {
     "duration": 0.045082,
     "end_time": "2023-12-22T12:31:45.861237",
     "exception": false,
     "start_time": "2023-12-22T12:31:45.816155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This was the preproccesing we did for the first assginemnt, in this assignment we will also replace ς with σ, and replace special chracters with the special character and a blank space, so it can be tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "340b611c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:31:45.953982Z",
     "iopub.status.busy": "2023-12-22T12:31:45.953598Z",
     "iopub.status.idle": "2023-12-22T12:31:46.438492Z",
     "shell.execute_reply": "2023-12-22T12:31:46.437343Z"
    },
    "papermill": {
     "duration": 0.534874,
     "end_time": "2023-12-22T12:31:46.441354",
     "exception": false,
     "start_time": "2023-12-22T12:31:45.906480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   New_ID                                               Text Sentiment   Party\n",
      "0   35027   # απολυμανση _ κοριοι  # απεντομωση _ κοριοσ ...   NEUTRAL  SYRIZA\n",
      "1    9531  εξι νε επιστολ τ μακεδονι  « καινε »  τ νδ  - ...  NEGATIVE      ND\n",
      "2   14146    ισχυρ κκε ,  δυναμ λα στ βουλ στ καθημεριν αγων  POSITIVE     KKE\n",
      "3   28716   @ five2nds  @ anthi7vas μνημονιακοτατ  # μερα...   NEUTRAL     KKE\n",
      "4   32886   @ ai _ katerina αυτ εινα συγκλονιστικ εινα ψυ...   NEUTRAL  SYRIZA\n",
      "5   12112   @ tou _ diaolou εχ δικιο ,  αντι να παιζ εαμ ...  NEGATIVE  SYRIZA\n",
      "6   13115                             προκλητικ ολ τσιπρ σκα  POSITIVE  SYRIZA\n",
      "7   21431   @ ksyrizohunter θ π  \" αλλιωσ \"  ;  μητσοτακ ...  POSITIVE      ND\n",
      "8   12593  ραπισμ αντετοκουμπ υποκρισι μητσοτακη :  εξι χ...  POSITIVE      ND\n",
      "9   19725   @ nikospappas16  @ atsipras  @ kmitsotakis ξε...  POSITIVE      ND\n",
      "   New_ID                                               Text Sentiment  \\\n",
      "0     435   @ glinard  @ teza _ tereza  @ adonisgeorgiadi...  POSITIVE   \n",
      "1    3061  τσιπρασ :  ζητησαμ απο αντιπολιτευσ να συμμετε...  NEGATIVE   \n",
      "2    2161  σωστ ελληνασ ,  δημοκρατησ ,  ελλην εξωτερικ ε...  NEGATIVE   \n",
      "3    1271   @ 30 _  _ kai ναι βλεπ αυτ ενδιαφερ τουσ μητσ...  POSITIVE   \n",
      "4    4396  συνεντευξ μητσοτακ alpha :  υπο αιρεσ 13η συντ...   NEUTRAL   \n",
      "5    1102  εκλογικ περιπτερ συριζα  -  προοδευτικ συμμαχι...  POSITIVE   \n",
      "6    1567  επιτακτικ αναγκ τ κυβερνησ κ .  μητσοτακ καθαρ...  POSITIVE   \n",
      "7    4093  times λονδιν τσιπρα :  πωσ απο λαικιστ σωτηρ ε...   NEUTRAL   \n",
      "8    3026   @ dimi _ zaharakis  @ sspithess παντ να ξερ σ...  NEGATIVE   \n",
      "9    2473   @ manosvoularinos εμετικο !  !  !  στ νδ να β...  NEGATIVE   \n",
      "\n",
      "      Party  \n",
      "0    SYRIZA  \n",
      "1    SYRIZA  \n",
      "2        ND  \n",
      "3        ND  \n",
      "4        ND  \n",
      "5    SYRIZA  \n",
      "6  ELL_LYSI  \n",
      "7    SYRIZA  \n",
      "8        ND  \n",
      "9        ND  \n"
     ]
    }
   ],
   "source": [
    "data['Text'] = data['Text'].str.replace('ς', 'σ')\n",
    "valid['Text'] = valid['Text'].str.replace('ς', 'σ')\n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub(r'[^A-Za-zΑ-Ωα-ω0-9 ]', lambda y: ' ' + y.group(0) + ' ', x))\n",
    "valid['Text'] = valid['Text'].apply(lambda x: re.sub(r'[^A-Za-zΑ-Ωα-ω0-9 ]', lambda y: ' ' + y.group(0) + ' ', x))\n",
    "print(data.head(10))\n",
    "print(valid.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499fe3c3",
   "metadata": {
    "papermill": {
     "duration": 0.045283,
     "end_time": "2023-12-22T12:31:46.532541",
     "exception": false,
     "start_time": "2023-12-22T12:31:46.487258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After that it owuld be better to remove spaces that are not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd726399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:31:46.625394Z",
     "iopub.status.busy": "2023-12-22T12:31:46.625020Z",
     "iopub.status.idle": "2023-12-22T12:31:47.753995Z",
     "shell.execute_reply": "2023-12-22T12:31:47.753238Z"
    },
    "papermill": {
     "duration": 1.178792,
     "end_time": "2023-12-22T12:31:47.756789",
     "exception": false,
     "start_time": "2023-12-22T12:31:46.577997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   New_ID                                               Text Sentiment   Party\n",
      "0   35027   # απολυμανση _ κοριοι # απεντομωση _ κοριοσ #...   NEUTRAL  SYRIZA\n",
      "1    9531  εξι νε επιστολ τ μακεδονι « καινε » τ νδ - μητ...  NEGATIVE      ND\n",
      "2   14146     ισχυρ κκε , δυναμ λα στ βουλ στ καθημεριν αγων  POSITIVE     KKE\n",
      "3   28716   @ five2nds @ anthi7vas μνημονιακοτατ # μερα25...   NEUTRAL     KKE\n",
      "4   32886   @ ai _ katerina αυτ εινα συγκλονιστικ εινα ψυ...   NEUTRAL  SYRIZA\n",
      "5   12112   @ tou _ diaolou εχ δικιο , αντι να παιζ εαμ ε...  NEGATIVE  SYRIZA\n",
      "6   13115                             προκλητικ ολ τσιπρ σκα  POSITIVE  SYRIZA\n",
      "7   21431   @ ksyrizohunter θ π \" αλλιωσ \" ; μητσοτακ δηλ...  POSITIVE      ND\n",
      "8   12593  ραπισμ αντετοκουμπ υποκρισι μητσοτακη : εξι χρ...  POSITIVE      ND\n",
      "9   19725   @ nikospappas16 @ atsipras @ kmitsotakis ξερ ...  POSITIVE      ND\n",
      "   New_ID                                               Text Sentiment  \\\n",
      "0     435   @ glinard @ teza _ tereza @ adonisgeorgiadi @...  POSITIVE   \n",
      "1    3061  τσιπρασ : ζητησαμ απο αντιπολιτευσ να συμμετεχ...  NEGATIVE   \n",
      "2    2161  σωστ ελληνασ , δημοκρατησ , ελλην εξωτερικ ερχ...  NEGATIVE   \n",
      "3    1271   @ 30 _ _ kai ναι βλεπ αυτ ενδιαφερ τουσ μητσο...  POSITIVE   \n",
      "4    4396  συνεντευξ μητσοτακ alpha : υπο αιρεσ 13η συντα...   NEUTRAL   \n",
      "5    1102  εκλογικ περιπτερ συριζα - προοδευτικ συμμαχι σ...  POSITIVE   \n",
      "6    1567  επιτακτικ αναγκ τ κυβερνησ κ . μητσοτακ καθαρσ...  POSITIVE   \n",
      "7    4093  times λονδιν τσιπρα : πωσ απο λαικιστ σωτηρ εγ...   NEUTRAL   \n",
      "8    3026   @ dimi _ zaharakis @ sspithess παντ να ξερ συ...  NEGATIVE   \n",
      "9    2473   @ manosvoularinos εμετικο ! ! ! στ νδ να βλεπ...  NEGATIVE   \n",
      "\n",
      "      Party  \n",
      "0    SYRIZA  \n",
      "1    SYRIZA  \n",
      "2        ND  \n",
      "3        ND  \n",
      "4        ND  \n",
      "5    SYRIZA  \n",
      "6  ELL_LYSI  \n",
      "7    SYRIZA  \n",
      "8        ND  \n",
      "9        ND  \n"
     ]
    }
   ],
   "source": [
    "data['Text'] = data['Text'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "valid['Text'] = valid['Text'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "\n",
    "data.to_csv(\"data.csv\", index=False)\n",
    "valid.to_csv(\"valid.csv\", index=False)\n",
    "print(data.head(10))\n",
    "print(valid.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b5bac",
   "metadata": {
    "papermill": {
     "duration": 0.045662,
     "end_time": "2023-12-22T12:31:47.848437",
     "exception": false,
     "start_time": "2023-12-22T12:31:47.802775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also stored as csv our final cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e6650",
   "metadata": {
    "papermill": {
     "duration": 0.045922,
     "end_time": "2023-12-22T12:31:47.939954",
     "exception": false,
     "start_time": "2023-12-22T12:31:47.894032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I am going to use optuna to tune the hyperparameters, I will brek the full body of optuna in pieces for better understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14cf005",
   "metadata": {
    "papermill": {
     "duration": 0.045087,
     "end_time": "2023-12-22T12:31:48.031869",
     "exception": false,
     "start_time": "2023-12-22T12:31:47.986782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First we read the clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1175837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:31:48.126979Z",
     "iopub.status.busy": "2023-12-22T12:31:48.126371Z",
     "iopub.status.idle": "2023-12-22T12:31:48.374079Z",
     "shell.execute_reply": "2023-12-22T12:31:48.372953Z"
    },
    "papermill": {
     "duration": 0.299186,
     "end_time": "2023-12-22T12:31:48.377355",
     "exception": false,
     "start_time": "2023-12-22T12:31:48.078169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "valid = pd.read_csv(\"/kaggle/working/valid.csv\")\n",
    "data = pd.read_csv(\"/kaggle/working/data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc9d44",
   "metadata": {
    "papermill": {
     "duration": 0.050828,
     "end_time": "2023-12-22T12:31:48.482290",
     "exception": false,
     "start_time": "2023-12-22T12:31:48.431462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is our DataLoader that uses x_train and y_train that will be defined later, the definition of this class remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d57a5cdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:31:48.575514Z",
     "iopub.status.busy": "2023-12-22T12:31:48.574789Z",
     "iopub.status.idle": "2023-12-22T12:31:52.145885Z",
     "shell.execute_reply": "2023-12-22T12:31:52.144815Z"
    },
    "papermill": {
     "duration": 3.620575,
     "end_time": "2023-12-22T12:31:52.148696",
     "exception": false,
     "start_time": "2023-12-22T12:31:48.528121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x=torch.from_numpy(x_train)\n",
    "        self.y=torch.from_numpy(y_train)\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):      \n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4849561",
   "metadata": {
    "papermill": {
     "duration": 0.045204,
     "end_time": "2023-12-22T12:31:52.239415",
     "exception": false,
     "start_time": "2023-12-22T12:31:52.194211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is a simple definition of the NN with just one hidden dimesnion, we will change this and try different approaches later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c6c2f0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:31:52.333315Z",
     "iopub.status.busy": "2023-12-22T12:31:52.332781Z",
     "iopub.status.idle": "2023-12-22T12:31:52.339669Z",
     "shell.execute_reply": "2023-12-22T12:31:52.338833Z"
    },
    "papermill": {
     "duration": 0.056099,
     "end_time": "2023-12-22T12:31:52.341737",
     "exception": false,
     "start_time": "2023-12-22T12:31:52.285638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,D_in,H,D_out):\n",
    "        super(Net,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.linear2=nn.Linear(H,D_out)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.sigmoid(self.linear1(x))  \n",
    "        x=self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a99fd",
   "metadata": {
    "papermill": {
     "duration": 0.045235,
     "end_time": "2023-12-22T12:31:52.432539",
     "exception": false,
     "start_time": "2023-12-22T12:31:52.387304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use label encoder to encode Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a69145b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:31:52.525426Z",
     "iopub.status.busy": "2023-12-22T12:31:52.524718Z",
     "iopub.status.idle": "2023-12-22T12:31:53.769082Z",
     "shell.execute_reply": "2023-12-22T12:31:53.767782Z"
    },
    "papermill": {
     "duration": 1.294278,
     "end_time": "2023-12-22T12:31:53.772114",
     "exception": false,
     "start_time": "2023-12-22T12:31:52.477836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "data['Sentiment'] = label_encoder.fit_transform(data['Sentiment'])\n",
    "valid['Sentiment'] = label_encoder.fit_transform(valid['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de5393b",
   "metadata": {
    "papermill": {
     "duration": 0.047796,
     "end_time": "2023-12-22T12:31:53.866538",
     "exception": false,
     "start_time": "2023-12-22T12:31:53.818742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define the word2vec model, different approaches will be tested afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc44a5a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:31:53.963626Z",
     "iopub.status.busy": "2023-12-22T12:31:53.963142Z",
     "iopub.status.idle": "2023-12-22T12:32:36.763514Z",
     "shell.execute_reply": "2023-12-22T12:32:36.762286Z"
    },
    "papermill": {
     "duration": 42.852792,
     "end_time": "2023-12-22T12:32:36.766538",
     "exception": false,
     "start_time": "2023-12-22T12:31:53.913746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "input_dim = 100\n",
    "nltk.download('punkt')\n",
    "data['tokenized_text'] = data['Text'].apply(word_tokenize)\n",
    "valid['tokenized_text'] = valid['Text'].apply(word_tokenize)\n",
    "word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf4705",
   "metadata": {
    "papermill": {
     "duration": 0.045386,
     "end_time": "2023-12-22T12:32:36.858098",
     "exception": false,
     "start_time": "2023-12-22T12:32:36.812712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since the text of each tweet has not a fixed size we will use the mean embedding to represent each tweet, we will check some different approaches later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c04b911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:36.951926Z",
     "iopub.status.busy": "2023-12-22T12:32:36.951219Z",
     "iopub.status.idle": "2023-12-22T12:32:41.139073Z",
     "shell.execute_reply": "2023-12-22T12:32:41.137956Z"
    },
    "papermill": {
     "duration": 4.237266,
     "end_time": "2023-12-22T12:32:41.141530",
     "exception": false,
     "start_time": "2023-12-22T12:32:36.904264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Party</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>mean_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35027</td>\n",
       "      <td># απολυμανση _ κοριοι # απεντομωση _ κοριοσ #...</td>\n",
       "      <td>1</td>\n",
       "      <td>SYRIZA</td>\n",
       "      <td>[#, απολυμανση, _, κοριοι, #, απεντομωση, _, κ...</td>\n",
       "      <td>[-0.2660993, 0.38771376, 0.30157158, 0.6053943...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9531</td>\n",
       "      <td>εξι νε επιστολ τ μακεδονι « καινε » τ νδ - μητ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ND</td>\n",
       "      <td>[εξι, νε, επιστολ, τ, μακεδονι, «, καινε, », τ...</td>\n",
       "      <td>[0.7498901, 0.033539865, -0.08454637, -0.50484...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14146</td>\n",
       "      <td>ισχυρ κκε , δυναμ λα στ βουλ στ καθημεριν αγων</td>\n",
       "      <td>2</td>\n",
       "      <td>KKE</td>\n",
       "      <td>[ισχυρ, κκε, ,, δυναμ, λα, στ, βουλ, στ, καθημ...</td>\n",
       "      <td>[-0.46750936, 1.1662321, 0.20756933, -0.106002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28716</td>\n",
       "      <td>@ five2nds @ anthi7vas μνημονιακοτατ # μερα25...</td>\n",
       "      <td>1</td>\n",
       "      <td>KKE</td>\n",
       "      <td>[@, five2nds, @, anthi7vas, μνημονιακοτατ, #, ...</td>\n",
       "      <td>[-1.4631376, 0.93277603, 0.116481006, 1.275122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32886</td>\n",
       "      <td>@ ai _ katerina αυτ εινα συγκλονιστικ εινα ψυ...</td>\n",
       "      <td>1</td>\n",
       "      <td>SYRIZA</td>\n",
       "      <td>[@, ai, _, katerina, αυτ, εινα, συγκλονιστικ, ...</td>\n",
       "      <td>[-0.77877134, 0.043030836, -0.039665487, 0.795...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   New_ID                                               Text  Sentiment  \\\n",
       "0   35027   # απολυμανση _ κοριοι # απεντομωση _ κοριοσ #...          1   \n",
       "1    9531  εξι νε επιστολ τ μακεδονι « καινε » τ νδ - μητ...          0   \n",
       "2   14146     ισχυρ κκε , δυναμ λα στ βουλ στ καθημεριν αγων          2   \n",
       "3   28716   @ five2nds @ anthi7vas μνημονιακοτατ # μερα25...          1   \n",
       "4   32886   @ ai _ katerina αυτ εινα συγκλονιστικ εινα ψυ...          1   \n",
       "\n",
       "    Party                                     tokenized_text  \\\n",
       "0  SYRIZA  [#, απολυμανση, _, κοριοι, #, απεντομωση, _, κ...   \n",
       "1      ND  [εξι, νε, επιστολ, τ, μακεδονι, «, καινε, », τ...   \n",
       "2     KKE  [ισχυρ, κκε, ,, δυναμ, λα, στ, βουλ, στ, καθημ...   \n",
       "3     KKE  [@, five2nds, @, anthi7vas, μνημονιακοτατ, #, ...   \n",
       "4  SYRIZA  [@, ai, _, katerina, αυτ, εινα, συγκλονιστικ, ...   \n",
       "\n",
       "                                      mean_embedding  \n",
       "0  [-0.2660993, 0.38771376, 0.30157158, 0.6053943...  \n",
       "1  [0.7498901, 0.033539865, -0.08454637, -0.50484...  \n",
       "2  [-0.46750936, 1.1662321, 0.20756933, -0.106002...  \n",
       "3  [-1.4631376, 0.93277603, 0.116481006, 1.275122...  \n",
       "4  [-0.77877134, 0.043030836, -0.039665487, 0.795...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd158d",
   "metadata": {
    "papermill": {
     "duration": 0.046174,
     "end_time": "2023-12-22T12:32:41.234276",
     "exception": false,
     "start_time": "2023-12-22T12:32:41.188102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Same for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5ddd626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:41.328396Z",
     "iopub.status.busy": "2023-12-22T12:32:41.327595Z",
     "iopub.status.idle": "2023-12-22T12:32:41.932703Z",
     "shell.execute_reply": "2023-12-22T12:32:41.931513Z"
    },
    "papermill": {
     "duration": 0.655549,
     "end_time": "2023-12-22T12:32:41.935472",
     "exception": false,
     "start_time": "2023-12-22T12:32:41.279923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Party</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>mean_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>435</td>\n",
       "      <td>@ glinard @ teza _ tereza @ adonisgeorgiadi @...</td>\n",
       "      <td>2</td>\n",
       "      <td>SYRIZA</td>\n",
       "      <td>[@, glinard, @, teza, _, tereza, @, adonisgeor...</td>\n",
       "      <td>[-0.19958033, 0.30547684, -0.01944047, 0.52729...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3061</td>\n",
       "      <td>τσιπρασ : ζητησαμ απο αντιπολιτευσ να συμμετεχ...</td>\n",
       "      <td>0</td>\n",
       "      <td>SYRIZA</td>\n",
       "      <td>[τσιπρασ, :, ζητησαμ, απο, αντιπολιτευσ, να, σ...</td>\n",
       "      <td>[-0.11728642, 0.4991955, 0.093434975, 0.109933...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2161</td>\n",
       "      <td>σωστ ελληνασ , δημοκρατησ , ελλην εξωτερικ ερχ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ND</td>\n",
       "      <td>[σωστ, ελληνασ, ,, δημοκρατησ, ,, ελλην, εξωτε...</td>\n",
       "      <td>[-0.47808185, 0.42485306, -0.041567665, 0.7423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1271</td>\n",
       "      <td>@ 30 _ _ kai ναι βλεπ αυτ ενδιαφερ τουσ μητσο...</td>\n",
       "      <td>2</td>\n",
       "      <td>ND</td>\n",
       "      <td>[@, 30, _, _, kai, ναι, βλεπ, αυτ, ενδιαφερ, τ...</td>\n",
       "      <td>[-0.12954354, 0.020736314, 0.0035473264, 0.411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4396</td>\n",
       "      <td>συνεντευξ μητσοτακ alpha : υπο αιρεσ 13η συντα...</td>\n",
       "      <td>1</td>\n",
       "      <td>ND</td>\n",
       "      <td>[συνεντευξ, μητσοτακ, alpha, :, υπο, αιρεσ, 13...</td>\n",
       "      <td>[0.65131706, -0.08270162, 0.38664216, 0.177338...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   New_ID                                               Text  Sentiment  \\\n",
       "0     435   @ glinard @ teza _ tereza @ adonisgeorgiadi @...          2   \n",
       "1    3061  τσιπρασ : ζητησαμ απο αντιπολιτευσ να συμμετεχ...          0   \n",
       "2    2161  σωστ ελληνασ , δημοκρατησ , ελλην εξωτερικ ερχ...          0   \n",
       "3    1271   @ 30 _ _ kai ναι βλεπ αυτ ενδιαφερ τουσ μητσο...          2   \n",
       "4    4396  συνεντευξ μητσοτακ alpha : υπο αιρεσ 13η συντα...          1   \n",
       "\n",
       "    Party                                     tokenized_text  \\\n",
       "0  SYRIZA  [@, glinard, @, teza, _, tereza, @, adonisgeor...   \n",
       "1  SYRIZA  [τσιπρασ, :, ζητησαμ, απο, αντιπολιτευσ, να, σ...   \n",
       "2      ND  [σωστ, ελληνασ, ,, δημοκρατησ, ,, ελλην, εξωτε...   \n",
       "3      ND  [@, 30, _, _, kai, ναι, βλεπ, αυτ, ενδιαφερ, τ...   \n",
       "4      ND  [συνεντευξ, μητσοτακ, alpha, :, υπο, αιρεσ, 13...   \n",
       "\n",
       "                                      mean_embedding  \n",
       "0  [-0.19958033, 0.30547684, -0.01944047, 0.52729...  \n",
       "1  [-0.11728642, 0.4991955, 0.093434975, 0.109933...  \n",
       "2  [-0.47808185, 0.42485306, -0.041567665, 0.7423...  \n",
       "3  [-0.12954354, 0.020736314, 0.0035473264, 0.411...  \n",
       "4  [0.65131706, -0.08270162, 0.38664216, 0.177338...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4021c4",
   "metadata": {
    "papermill": {
     "duration": 0.046153,
     "end_time": "2023-12-22T12:32:42.028799",
     "exception": false,
     "start_time": "2023-12-22T12:32:41.982646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is our train and validation sets, the way they are created remains unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "504b8f2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:42.122943Z",
     "iopub.status.busy": "2023-12-22T12:32:42.122491Z",
     "iopub.status.idle": "2023-12-22T12:32:42.127455Z",
     "shell.execute_reply": "2023-12-22T12:32:42.126685Z"
    },
    "papermill": {
     "duration": 0.054386,
     "end_time": "2023-12-22T12:32:42.129423",
     "exception": false,
     "start_time": "2023-12-22T12:32:42.075037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = data['mean_embedding']\n",
    "x_val = valid['mean_embedding']\n",
    "y_val = valid['Sentiment']\n",
    "y_train = data['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e88a59",
   "metadata": {
    "papermill": {
     "duration": 0.047499,
     "end_time": "2023-12-22T12:32:42.223334",
     "exception": false,
     "start_time": "2023-12-22T12:32:42.175835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Convert to float type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f4bb956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:42.319295Z",
     "iopub.status.busy": "2023-12-22T12:32:42.318240Z",
     "iopub.status.idle": "2023-12-22T12:32:42.431414Z",
     "shell.execute_reply": "2023-12-22T12:32:42.430273Z"
    },
    "papermill": {
     "duration": 0.1643,
     "end_time": "2023-12-22T12:32:42.434069",
     "exception": false,
     "start_time": "2023-12-22T12:32:42.269769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "x_train = np.vstack(x_train).astype(np.float32)\n",
    "x_val = np.vstack(x_val).astype(np.float32)\n",
    "\n",
    "# Now x_train_np is a NumPy array with float32 elements\n",
    "print(x_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5779b3af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:42.529154Z",
     "iopub.status.busy": "2023-12-22T12:32:42.528762Z",
     "iopub.status.idle": "2023-12-22T12:32:42.534360Z",
     "shell.execute_reply": "2023-12-22T12:32:42.533416Z"
    },
    "papermill": {
     "duration": 0.055859,
     "end_time": "2023-12-22T12:32:42.536960",
     "exception": false,
     "start_time": "2023-12-22T12:32:42.481101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_val = y_val.values\n",
    "y_train = y_train.values\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc4ffd",
   "metadata": {
    "papermill": {
     "duration": 0.045802,
     "end_time": "2023-12-22T12:32:42.628782",
     "exception": false,
     "start_time": "2023-12-22T12:32:42.582980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create the dataset and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54f9fbfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:42.723521Z",
     "iopub.status.busy": "2023-12-22T12:32:42.722460Z",
     "iopub.status.idle": "2023-12-22T12:32:42.736661Z",
     "shell.execute_reply": "2023-12-22T12:32:42.735694Z"
    },
    "papermill": {
     "duration": 0.064465,
     "end_time": "2023-12-22T12:32:42.739219",
     "exception": false,
     "start_time": "2023-12-22T12:32:42.674754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_set=Data()\n",
    "trainloader=DataLoader(dataset=data_set,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32a9cf",
   "metadata": {
    "papermill": {
     "duration": 0.046199,
     "end_time": "2023-12-22T12:32:42.832870",
     "exception": false,
     "start_time": "2023-12-22T12:32:42.786671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Get an insight of the data, since we are using mean embedding, the values are close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a806eefe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:42.927832Z",
     "iopub.status.busy": "2023-12-22T12:32:42.927412Z",
     "iopub.status.idle": "2023-12-22T12:32:43.048680Z",
     "shell.execute_reply": "2023-12-22T12:32:43.047642Z"
    },
    "papermill": {
     "duration": 0.172398,
     "end_time": "2023-12-22T12:32:43.051772",
     "exception": false,
     "start_time": "2023-12-22T12:32:42.879374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.4989e-01,  3.3540e-02, -8.4546e-02, -5.0484e-01,  7.6754e-02,\n",
       "         -5.5329e-01,  5.1206e-01,  9.0051e-01, -7.2913e-01, -3.2155e-01,\n",
       "         -1.2228e-01, -3.1287e-01,  2.9330e-01,  8.7970e-01,  1.5034e-01,\n",
       "         -7.8413e-01, -7.9681e-02, -5.0368e-01, -1.1225e-01, -1.4270e+00,\n",
       "          7.0529e-01,  3.0117e-01,  8.8501e-01,  3.3277e-01, -2.6973e-01,\n",
       "         -6.6508e-01,  8.4934e-02, -1.1731e-01, -4.6263e-01,  5.2594e-01,\n",
       "          6.7127e-01, -6.5310e-01,  4.8948e-01, -5.2458e-01, -4.8400e-01,\n",
       "          1.2937e+00,  5.0512e-01,  6.5882e-01,  3.4679e-01, -1.5165e+00,\n",
       "          4.6210e-02, -4.6174e-01, -8.0139e-01,  3.8962e-01,  2.8268e-01,\n",
       "          2.4144e-03, -7.6588e-01, -1.1874e-01,  1.0550e+00,  4.7734e-01,\n",
       "         -5.7921e-01, -3.9839e-01,  2.3553e-01,  4.2765e-01,  5.1989e-01,\n",
       "          9.3723e-01, -2.1290e-01, -1.4168e-01, -7.9782e-01, -3.6919e-01,\n",
       "          5.1111e-02, -4.7642e-01,  4.2305e-01, -1.9095e-01, -1.4556e+00,\n",
       "          1.0295e+00,  2.2860e-01,  2.5182e-02, -8.2739e-01,  6.6267e-01,\n",
       "          2.6990e-02,  1.1693e+00,  8.1590e-01, -6.2528e-01,  6.2686e-01,\n",
       "          5.3924e-01,  7.0795e-01,  1.0205e-01, -8.5981e-01,  8.7328e-01,\n",
       "         -4.0803e-01,  3.4983e-01, -6.7534e-01,  9.7200e-01, -3.2996e-01,\n",
       "         -6.0096e-01, -1.0168e-01,  9.2495e-01,  7.0701e-01,  6.8345e-01,\n",
       "          1.6405e+00,  6.5612e-01, -1.3214e-02, -1.9189e-01,  4.2301e-01,\n",
       "         -2.2611e-01, -2.1542e-01, -6.2278e-01,  1.6150e-02, -5.0269e-01],\n",
       "        [-4.6751e-01,  1.1662e+00,  2.0757e-01, -1.0600e-01, -4.7391e-01,\n",
       "         -9.5788e-04, -2.0011e-01,  1.1641e+00, -8.9370e-01,  4.2780e-01,\n",
       "         -6.5966e-01, -4.7453e-01,  1.6210e-01,  6.8939e-01, -1.7112e-01,\n",
       "         -3.7604e-01,  1.8522e-01,  1.5121e-01,  9.6294e-02, -2.8625e+00,\n",
       "         -2.3868e-01,  9.9981e-01,  7.4695e-01, -2.0073e-01,  1.2743e-01,\n",
       "         -6.8950e-01, -6.5846e-01, -1.0425e-01, -2.8111e-01,  9.4160e-02,\n",
       "          7.1222e-01, -3.1113e-01,  4.2684e-01, -2.7814e-01, -3.4964e-01,\n",
       "          9.2263e-01,  3.0572e-01, -3.2655e-01,  6.7590e-01, -2.1733e+00,\n",
       "          1.9548e-01, -3.6275e-01, -3.4860e-01,  6.3443e-01,  1.4370e+00,\n",
       "         -3.7156e-01, -4.8964e-01,  4.6536e-01,  1.0772e+00, -5.2612e-01,\n",
       "         -3.5551e-01,  3.2572e-01,  1.0251e-01,  1.0255e+00, -7.5042e-03,\n",
       "          9.2635e-01, -7.7506e-01, -5.7778e-01, -1.3854e+00, -3.1003e-01,\n",
       "         -2.8687e-02,  2.8326e-01,  1.1518e+00,  6.9937e-01, -1.3111e+00,\n",
       "         -2.5430e-01, -2.3898e-01,  5.6905e-01, -6.4293e-01,  1.4656e+00,\n",
       "         -3.5014e-01,  1.4401e+00,  4.9628e-01, -1.9043e-01,  9.7845e-01,\n",
       "          1.2430e+00,  7.2671e-01,  4.1636e-01, -5.8507e-01, -1.9513e-01,\n",
       "         -3.4408e-01, -1.3581e-01, -7.7129e-01,  1.1254e+00, -8.3117e-01,\n",
       "         -2.2396e-01, -6.2732e-01,  8.7826e-01,  1.1985e+00,  9.3254e-01,\n",
       "          1.0284e+00,  6.2187e-01,  3.1149e-01,  1.1900e-01,  1.7429e+00,\n",
       "         -7.2155e-01, -3.7043e-02, -3.6116e-01,  5.5494e-01,  4.3755e-02],\n",
       "        [-1.4631e+00,  9.3278e-01,  1.1648e-01,  1.2751e+00, -3.1599e-01,\n",
       "         -8.9414e-01,  7.3860e-01,  1.6837e+00, -2.1620e-01, -1.5625e+00,\n",
       "          5.4342e-01, -1.2548e+00, -2.6302e-01,  1.0338e+00, -1.3063e+00,\n",
       "         -4.5960e-01,  1.8630e+00, -3.3732e-01, -4.8390e-01, -2.1971e+00,\n",
       "          1.3781e-01, -4.7729e-01,  1.9055e-01, -1.0263e+00,  1.6300e-01,\n",
       "         -2.6916e-01, -1.6713e+00,  1.5179e-01, -7.3430e-01, -1.0293e+00,\n",
       "          1.1967e-01, -4.1785e-01,  1.1581e+00, -1.4834e+00, -5.5257e-01,\n",
       "         -5.9798e-02,  1.0210e+00,  6.5214e-02, -8.0987e-01, -8.4549e-01,\n",
       "         -1.5024e+00,  5.6311e-01, -1.7481e-01, -6.8370e-01, -4.5139e-01,\n",
       "         -7.6935e-01, -5.1760e-01,  6.4163e-01, -2.1362e-01,  1.1506e+00,\n",
       "          1.1093e-01, -4.6595e-01, -1.3691e+00,  3.8368e-01, -1.9079e-02,\n",
       "         -1.2916e+00,  1.2283e+00, -7.4559e-01, -1.3512e+00,  9.2251e-01,\n",
       "         -3.5100e-01,  3.5204e-01,  1.2860e+00,  1.2219e-01, -6.0037e-01,\n",
       "         -5.2617e-01,  5.2566e-03,  9.6636e-01, -1.9008e+00,  8.9205e-01,\n",
       "          7.0561e-01,  6.9473e-01,  5.6116e-01,  1.0427e+00,  1.7183e+00,\n",
       "          1.1220e-01, -9.9156e-02,  3.1191e-01, -8.2854e-01, -2.7526e-01,\n",
       "          7.9704e-03,  1.9256e-01, -4.2159e-01,  4.9584e-01, -4.7025e-01,\n",
       "         -1.9378e+00,  5.7833e-01,  2.8343e-01, -4.5700e-01,  1.2376e+00,\n",
       "          1.2550e-01,  1.5254e+00,  1.1060e+00,  8.2147e-01,  2.3895e+00,\n",
       "          7.4833e-01, -7.6072e-01,  4.6835e-01,  1.2295e-01,  3.7424e-01],\n",
       "        [-7.7877e-01,  4.3031e-02, -3.9665e-02,  7.9550e-01, -3.9580e-01,\n",
       "         -9.3398e-01,  5.3626e-01,  1.8164e+00, -2.4170e-01, -8.5311e-01,\n",
       "          7.6519e-02, -3.7624e-01, -3.3821e-01,  9.4107e-01, -5.5435e-01,\n",
       "         -1.3383e-01,  1.0210e+00, -3.6405e-01, -5.3481e-01, -9.2672e-01,\n",
       "          1.3458e-01,  2.4079e-01,  9.5707e-01, -2.1717e-01, -4.0907e-01,\n",
       "         -4.2028e-01, -5.3124e-01,  2.4293e-01, -1.4315e-01, -3.1422e-01,\n",
       "          6.3226e-01, -2.2528e-01,  4.9172e-01, -6.4323e-01, -6.0327e-01,\n",
       "          6.0495e-01,  8.7074e-01, -7.5196e-01, -6.3770e-01, -7.0493e-01,\n",
       "         -1.7296e-01,  9.5650e-02, -4.9493e-01, -1.4783e-01,  3.3945e-01,\n",
       "         -9.1063e-02, -8.4833e-01,  5.4764e-02,  7.9170e-02,  3.3208e-01,\n",
       "         -2.8331e-01, -8.6588e-02, -6.4686e-01, -1.3447e-02,  8.1722e-02,\n",
       "         -2.4683e-01,  8.4611e-01, -3.9519e-01, -1.0398e-01,  2.8408e-01,\n",
       "         -5.6518e-02,  8.5673e-01,  7.7233e-01, -2.6269e-01, -9.2642e-01,\n",
       "          1.4260e-01,  1.7411e-01,  9.1432e-01, -1.6132e+00,  2.9856e-01,\n",
       "          2.6216e-02,  6.1600e-01,  6.0496e-01,  2.5532e-01,  8.5116e-01,\n",
       "         -8.5235e-02,  9.5467e-02,  4.2686e-02, -8.7579e-01, -4.7277e-02,\n",
       "          2.8835e-01, -8.3725e-02, -2.5262e-02,  8.3857e-01, -2.7664e-01,\n",
       "         -8.4904e-01,  2.9464e-01,  6.1154e-02, -2.4734e-01,  5.5756e-01,\n",
       "         -1.5507e-01,  5.7966e-01,  6.5818e-01,  7.0231e-02,  1.4990e+00,\n",
       "          3.0720e-01, -1.3060e-01,  2.6999e-01,  3.4710e-01,  3.2191e-01],\n",
       "        [-1.7979e-01,  2.3188e-01, -5.3360e-02,  5.4734e-01,  6.7717e-02,\n",
       "         -5.1283e-01,  4.6679e-01,  1.3397e+00, -9.4601e-01, -6.5228e-01,\n",
       "          1.8044e-01, -5.1284e-01, -1.7565e-01,  7.8872e-01, -1.0320e-01,\n",
       "         -8.7124e-02,  5.1826e-01, -3.7149e-02, -3.5919e-01, -1.2668e+00,\n",
       "          1.1303e-01,  1.6636e-01,  9.2371e-01, -4.3797e-01,  1.5338e-01,\n",
       "         -2.3201e-01, -2.8447e-01,  4.8184e-03, -2.9886e-01,  7.0571e-02,\n",
       "          3.9634e-01, -1.3275e-01,  4.2385e-01, -7.8981e-01, -5.3617e-01,\n",
       "          1.5790e-01,  1.3951e-01, -6.1502e-01,  9.2751e-02, -1.0093e+00,\n",
       "         -1.2714e-01, -3.1119e-01, -3.2677e-01,  4.9519e-02,  5.0206e-01,\n",
       "          1.0653e-01, -4.7622e-01,  1.8260e-01,  2.9865e-01,  1.9275e-01,\n",
       "         -2.6940e-01,  5.6413e-02, -3.2419e-01,  1.2477e-02,  3.8914e-02,\n",
       "         -3.0637e-01,  1.7586e-01, -2.1174e-01, -2.9289e-01,  3.0919e-01,\n",
       "          1.0674e-01,  4.3546e-01,  3.4680e-01, -8.7247e-02, -7.5887e-01,\n",
       "          6.0487e-01,  3.2519e-01,  3.3932e-01, -7.3411e-01,  6.2718e-01,\n",
       "         -1.2909e-01,  5.5445e-01,  3.0210e-01, -1.9134e-01,  6.0724e-01,\n",
       "         -1.2826e-01,  1.7869e-01,  2.6950e-01, -4.5672e-01, -2.8482e-01,\n",
       "          1.0724e-01, -1.3214e-01, -1.4919e-01,  5.1243e-01, -3.2519e-01,\n",
       "         -4.4901e-01,  3.0256e-01, -1.1322e-01,  4.6489e-01,  7.4737e-02,\n",
       "          2.5784e-01,  2.1894e-01,  3.4817e-01,  2.8396e-01,  1.1210e+00,\n",
       "         -1.3253e-01,  2.7295e-01, -6.2453e-01,  2.6489e-01,  1.7526e-01],\n",
       "        [ 3.5647e-01, -3.3720e-01,  2.1588e-01, -5.5550e-01,  5.8764e-01,\n",
       "         -3.8310e-01,  4.3946e-01,  1.8232e+00, -4.0035e-01,  2.9275e-01,\n",
       "         -7.8507e-01, -5.3739e-01, -8.4451e-01,  1.3427e+00, -3.5100e-01,\n",
       "         -3.3554e-01, -4.3696e-01, -6.8060e-01, -4.6049e-01, -1.1466e+00,\n",
       "          5.6679e-01,  1.1732e+00,  2.8853e-01,  1.0236e+00, -7.6288e-02,\n",
       "         -1.0640e+00,  3.2584e-01, -9.4560e-01, -3.2903e-01, -2.8102e-01,\n",
       "          1.1366e+00, -7.8245e-01, -2.2232e-01, -1.6937e+00, -4.6019e-01,\n",
       "          1.2533e+00,  5.5033e-01, -2.7396e-01,  2.6568e-01, -2.5960e+00,\n",
       "         -1.9465e-01, -9.6192e-01, -1.2577e+00,  7.3061e-01,  9.9614e-01,\n",
       "          1.5422e-01, -1.4034e+00, -5.9446e-01,  1.2021e+00, -1.7397e-01,\n",
       "         -7.3405e-01, -6.6129e-01,  6.3057e-01, -2.9220e-01,  1.7388e+00,\n",
       "         -1.6325e-02,  3.9169e-01, -1.1298e+00, -4.4600e-01,  1.7140e-01,\n",
       "          3.6687e-01,  3.2878e-01,  7.5607e-01, -2.7721e-01, -1.3401e+00,\n",
       "          8.1796e-01,  1.2241e-01,  5.9614e-01, -1.3164e+00,  3.0262e-01,\n",
       "         -9.2467e-01,  8.7650e-01,  3.8119e-01, -9.0740e-01,  4.2413e-01,\n",
       "         -6.4651e-01,  3.2277e-01, -6.1320e-01, -7.9960e-01,  3.2851e-03,\n",
       "          2.6082e-01, -4.2888e-01, -4.6139e-01,  1.2784e-01, -2.6628e-02,\n",
       "         -7.1854e-01, -2.3379e-02,  2.7118e-01,  2.4637e-01,  1.9793e-01,\n",
       "          6.8630e-01,  6.4984e-01,  8.0732e-01, -3.3470e-01,  1.1486e+00,\n",
       "          4.0321e-01, -4.7542e-01,  2.2617e-01,  3.4386e-01, -6.1331e-01],\n",
       "        [ 9.1219e-02,  2.7169e-01,  4.1978e-03,  5.1621e-01,  6.2358e-02,\n",
       "         -1.0450e+00,  5.0226e-01,  1.6548e+00, -9.1666e-01, -7.7718e-01,\n",
       "          1.3381e-01, -6.0754e-01, -1.6183e-01,  7.7206e-01,  3.6782e-01,\n",
       "         -1.7095e-01,  9.2052e-02,  1.1501e-01,  4.8270e-02, -1.5129e+00,\n",
       "          4.1135e-01,  4.6027e-01,  1.0104e+00, -3.6732e-01, -4.6295e-03,\n",
       "         -5.8849e-01, -3.9386e-01, -7.0009e-02, -1.0987e-01, -2.3624e-01,\n",
       "          5.4411e-01, -7.7765e-01,  6.0183e-01, -7.1667e-01, -2.2063e-01,\n",
       "          4.6284e-01,  4.5735e-01, -4.7143e-01,  4.8305e-01, -1.3611e+00,\n",
       "         -3.2691e-01, -2.9208e-01, -5.9995e-01,  3.1690e-01,  4.3932e-01,\n",
       "         -1.4097e-01, -7.7253e-01,  2.9408e-01,  7.5227e-01,  8.9960e-02,\n",
       "         -4.6864e-01,  9.6660e-02, -1.9264e-01,  3.2182e-01,  5.4637e-01,\n",
       "          3.0641e-01,  1.2052e-01, -2.2932e-01, -9.3574e-02,  3.5901e-01,\n",
       "          2.3158e-02,  6.4040e-01,  5.0935e-01,  7.1977e-03, -9.5232e-01,\n",
       "          8.4909e-01,  6.0948e-01,  9.4780e-01, -8.5334e-01,  7.7063e-01,\n",
       "          1.7507e-01,  6.5358e-01,  6.1103e-01, -2.6429e-01,  6.7305e-01,\n",
       "          2.4950e-01,  1.2891e-01,  3.8462e-01, -7.7572e-01, -3.1227e-01,\n",
       "         -1.5968e-01, -9.6691e-02,  6.9543e-02,  7.6995e-01, -1.0928e-01,\n",
       "         -6.1422e-02,  3.4992e-01,  6.8847e-02,  5.0359e-01,  3.9454e-01,\n",
       "          7.3670e-01,  1.1181e-01,  3.9528e-01,  6.0200e-01,  1.2890e+00,\n",
       "          4.9987e-02,  2.4591e-02, -6.1011e-01,  2.3108e-01, -7.3601e-03],\n",
       "        [ 2.5769e-01,  2.9947e-01,  2.3294e-01,  8.7924e-02, -2.2783e-01,\n",
       "         -5.8032e-01,  1.7152e-01,  9.8136e-01, -9.6906e-01, -3.6499e-01,\n",
       "         -2.8607e-01, -2.7159e-01,  1.4105e-01,  4.7132e-01,  2.8346e-01,\n",
       "         -3.2024e-01, -5.3107e-02, -2.5882e-01, -7.7756e-02, -1.5622e+00,\n",
       "          3.4442e-01,  6.7289e-01,  9.3924e-01,  1.7240e-01, -1.4470e-01,\n",
       "         -4.0133e-01, -1.1376e-01,  4.4126e-02, -4.1812e-01,  2.1838e-01,\n",
       "          4.2156e-01, -3.8783e-01,  4.8461e-01, -7.2981e-01, -1.9557e-01,\n",
       "          6.5645e-01, -1.2289e-02, -3.9670e-01,  2.0170e-01, -1.4238e+00,\n",
       "          1.9910e-02, -5.8050e-01, -7.2445e-01,  6.1999e-01,  8.7481e-01,\n",
       "         -5.4145e-02, -8.0689e-01, -1.2048e-02,  6.7726e-01, -2.3539e-02,\n",
       "         -3.1636e-01,  1.9081e-01,  1.9676e-01,  2.0350e-02,  6.6442e-01,\n",
       "          2.7007e-01, -2.9088e-01, -3.0119e-01, -5.0716e-01,  1.8167e-02,\n",
       "          5.0083e-01, -3.1502e-02,  1.8025e-01, -1.9470e-01, -1.1214e+00,\n",
       "          7.5481e-01,  3.6494e-01,  3.9173e-01, -5.6206e-01,  8.3723e-01,\n",
       "         -4.1456e-01,  7.8728e-01,  5.5770e-01, -5.8176e-01,  5.6287e-01,\n",
       "          5.8555e-01,  6.6908e-01, -1.3695e-01, -5.6378e-01, -1.0065e-01,\n",
       "         -3.7856e-01, -2.5858e-01, -2.2599e-01,  5.7753e-01, -4.7434e-01,\n",
       "         -3.0748e-01,  5.4750e-02,  5.4573e-01,  7.3415e-01,  3.4063e-01,\n",
       "          7.4100e-01,  1.9976e-01,  6.3068e-02,  2.2634e-01,  9.9446e-01,\n",
       "         -2.6406e-01, -6.3538e-02, -6.3411e-01,  3.9676e-01, -3.8943e-01],\n",
       "        [-2.0818e-01,  2.7284e-01,  1.1861e-01,  3.0456e-01, -2.4562e-01,\n",
       "         -8.1085e-01,  2.6164e-01,  2.1161e+00, -5.5551e-01, -9.2919e-01,\n",
       "          6.1570e-02, -8.9612e-02, -3.6837e-01,  6.5079e-01,  2.7896e-01,\n",
       "          7.4752e-02,  3.2773e-01, -2.0030e-01, -4.5360e-01, -1.1847e+00,\n",
       "         -1.0526e-01,  4.5477e-01,  1.2090e+00, -8.4738e-02, -3.4942e-01,\n",
       "         -3.0151e-01, -3.1657e-01, -1.6200e-01,  9.8720e-02,  8.3455e-02,\n",
       "          5.6124e-01, -5.2817e-01,  3.6554e-01, -9.6950e-01, -4.3968e-01,\n",
       "          5.6808e-01,  2.9224e-01, -1.2211e+00, -1.8687e-01, -1.1421e+00,\n",
       "          4.5645e-02, -2.6998e-01, -7.0287e-01, -1.1655e-01,  1.0272e+00,\n",
       "         -2.1719e-01, -7.6871e-01,  1.7228e-01,  1.5780e-01, -6.1496e-02,\n",
       "         -3.0507e-01,  5.5794e-03, -3.9272e-01, -2.0800e-01,  4.5781e-01,\n",
       "         -2.7154e-01,  4.0859e-01, -2.1922e-01, -7.6029e-02,  5.9045e-03,\n",
       "         -1.2508e-02,  1.0010e+00,  5.7077e-01, -5.6447e-02, -9.9758e-01,\n",
       "          8.9074e-01,  6.4540e-01,  7.7524e-01, -1.3985e+00,  6.4939e-01,\n",
       "         -3.1003e-01,  7.9890e-01,  4.1015e-01, -1.0004e-01,  4.5287e-01,\n",
       "          2.2981e-01, -6.0095e-02,  2.7353e-01, -9.1506e-01, -2.6909e-01,\n",
       "          1.5940e-01, -1.0509e-01,  1.2515e-01,  7.0777e-01, -2.6262e-01,\n",
       "         -2.1281e-01,  6.3500e-01, -2.6191e-02,  2.5232e-01,  7.8979e-02,\n",
       "          2.8649e-01,  1.7356e-01,  1.5194e-01,  2.1900e-02,  1.4139e+00,\n",
       "          8.8111e-02,  2.6491e-01, -6.3310e-01,  3.0958e-01,  2.1678e-01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.x[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8f4af3",
   "metadata": {
    "papermill": {
     "duration": 0.046658,
     "end_time": "2023-12-22T12:32:43.145173",
     "exception": false,
     "start_time": "2023-12-22T12:32:43.098515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Get an insight of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7351377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:43.242026Z",
     "iopub.status.busy": "2023-12-22T12:32:43.241641Z",
     "iopub.status.idle": "2023-12-22T12:32:43.249150Z",
     "shell.execute_reply": "2023-12-22T12:32:43.248056Z"
    },
    "papermill": {
     "duration": 0.05921,
     "end_time": "2023-12-22T12:32:43.251483",
     "exception": false,
     "start_time": "2023-12-22T12:32:43.192273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1, 1, 0, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.y[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1233ee",
   "metadata": {
    "papermill": {
     "duration": 0.049917,
     "end_time": "2023-12-22T12:32:43.348395",
     "exception": false,
     "start_time": "2023-12-22T12:32:43.298478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Check that size of x and y are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cd1574d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:43.465523Z",
     "iopub.status.busy": "2023-12-22T12:32:43.464649Z",
     "iopub.status.idle": "2023-12-22T12:32:43.473460Z",
     "shell.execute_reply": "2023-12-22T12:32:43.472090Z"
    },
    "papermill": {
     "duration": 0.080687,
     "end_time": "2023-12-22T12:32:43.476053",
     "exception": false,
     "start_time": "2023-12-22T12:32:43.395366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([36630, 100]), torch.Size([36630]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.x.shape, data_set.y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ae9459",
   "metadata": {
    "papermill": {
     "duration": 0.046683,
     "end_time": "2023-12-22T12:32:43.570491",
     "exception": false,
     "start_time": "2023-12-22T12:32:43.523808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28a55cee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:43.666869Z",
     "iopub.status.busy": "2023-12-22T12:32:43.666481Z",
     "iopub.status.idle": "2023-12-22T12:32:43.675280Z",
     "shell.execute_reply": "2023-12-22T12:32:43.674377Z"
    },
    "papermill": {
     "duration": 0.059886,
     "end_time": "2023-12-22T12:32:43.677642",
     "exception": false,
     "start_time": "2023-12-22T12:32:43.617756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim=100     # how many Variables are in the dataset\n",
    "hidden_dim = 25 # hidden layers\n",
    "output_dim=3    # number of classes\n",
    "model=Net(input_dim,hidden_dim,output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310615bd",
   "metadata": {
    "papermill": {
     "duration": 0.047641,
     "end_time": "2023-12-22T12:32:43.772312",
     "exception": false,
     "start_time": "2023-12-22T12:32:43.724671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define loss function, we will check others later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b17f0d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:43.869861Z",
     "iopub.status.busy": "2023-12-22T12:32:43.869437Z",
     "iopub.status.idle": "2023-12-22T12:32:43.874299Z",
     "shell.execute_reply": "2023-12-22T12:32:43.873490Z"
    },
    "papermill": {
     "duration": 0.056235,
     "end_time": "2023-12-22T12:32:43.876379",
     "exception": false,
     "start_time": "2023-12-22T12:32:43.820144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66eb09d",
   "metadata": {
    "papermill": {
     "duration": 0.047138,
     "end_time": "2023-12-22T12:32:43.970876",
     "exception": false,
     "start_time": "2023-12-22T12:32:43.923738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define learning rate and optimizer, we will check other values later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02b1a9d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:44.067534Z",
     "iopub.status.busy": "2023-12-22T12:32:44.067105Z",
     "iopub.status.idle": "2023-12-22T12:32:44.073063Z",
     "shell.execute_reply": "2023-12-22T12:32:44.071947Z"
    },
    "papermill": {
     "duration": 0.056636,
     "end_time": "2023-12-22T12:32:44.075351",
     "exception": false,
     "start_time": "2023-12-22T12:32:44.018715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate=0.1\n",
    "\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab1d35",
   "metadata": {
    "papermill": {
     "duration": 0.046891,
     "end_time": "2023-12-22T12:32:44.169302",
     "exception": false,
     "start_time": "2023-12-22T12:32:44.122411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Train model for 300 epochs, we will also check some other values later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3130e5ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:32:44.266676Z",
     "iopub.status.busy": "2023-12-22T12:32:44.266188Z",
     "iopub.status.idle": "2023-12-22T12:36:03.901337Z",
     "shell.execute_reply": "2023-12-22T12:36:03.900075Z"
    },
    "papermill": {
     "duration": 199.687442,
     "end_time": "2023-12-22T12:36:03.904497",
     "exception": false,
     "start_time": "2023-12-22T12:32:44.217055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epochs=300\n",
    "loss_list=[]\n",
    "early_stop_threshold = 0.01\n",
    "\n",
    "\n",
    "#n_epochs\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "\n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        z=model.forward(x)\n",
    "        loss=criterion(z,y)\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45b0a4",
   "metadata": {
    "papermill": {
     "duration": 0.047967,
     "end_time": "2023-12-22T12:36:04.003783",
     "exception": false,
     "start_time": "2023-12-22T12:36:03.955816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Feed the validation set to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc4d3a00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:36:04.102617Z",
     "iopub.status.busy": "2023-12-22T12:36:04.101944Z",
     "iopub.status.idle": "2023-12-22T12:36:04.108423Z",
     "shell.execute_reply": "2023-12-22T12:36:04.107372Z"
    },
    "papermill": {
     "duration": 0.057938,
     "end_time": "2023-12-22T12:36:04.110818",
     "exception": false,
     "start_time": "2023-12-22T12:36:04.052880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_val = torch.from_numpy(x_val)\n",
    "z=model.forward(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec46ead5",
   "metadata": {
    "papermill": {
     "duration": 0.047578,
     "end_time": "2023-12-22T12:36:04.207519",
     "exception": false,
     "start_time": "2023-12-22T12:36:04.159941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Output is 3 values based on the idea of a Softmax Classifier, we chose the highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e15ec48e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:36:04.305793Z",
     "iopub.status.busy": "2023-12-22T12:36:04.305384Z",
     "iopub.status.idle": "2023-12-22T12:36:04.316448Z",
     "shell.execute_reply": "2023-12-22T12:36:04.315248Z"
    },
    "papermill": {
     "duration": 0.063057,
     "end_time": "2023-12-22T12:36:04.319173",
     "exception": false,
     "start_time": "2023-12-22T12:36:04.256116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "z=model.forward(x_val)\n",
    "max_indexes = torch.argmax(z, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07738f9b",
   "metadata": {
    "papermill": {
     "duration": 0.046587,
     "end_time": "2023-12-22T12:36:04.414019",
     "exception": false,
     "start_time": "2023-12-22T12:36:04.367432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Convert to numpy so we can use the metrics for scoring from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96dee674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:36:04.511348Z",
     "iopub.status.busy": "2023-12-22T12:36:04.510530Z",
     "iopub.status.idle": "2023-12-22T12:36:04.515756Z",
     "shell.execute_reply": "2023-12-22T12:36:04.515002Z"
    },
    "papermill": {
     "duration": 0.056384,
     "end_time": "2023-12-22T12:36:04.518041",
     "exception": false,
     "start_time": "2023-12-22T12:36:04.461657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "y_pred = max_indexes.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6da54ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:36:04.615025Z",
     "iopub.status.busy": "2023-12-22T12:36:04.614651Z",
     "iopub.status.idle": "2023-12-22T12:36:04.635800Z",
     "shell.execute_reply": "2023-12-22T12:36:04.634468Z"
    },
    "papermill": {
     "duration": 0.072782,
     "end_time": "2023-12-22T12:36:04.638310",
     "exception": false,
     "start_time": "2023-12-22T12:36:04.565528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38551\n",
      "Precision: 0.39132\n",
      "Recall: 0.38551\n",
      "F1 Score: 0.37833\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Precision: {precision:.5f}')\n",
    "print(f'Recall: {recall:.5f}')\n",
    "print(f'F1 Score: {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdaf432",
   "metadata": {
    "papermill": {
     "duration": 0.047235,
     "end_time": "2023-12-22T12:36:04.733286",
     "exception": false,
     "start_time": "2023-12-22T12:36:04.686051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This was a simple example with 300 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7ce349",
   "metadata": {
    "papermill": {
     "duration": 0.047958,
     "end_time": "2023-12-22T12:36:04.829291",
     "exception": false,
     "start_time": "2023-12-22T12:36:04.781333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before we continue with optuna we need to define the number of epochs, we need a reliable number but not something too large because optuna would take for ages, lets try 11 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c952d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:36:04.928010Z",
     "iopub.status.busy": "2023-12-22T12:36:04.927595Z",
     "iopub.status.idle": "2023-12-22T12:36:12.284244Z",
     "shell.execute_reply": "2023-12-22T12:36:12.283132Z"
    },
    "papermill": {
     "duration": 7.408573,
     "end_time": "2023-12-22T12:36:12.287034",
     "exception": false,
     "start_time": "2023-12-22T12:36:04.878461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37768\n",
      "Precision: 0.38214\n",
      "Recall: 0.37768\n",
      "F1 Score: 0.36117\n"
     ]
    }
   ],
   "source": [
    "input_dim=100     # how many Variables are in the dataset\n",
    "hidden_dim = 25 # hidden layers\n",
    "output_dim=3    # number of classes\n",
    "model=Net(input_dim,hidden_dim,output_dim)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate=0.1\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "n_epochs=11\n",
    "loss_list=[]\n",
    "\n",
    "#n_epochs\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "\n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        z=model.forward(x)\n",
    "        loss=criterion(z,y)\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.data)\n",
    "z=model.forward(x_val)\n",
    "max_indexes = torch.argmax(z, dim=1)\n",
    "y_pred = max_indexes.numpy()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Precision: {precision:.5f}')\n",
    "print(f'Recall: {recall:.5f}')\n",
    "print(f'F1 Score: {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff59301",
   "metadata": {
    "papermill": {
     "duration": 0.046902,
     "end_time": "2023-12-22T12:36:12.381392",
     "exception": false,
     "start_time": "2023-12-22T12:36:12.334490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Nice, results are way faster and they are really close to 300 epochs, lets try to decrease it more, go with 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f34646df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:36:12.478538Z",
     "iopub.status.busy": "2023-12-22T12:36:12.477758Z",
     "iopub.status.idle": "2023-12-22T12:36:15.828233Z",
     "shell.execute_reply": "2023-12-22T12:36:15.827442Z"
    },
    "papermill": {
     "duration": 3.402007,
     "end_time": "2023-12-22T12:36:15.830631",
     "exception": false,
     "start_time": "2023-12-22T12:36:12.428624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37003\n",
      "Precision: 0.38049\n",
      "Recall: 0.37003\n",
      "F1 Score: 0.34679\n"
     ]
    }
   ],
   "source": [
    "input_dim=100     # how many Variables are in the dataset\n",
    "hidden_dim = 25 # hidden layers\n",
    "output_dim=3    # number of classes\n",
    "model=Net(input_dim,hidden_dim,output_dim)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate=0.1\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "n_epochs=5\n",
    "loss_list=[]\n",
    "\n",
    "#n_epochs\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "\n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        z=model.forward(x)\n",
    "        loss=criterion(z,y)\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.data)\n",
    "z=model.forward(x_val)\n",
    "max_indexes = torch.argmax(z, dim=1)\n",
    "y_pred = max_indexes.numpy()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Precision: {precision:.5f}')\n",
    "print(f'Recall: {recall:.5f}')\n",
    "print(f'F1 Score: {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efbb169",
   "metadata": {
    "papermill": {
     "duration": 0.049181,
     "end_time": "2023-12-22T12:36:15.927273",
     "exception": false,
     "start_time": "2023-12-22T12:36:15.878092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Too low, we will keep 11 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5ae4f",
   "metadata": {
    "papermill": {
     "duration": 0.047605,
     "end_time": "2023-12-22T12:36:16.022943",
     "exception": false,
     "start_time": "2023-12-22T12:36:15.975338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we proceed to the hyperparameters tuning section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e665d04",
   "metadata": {
    "papermill": {
     "duration": 0.047192,
     "end_time": "2023-12-22T12:36:16.120008",
     "exception": false,
     "start_time": "2023-12-22T12:36:16.072816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The main idea behind this step is to optimize the following parameters : input_dim (size of embedding),window, hidden_dim, batch_size and learning_rate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3984c3",
   "metadata": {
    "papermill": {
     "duration": 0.046787,
     "end_time": "2023-12-22T12:36:16.214608",
     "exception": false,
     "start_time": "2023-12-22T12:36:16.167821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What remains same same here is the model (number of hidden layers and dimension), the representation of each tweet (mean embedding) and number of epochs, criterion and optimizer, we will alter them in next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9a1de27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:36:16.311838Z",
     "iopub.status.busy": "2023-12-22T12:36:16.311421Z",
     "iopub.status.idle": "2023-12-22T12:51:28.729282Z",
     "shell.execute_reply": "2023-12-22T12:51:28.728145Z"
    },
    "papermill": {
     "duration": 912.522797,
     "end_time": "2023-12-22T12:51:28.785224",
     "exception": false,
     "start_time": "2023-12-22T12:36:16.262427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 12:36:17,703] A new study created in memory with name: no-name-1564f740-16f4-4213-87ae-52c8e4acc16a\n",
      "[I 2023-12-22 12:36:36,213] Trial 0 finished with value: 0.37786697247706424 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502}. Best is trial 0 with value: 0.37786697247706424.\n",
      "[I 2023-12-22 12:36:53,380] Trial 1 finished with value: 0.3918195718654434 and parameters: {'input_dim': 73, 'hidden_dim': 12, 'window_size': 9, 'b_size': 90, 'learning_rate': 0.2607024758370766}. Best is trial 1 with value: 0.3918195718654434.\n",
      "[I 2023-12-22 12:37:13,289] Trial 2 finished with value: 0.378631498470948 and parameters: {'input_dim': 53, 'hidden_dim': 49, 'window_size': 9, 'b_size': 52, 'learning_rate': 0.02310201887845294}. Best is trial 1 with value: 0.3918195718654434.\n",
      "[I 2023-12-22 12:37:32,160] Trial 3 finished with value: 0.3761467889908257 and parameters: {'input_dim': 77, 'hidden_dim': 22, 'window_size': 7, 'b_size': 73, 'learning_rate': 0.038234752246751866}. Best is trial 1 with value: 0.3918195718654434.\n",
      "[I 2023-12-22 12:37:51,186] Trial 4 finished with value: 0.37882262996941896 and parameters: {'input_dim': 142, 'hidden_dim': 15, 'window_size': 5, 'b_size': 67, 'learning_rate': 0.08168455894760163}. Best is trial 1 with value: 0.3918195718654434.\n",
      "[I 2023-12-22 12:38:09,863] Trial 5 finished with value: 0.36563455657492355 and parameters: {'input_dim': 168, 'hidden_dim': 18, 'window_size': 7, 'b_size': 89, 'learning_rate': 0.012385137298860933}. Best is trial 1 with value: 0.3918195718654434.\n",
      "[I 2023-12-22 12:38:26,472] Trial 6 finished with value: 0.371368501529052 and parameters: {'input_dim': 141, 'hidden_dim': 16, 'window_size': 3, 'b_size': 124, 'learning_rate': 0.8536189862866826}. Best is trial 1 with value: 0.3918195718654434.\n",
      "[I 2023-12-22 12:38:44,699] Trial 7 finished with value: 0.37767584097859325 and parameters: {'input_dim': 172, 'hidden_dim': 22, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695}. Best is trial 1 with value: 0.3918195718654434.\n",
      "[I 2023-12-22 12:39:00,452] Trial 8 finished with value: 0.3610474006116208 and parameters: {'input_dim': 68, 'hidden_dim': 30, 'window_size': 3, 'b_size': 120, 'learning_rate': 0.032927591344236166}. Best is trial 1 with value: 0.3918195718654434.\n",
      "[I 2023-12-22 12:39:19,259] Trial 9 finished with value: 0.3761467889908257 and parameters: {'input_dim': 150, 'hidden_dim': 22, 'window_size': 7, 'b_size': 85, 'learning_rate': 0.02342658105820405}. Best is trial 1 with value: 0.3918195718654434.\n",
      "[I 2023-12-22 12:39:41,326] Trial 10 finished with value: 0.3929663608562691 and parameters: {'input_dim': 103, 'hidden_dim': 10, 'window_size': 10, 'b_size': 33, 'learning_rate': 0.30039523655512246}. Best is trial 10 with value: 0.3929663608562691.\n",
      "[I 2023-12-22 12:40:02,051] Trial 11 finished with value: 0.39143730886850153 and parameters: {'input_dim': 102, 'hidden_dim': 10, 'window_size': 10, 'b_size': 40, 'learning_rate': 0.2997858219123054}. Best is trial 10 with value: 0.3929663608562691.\n",
      "[I 2023-12-22 12:40:24,646] Trial 12 finished with value: 0.37213302752293576 and parameters: {'input_dim': 95, 'hidden_dim': 10, 'window_size': 10, 'b_size': 37, 'learning_rate': 0.23835721993582848}. Best is trial 10 with value: 0.3929663608562691.\n",
      "[I 2023-12-22 12:40:42,670] Trial 13 finished with value: 0.3820718654434251 and parameters: {'input_dim': 117, 'hidden_dim': 38, 'window_size': 9, 'b_size': 108, 'learning_rate': 0.19575500799074522}. Best is trial 10 with value: 0.3929663608562691.\n",
      "[I 2023-12-22 12:41:02,308] Trial 14 finished with value: 0.371368501529052 and parameters: {'input_dim': 82, 'hidden_dim': 30, 'window_size': 9, 'b_size': 58, 'learning_rate': 0.5358828537716193}. Best is trial 10 with value: 0.3929663608562691.\n",
      "[I 2023-12-22 12:41:22,442] Trial 15 finished with value: 0.3637232415902141 and parameters: {'input_dim': 195, 'hidden_dim': 10, 'window_size': 5, 'b_size': 53, 'learning_rate': 0.14855681038337287}. Best is trial 10 with value: 0.3929663608562691.\n",
      "[I 2023-12-22 12:41:39,708] Trial 16 finished with value: 0.3922018348623853 and parameters: {'input_dim': 51, 'hidden_dim': 38, 'window_size': 10, 'b_size': 104, 'learning_rate': 0.3944479816467619}. Best is trial 10 with value: 0.3929663608562691.\n",
      "[I 2023-12-22 12:41:57,100] Trial 17 finished with value: 0.3943042813455658 and parameters: {'input_dim': 53, 'hidden_dim': 39, 'window_size': 10, 'b_size': 107, 'learning_rate': 0.4661724106311634}. Best is trial 17 with value: 0.3943042813455658.\n",
      "[I 2023-12-22 12:42:15,029] Trial 18 finished with value: 0.3876146788990826 and parameters: {'input_dim': 121, 'hidden_dim': 40, 'window_size': 8, 'b_size': 116, 'learning_rate': 0.611041312625025}. Best is trial 17 with value: 0.3943042813455658.\n",
      "[I 2023-12-22 12:42:33,446] Trial 19 finished with value: 0.39143730886850153 and parameters: {'input_dim': 87, 'hidden_dim': 44, 'window_size': 5, 'b_size': 71, 'learning_rate': 0.8094288207585482}. Best is trial 17 with value: 0.3943042813455658.\n",
      "[I 2023-12-22 12:42:51,615] Trial 20 finished with value: 0.39353975535168195 and parameters: {'input_dim': 62, 'hidden_dim': 32, 'window_size': 8, 'b_size': 79, 'learning_rate': 0.4022232854608565}. Best is trial 17 with value: 0.3943042813455658.\n",
      "[I 2023-12-22 12:43:12,234] Trial 21 finished with value: 0.38398318042813456 and parameters: {'input_dim': 62, 'hidden_dim': 31, 'window_size': 8, 'b_size': 44, 'learning_rate': 0.42812854347479706}. Best is trial 17 with value: 0.3943042813455658.\n",
      "[I 2023-12-22 12:43:33,534] Trial 22 finished with value: 0.3952599388379205 and parameters: {'input_dim': 64, 'hidden_dim': 34, 'window_size': 10, 'b_size': 32, 'learning_rate': 0.39700561395016903}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:43:50,439] Trial 23 finished with value: 0.36678134556574926 and parameters: {'input_dim': 60, 'hidden_dim': 33, 'window_size': 6, 'b_size': 128, 'learning_rate': 0.5946236498759332}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:44:06,758] Trial 24 finished with value: 0.3587538226299694 and parameters: {'input_dim': 66, 'hidden_dim': 34, 'window_size': 9, 'b_size': 109, 'learning_rate': 0.1420389417169953}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:44:24,655] Trial 25 finished with value: 0.3885703363914373 and parameters: {'input_dim': 50, 'hidden_dim': 26, 'window_size': 8, 'b_size': 77, 'learning_rate': 0.4154324324973132}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:44:43,803] Trial 26 finished with value: 0.35856269113149847 and parameters: {'input_dim': 86, 'hidden_dim': 42, 'window_size': 10, 'b_size': 63, 'learning_rate': 0.9606261224252225}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:45:00,676] Trial 27 finished with value: 0.38321865443425074 and parameters: {'input_dim': 73, 'hidden_dim': 36, 'window_size': 6, 'b_size': 100, 'learning_rate': 0.3516224685983755}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:45:19,349] Trial 28 finished with value: 0.38685015290519875 and parameters: {'input_dim': 93, 'hidden_dim': 26, 'window_size': 9, 'b_size': 81, 'learning_rate': 0.5802904282306662}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:45:37,561] Trial 29 finished with value: 0.3900993883792049 and parameters: {'input_dim': 111, 'hidden_dim': 45, 'window_size': 8, 'b_size': 94, 'learning_rate': 0.21588206679540553}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:45:55,287] Trial 30 finished with value: 0.3948776758409786 and parameters: {'input_dim': 59, 'hidden_dim': 27, 'window_size': 10, 'b_size': 114, 'learning_rate': 0.45513837104079763}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:46:12,578] Trial 31 finished with value: 0.39392201834862384 and parameters: {'input_dim': 60, 'hidden_dim': 27, 'window_size': 10, 'b_size': 114, 'learning_rate': 0.4386860085311703}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:46:30,075] Trial 32 finished with value: 0.39143730886850153 and parameters: {'input_dim': 74, 'hidden_dim': 27, 'window_size': 10, 'b_size': 114, 'learning_rate': 0.7272310548320275}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:46:47,062] Trial 33 finished with value: 0.3862767584097859 and parameters: {'input_dim': 59, 'hidden_dim': 35, 'window_size': 9, 'b_size': 113, 'learning_rate': 0.4848406937591766}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:47:04,160] Trial 34 finished with value: 0.38799694189602446 and parameters: {'input_dim': 50, 'hidden_dim': 26, 'window_size': 10, 'b_size': 121, 'learning_rate': 0.3270615813852837}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:47:21,555] Trial 35 finished with value: 0.3753822629969419 and parameters: {'input_dim': 78, 'hidden_dim': 28, 'window_size': 9, 'b_size': 103, 'learning_rate': 0.7100336488288294}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:47:37,781] Trial 36 finished with value: 0.38876146788990823 and parameters: {'input_dim': 70, 'hidden_dim': 23, 'window_size': 10, 'b_size': 128, 'learning_rate': 0.5073438178337288}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:47:55,478] Trial 37 finished with value: 0.3816896024464832 and parameters: {'input_dim': 57, 'hidden_dim': 37, 'window_size': 9, 'b_size': 94, 'learning_rate': 0.2755306452695145}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:48:13,292] Trial 38 finished with value: 0.38321865443425074 and parameters: {'input_dim': 93, 'hidden_dim': 19, 'window_size': 10, 'b_size': 110, 'learning_rate': 0.8932177244341322}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:48:30,206] Trial 39 finished with value: 0.38646788990825687 and parameters: {'input_dim': 130, 'hidden_dim': 46, 'window_size': 4, 'b_size': 119, 'learning_rate': 0.6641245409592809}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:48:47,492] Trial 40 finished with value: 0.38876146788990823 and parameters: {'input_dim': 68, 'hidden_dim': 50, 'window_size': 9, 'b_size': 90, 'learning_rate': 0.3793109185736262}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:49:07,692] Trial 41 finished with value: 0.39353975535168195 and parameters: {'input_dim': 61, 'hidden_dim': 33, 'window_size': 10, 'b_size': 47, 'learning_rate': 0.47142516986860294}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:49:24,870] Trial 42 finished with value: 0.37155963302752293 and parameters: {'input_dim': 57, 'hidden_dim': 32, 'window_size': 7, 'b_size': 105, 'learning_rate': 0.35936005600112453}. Best is trial 22 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 12:49:42,253] Trial 43 finished with value: 0.3958333333333333 and parameters: {'input_dim': 76, 'hidden_dim': 29, 'window_size': 8, 'b_size': 96, 'learning_rate': 0.26553396204071694}. Best is trial 43 with value: 0.3958333333333333.\n",
      "[I 2023-12-22 12:49:59,590] Trial 44 finished with value: 0.3893348623853211 and parameters: {'input_dim': 78, 'hidden_dim': 29, 'window_size': 10, 'b_size': 98, 'learning_rate': 0.253928764876931}. Best is trial 43 with value: 0.3958333333333333.\n",
      "[I 2023-12-22 12:50:16,823] Trial 45 finished with value: 0.3944954128440367 and parameters: {'input_dim': 66, 'hidden_dim': 23, 'window_size': 8, 'b_size': 86, 'learning_rate': 0.30161194380205064}. Best is trial 43 with value: 0.3958333333333333.\n",
      "[I 2023-12-22 12:50:34,413] Trial 46 finished with value: 0.33811162079510704 and parameters: {'input_dim': 84, 'hidden_dim': 23, 'window_size': 6, 'b_size': 87, 'learning_rate': 0.18757748526758508}. Best is trial 43 with value: 0.3958333333333333.\n",
      "[I 2023-12-22 12:50:50,767] Trial 47 finished with value: 0.3650611620795107 and parameters: {'input_dim': 68, 'hidden_dim': 24, 'window_size': 7, 'b_size': 96, 'learning_rate': 0.2953533203120104}. Best is trial 43 with value: 0.3958333333333333.\n",
      "[I 2023-12-22 12:51:10,271] Trial 48 finished with value: 0.3755733944954128 and parameters: {'input_dim': 159, 'hidden_dim': 19, 'window_size': 8, 'b_size': 83, 'learning_rate': 0.2917883941764053}. Best is trial 43 with value: 0.3958333333333333.\n",
      "[I 2023-12-22 12:51:28,723] Trial 49 finished with value: 0.39258409785932724 and parameters: {'input_dim': 99, 'hidden_dim': 40, 'window_size': 7, 'b_size': 71, 'learning_rate': 0.24423438411281498}. Best is trial 43 with value: 0.3958333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 76, 'hidden_dim': 29, 'window_size': 8, 'b_size': 96, 'learning_rate': 0.26553396204071694}\n",
      "Best Accuracy: 0.3958333333333333\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,D_in,H,D_out):\n",
    "        super(Net,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.linear2=nn.Linear(H,D_out)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.sigmoid(self.linear1(x))  \n",
    "        x=self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    model = Net(input_dim, hidden_dim, output_dim)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9510d2c",
   "metadata": {
    "papermill": {
     "duration": 0.052299,
     "end_time": "2023-12-22T12:51:28.890048",
     "exception": false,
     "start_time": "2023-12-22T12:51:28.837749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we will check how many hidden layers to use, we will use the same idea behind optuna and try 3 and 5 hidden layers, we also define some functions to make coding easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4845d354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:51:28.998657Z",
     "iopub.status.busy": "2023-12-22T12:51:28.997942Z",
     "iopub.status.idle": "2023-12-22T13:11:05.357937Z",
     "shell.execute_reply": "2023-12-22T13:11:05.356658Z"
    },
    "papermill": {
     "duration": 1176.472913,
     "end_time": "2023-12-22T13:11:05.415868",
     "exception": false,
     "start_time": "2023-12-22T12:51:28.942955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 12:51:29,026] A new study created in memory with name: no-name-b9250b15-813d-408e-b518-50080e077682\n",
      "[I 2023-12-22 12:51:51,788] Trial 0 finished with value: 0.3891784820683904 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502}. Best is trial 0 with value: 0.3891784820683904.\n",
      "[I 2023-12-22 12:52:12,670] Trial 1 finished with value: 0.39055115373922716 and parameters: {'input_dim': 73, 'hidden_dim': 12, 'window_size': 9, 'b_size': 90, 'learning_rate': 0.2607024758370766}. Best is trial 1 with value: 0.39055115373922716.\n",
      "[I 2023-12-22 12:52:39,977] Trial 2 finished with value: 0.38778843480678343 and parameters: {'input_dim': 53, 'hidden_dim': 49, 'window_size': 9, 'b_size': 52, 'learning_rate': 0.02310201887845294}. Best is trial 1 with value: 0.39055115373922716.\n",
      "[I 2023-12-22 12:53:03,509] Trial 3 finished with value: 0.3890394773422297 and parameters: {'input_dim': 77, 'hidden_dim': 22, 'window_size': 7, 'b_size': 73, 'learning_rate': 0.038234752246751866}. Best is trial 1 with value: 0.39055115373922716.\n",
      "[I 2023-12-22 12:53:27,941] Trial 4 finished with value: 0.3907944120100083 and parameters: {'input_dim': 142, 'hidden_dim': 15, 'window_size': 5, 'b_size': 67, 'learning_rate': 0.08168455894760163}. Best is trial 4 with value: 0.3907944120100083.\n",
      "[I 2023-12-22 12:53:50,612] Trial 5 finished with value: 0.38325340561579097 and parameters: {'input_dim': 168, 'hidden_dim': 18, 'window_size': 7, 'b_size': 89, 'learning_rate': 0.012385137298860933}. Best is trial 4 with value: 0.3907944120100083.\n",
      "[I 2023-12-22 12:54:10,688] Trial 6 finished with value: 0.38429594106199616 and parameters: {'input_dim': 141, 'hidden_dim': 16, 'window_size': 3, 'b_size': 124, 'learning_rate': 0.8536189862866826}. Best is trial 4 with value: 0.3907944120100083.\n",
      "[I 2023-12-22 12:54:33,105] Trial 7 finished with value: 0.3941305254378649 and parameters: {'input_dim': 172, 'hidden_dim': 22, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 12:54:52,874] Trial 8 finished with value: 0.38667639699749795 and parameters: {'input_dim': 68, 'hidden_dim': 30, 'window_size': 3, 'b_size': 120, 'learning_rate': 0.032927591344236166}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 12:55:16,728] Trial 9 finished with value: 0.38540797887128164 and parameters: {'input_dim': 150, 'hidden_dim': 22, 'window_size': 7, 'b_size': 85, 'learning_rate': 0.02342658105820405}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 12:55:51,466] Trial 10 finished with value: 0.39145468445927156 and parameters: {'input_dim': 197, 'hidden_dim': 38, 'window_size': 5, 'b_size': 33, 'learning_rate': 0.10745871100472208}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 12:56:24,909] Trial 11 finished with value: 0.38745829858215186 and parameters: {'input_dim': 191, 'hidden_dim': 38, 'window_size': 5, 'b_size': 40, 'learning_rate': 0.09933513765086906}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 12:56:47,821] Trial 12 finished with value: 0.3836182930219627 and parameters: {'input_dim': 200, 'hidden_dim': 34, 'window_size': 5, 'b_size': 109, 'learning_rate': 0.17819891594836498}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 12:57:23,491] Trial 13 finished with value: 0.3899951348345844 and parameters: {'input_dim': 176, 'hidden_dim': 42, 'window_size': 4, 'b_size': 33, 'learning_rate': 0.0595920613164576}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 12:57:46,408] Trial 14 finished with value: 0.3869891576313595 and parameters: {'input_dim': 172, 'hidden_dim': 29, 'window_size': 4, 'b_size': 105, 'learning_rate': 0.18000554787310746}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 12:58:12,199] Trial 15 finished with value: 0.39048165137614677 and parameters: {'input_dim': 113, 'hidden_dim': 25, 'window_size': 4, 'b_size': 58, 'learning_rate': 0.06296431661636057}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 12:58:36,236] Trial 16 finished with value: 0.38858771198220743 and parameters: {'input_dim': 185, 'hidden_dim': 42, 'window_size': 6, 'b_size': 104, 'learning_rate': 0.14071939991903698}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 12:59:05,510] Trial 17 finished with value: 0.38700653322212947 and parameters: {'input_dim': 157, 'hidden_dim': 34, 'window_size': 3, 'b_size': 49, 'learning_rate': 0.2993620086989368}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 12:59:30,287] Trial 18 finished with value: 0.39152418682235196 and parameters: {'input_dim': 200, 'hidden_dim': 30, 'window_size': 6, 'b_size': 76, 'learning_rate': 0.043822823657896484}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 12:59:54,890] Trial 19 finished with value: 0.3926536002224076 and parameters: {'input_dim': 123, 'hidden_dim': 27, 'window_size': 10, 'b_size': 74, 'learning_rate': 0.047441323130562985}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 13:00:20,991] Trial 20 finished with value: 0.38373992215735336 and parameters: {'input_dim': 127, 'hidden_dim': 25, 'window_size': 10, 'b_size': 64, 'learning_rate': 0.0102206905470606}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 13:00:45,207] Trial 21 finished with value: 0.3857381150959132 and parameters: {'input_dim': 93, 'hidden_dim': 29, 'window_size': 10, 'b_size': 77, 'learning_rate': 0.04580878602649989}. Best is trial 7 with value: 0.3941305254378649.\n",
      "[I 2023-12-22 13:01:09,417] Trial 22 finished with value: 0.39505143174867946 and parameters: {'input_dim': 127, 'hidden_dim': 22, 'window_size': 8, 'b_size': 80, 'learning_rate': 0.061044068827625475}. Best is trial 22 with value: 0.39505143174867946.\n",
      "[I 2023-12-22 13:01:32,187] Trial 23 finished with value: 0.3880316930775647 and parameters: {'input_dim': 124, 'hidden_dim': 20, 'window_size': 9, 'b_size': 95, 'learning_rate': 0.06373176718891958}. Best is trial 22 with value: 0.39505143174867946.\n",
      "[I 2023-12-22 13:01:53,301] Trial 24 finished with value: 0.39326174589936047 and parameters: {'input_dim': 98, 'hidden_dim': 26, 'window_size': 8, 'b_size': 100, 'learning_rate': 0.07237731180250245}. Best is trial 22 with value: 0.39505143174867946.\n",
      "[I 2023-12-22 13:02:13,745] Trial 25 finished with value: 0.38643313872671675 and parameters: {'input_dim': 103, 'hidden_dim': 11, 'window_size': 8, 'b_size': 98, 'learning_rate': 0.08630776283520152}. Best is trial 22 with value: 0.39505143174867946.\n",
      "[I 2023-12-22 13:02:33,881] Trial 26 finished with value: 0.38738879621907146 and parameters: {'input_dim': 84, 'hidden_dim': 24, 'window_size': 8, 'b_size': 113, 'learning_rate': 0.07306604028787635}. Best is trial 22 with value: 0.39505143174867946.\n",
      "[I 2023-12-22 13:02:54,072] Trial 27 finished with value: 0.3924450931331665 and parameters: {'input_dim': 137, 'hidden_dim': 20, 'window_size': 8, 'b_size': 117, 'learning_rate': 0.12547957183629055}. Best is trial 22 with value: 0.39505143174867946.\n",
      "[I 2023-12-22 13:03:17,133] Trial 28 finished with value: 0.38683277731442867 and parameters: {'input_dim': 159, 'hidden_dim': 15, 'window_size': 6, 'b_size': 100, 'learning_rate': 0.03164787083882244}. Best is trial 22 with value: 0.39505143174867946.\n",
      "[I 2023-12-22 13:03:36,891] Trial 29 finished with value: 0.3825062552126772 and parameters: {'input_dim': 102, 'hidden_dim': 19, 'window_size': 9, 'b_size': 128, 'learning_rate': 0.01683848556284195}. Best is trial 22 with value: 0.39505143174867946.\n",
      "[I 2023-12-22 13:03:59,795] Trial 30 finished with value: 0.3904642757853767 and parameters: {'input_dim': 115, 'hidden_dim': 34, 'window_size': 7, 'b_size': 83, 'learning_rate': 0.05422751103177613}. Best is trial 22 with value: 0.39505143174867946.\n",
      "[I 2023-12-22 13:04:24,847] Trial 31 finished with value: 0.39188907422852376 and parameters: {'input_dim': 126, 'hidden_dim': 27, 'window_size': 10, 'b_size': 70, 'learning_rate': 0.04590024930953055}. Best is trial 22 with value: 0.39505143174867946.\n",
      "[I 2023-12-22 13:04:46,728] Trial 32 finished with value: 0.3849562135112594 and parameters: {'input_dim': 115, 'hidden_dim': 23, 'window_size': 9, 'b_size': 92, 'learning_rate': 0.07956320532421239}. Best is trial 22 with value: 0.39505143174867946.\n",
      "[I 2023-12-22 13:05:09,337] Trial 33 finished with value: 0.3962155963302752 and parameters: {'input_dim': 57, 'hidden_dim': 26, 'window_size': 8, 'b_size': 83, 'learning_rate': 0.029693622822662944}. Best is trial 33 with value: 0.3962155963302752.\n",
      "[I 2023-12-22 13:05:31,089] Trial 34 finished with value: 0.38733666944676115 and parameters: {'input_dim': 51, 'hidden_dim': 26, 'window_size': 8, 'b_size': 87, 'learning_rate': 0.03237359600965129}. Best is trial 33 with value: 0.3962155963302752.\n",
      "[I 2023-12-22 13:05:53,662] Trial 35 finished with value: 0.38636363636363635 and parameters: {'input_dim': 66, 'hidden_dim': 32, 'window_size': 9, 'b_size': 80, 'learning_rate': 0.025545727107266637}. Best is trial 33 with value: 0.3962155963302752.\n",
      "[I 2023-12-22 13:06:15,726] Trial 36 finished with value: 0.38426118988045593 and parameters: {'input_dim': 90, 'hidden_dim': 17, 'window_size': 7, 'b_size': 95, 'learning_rate': 0.03427794072611337}. Best is trial 33 with value: 0.3962155963302752.\n",
      "[I 2023-12-22 13:06:36,547] Trial 37 finished with value: 0.38076869613566866 and parameters: {'input_dim': 61, 'hidden_dim': 13, 'window_size': 8, 'b_size': 103, 'learning_rate': 0.05747141842434589}. Best is trial 33 with value: 0.3962155963302752.\n",
      "[I 2023-12-22 13:07:00,922] Trial 38 finished with value: 0.38716291353906035 and parameters: {'input_dim': 79, 'hidden_dim': 21, 'window_size': 7, 'b_size': 63, 'learning_rate': 0.016678308915580045}. Best is trial 33 with value: 0.3962155963302752.\n",
      "[I 2023-12-22 13:07:23,467] Trial 39 finished with value: 0.3880664442591048 and parameters: {'input_dim': 93, 'hidden_dim': 22, 'window_size': 8, 'b_size': 89, 'learning_rate': 0.026554485207490253}. Best is trial 33 with value: 0.3962155963302752.\n",
      "[I 2023-12-22 13:07:45,792] Trial 40 finished with value: 0.39289685849318884 and parameters: {'input_dim': 150, 'hidden_dim': 13, 'window_size': 8, 'b_size': 92, 'learning_rate': 0.039413832947595845}. Best is trial 33 with value: 0.3962155963302752.\n",
      "[I 2023-12-22 13:08:07,763] Trial 41 finished with value: 0.3821413678065054 and parameters: {'input_dim': 137, 'hidden_dim': 12, 'window_size': 8, 'b_size': 81, 'learning_rate': 0.03855806387442563}. Best is trial 33 with value: 0.3962155963302752.\n",
      "[I 2023-12-22 13:08:30,776] Trial 42 finished with value: 0.3811162079510703 and parameters: {'input_dim': 182, 'hidden_dim': 10, 'window_size': 9, 'b_size': 92, 'learning_rate': 0.06743143235518523}. Best is trial 33 with value: 0.3962155963302752.\n",
      "[I 2023-12-22 13:08:52,567] Trial 43 finished with value: 0.3963893522379761 and parameters: {'input_dim': 151, 'hidden_dim': 14, 'window_size': 7, 'b_size': 110, 'learning_rate': 0.08691686968694587}. Best is trial 43 with value: 0.3963893522379761.\n",
      "[I 2023-12-22 13:09:13,759] Trial 44 finished with value: 0.3851820961912705 and parameters: {'input_dim': 163, 'hidden_dim': 18, 'window_size': 7, 'b_size': 110, 'learning_rate': 0.08645971724475297}. Best is trial 43 with value: 0.3963893522379761.\n",
      "[I 2023-12-22 13:09:35,125] Trial 45 finished with value: 0.3878753127606338 and parameters: {'input_dim': 145, 'hidden_dim': 15, 'window_size': 6, 'b_size': 114, 'learning_rate': 0.09976214700889333}. Best is trial 43 with value: 0.3963893522379761.\n",
      "[I 2023-12-22 13:09:56,887] Trial 46 finished with value: 0.3876320544898526 and parameters: {'input_dim': 151, 'hidden_dim': 23, 'window_size': 7, 'b_size': 122, 'learning_rate': 0.05292322251173273}. Best is trial 43 with value: 0.3963893522379761.\n",
      "[I 2023-12-22 13:10:18,439] Trial 47 finished with value: 0.3877536836252433 and parameters: {'input_dim': 167, 'hidden_dim': 28, 'window_size': 7, 'b_size': 108, 'learning_rate': 0.07298466071281301}. Best is trial 43 with value: 0.3963893522379761.\n",
      "[I 2023-12-22 13:10:40,615] Trial 48 finished with value: 0.3842090631081457 and parameters: {'input_dim': 133, 'hidden_dim': 31, 'window_size': 6, 'b_size': 99, 'learning_rate': 0.1086524470572418}. Best is trial 43 with value: 0.3963893522379761.\n",
      "[I 2023-12-22 13:11:05,348] Trial 49 finished with value: 0.39107242146232973 and parameters: {'input_dim': 177, 'hidden_dim': 17, 'window_size': 9, 'b_size': 84, 'learning_rate': 0.05247076567742347}. Best is trial 43 with value: 0.3963893522379761.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 151, 'hidden_dim': 14, 'window_size': 7, 'b_size': 110, 'learning_rate': 0.08691686968694587}\n",
      "Best Accuracy: 0.3963893522379761\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, H3, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.bn1 = nn.BatchNorm1d(H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.bn2 = nn.BatchNorm1d(H2)\n",
    "        self.linear3 = nn.Linear(H2, H3)\n",
    "        self.bn3 = nn.BatchNorm1d(H3)\n",
    "        self.linear4 = nn.Linear(H3, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.linear1(x)))\n",
    "        x = F.relu(self.bn2(self.linear2(x)))\n",
    "        x = F.relu(self.bn3(self.linear3(x)))\n",
    "        x = self.linear4(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, trainloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    for x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model.forward(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def evaluate_model(model, x_val, y_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z_val = model.forward(x_val)\n",
    "        max_indexes = torch.argmax(z_val, dim=1)\n",
    "        y_pred = max_indexes.numpy()\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    model = Net(input_dim, 3*hidden_dim, 2*hidden_dim, hidden_dim, 3)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)  # Dynamic learning rate\n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    accuracy_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_model(model, trainloader, optimizer, criterion)\n",
    "        scheduler.step()  # Adjust the learning rate dynamically\n",
    "        accuracy = evaluate_model(model, torch.from_numpy(x_val), y_val)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    return np.mean(accuracy_list)\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d9ebc",
   "metadata": {
    "papermill": {
     "duration": 0.056989,
     "end_time": "2023-12-22T13:11:05.530744",
     "exception": false,
     "start_time": "2023-12-22T13:11:05.473755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Same as above but with 5 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8518155c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T13:11:05.648463Z",
     "iopub.status.busy": "2023-12-22T13:11:05.647685Z",
     "iopub.status.idle": "2023-12-22T13:36:09.257379Z",
     "shell.execute_reply": "2023-12-22T13:36:09.256291Z"
    },
    "papermill": {
     "duration": 1503.732969,
     "end_time": "2023-12-22T13:36:09.321298",
     "exception": false,
     "start_time": "2023-12-22T13:11:05.588329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 13:11:05,677] A new study created in memory with name: no-name-ef3ae538-6041-4cfd-b825-032897169c12\n",
      "[I 2023-12-22 13:11:32,443] Trial 0 finished with value: 0.37943077564637195 and parameters: {'input_dim': 106, 'hidden_dim': 29, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502}. Best is trial 0 with value: 0.37943077564637195.\n",
      "[I 2023-12-22 13:11:55,994] Trial 1 finished with value: 0.3807339449541285 and parameters: {'input_dim': 73, 'hidden_dim': 7, 'window_size': 9, 'b_size': 90, 'learning_rate': 0.2607024758370766}. Best is trial 1 with value: 0.3807339449541285.\n",
      "[I 2023-12-22 13:12:30,030] Trial 2 finished with value: 0.3783013622463164 and parameters: {'input_dim': 53, 'hidden_dim': 30, 'window_size': 9, 'b_size': 52, 'learning_rate': 0.02310201887845294}. Best is trial 1 with value: 0.3807339449541285.\n",
      "[I 2023-12-22 13:12:56,442] Trial 3 finished with value: 0.37972616068946347 and parameters: {'input_dim': 77, 'hidden_dim': 13, 'window_size': 7, 'b_size': 73, 'learning_rate': 0.038234752246751866}. Best is trial 1 with value: 0.3807339449541285.\n",
      "[I 2023-12-22 13:13:23,900] Trial 4 finished with value: 0.38645051431748684 and parameters: {'input_dim': 142, 'hidden_dim': 9, 'window_size': 5, 'b_size': 67, 'learning_rate': 0.08168455894760163}. Best is trial 4 with value: 0.38645051431748684.\n",
      "[I 2023-12-22 13:13:49,060] Trial 5 finished with value: 0.3839484292465944 and parameters: {'input_dim': 168, 'hidden_dim': 10, 'window_size': 7, 'b_size': 89, 'learning_rate': 0.012385137298860933}. Best is trial 4 with value: 0.38645051431748684.\n",
      "[I 2023-12-22 13:14:11,910] Trial 6 finished with value: 0.37845774256324716 and parameters: {'input_dim': 141, 'hidden_dim': 10, 'window_size': 3, 'b_size': 124, 'learning_rate': 0.8536189862866826}. Best is trial 4 with value: 0.38645051431748684.\n",
      "[I 2023-12-22 13:14:36,971] Trial 7 finished with value: 0.38257575757575757 and parameters: {'input_dim': 172, 'hidden_dim': 13, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695}. Best is trial 4 with value: 0.38645051431748684.\n",
      "[I 2023-12-22 13:14:59,283] Trial 8 finished with value: 0.3793960244648318 and parameters: {'input_dim': 68, 'hidden_dim': 18, 'window_size': 3, 'b_size': 120, 'learning_rate': 0.032927591344236166}. Best is trial 4 with value: 0.38645051431748684.\n",
      "[I 2023-12-22 13:15:26,034] Trial 9 finished with value: 0.36890116763969977 and parameters: {'input_dim': 150, 'hidden_dim': 13, 'window_size': 7, 'b_size': 85, 'learning_rate': 0.02342658105820405}. Best is trial 4 with value: 0.38645051431748684.\n",
      "[I 2023-12-22 13:16:08,057] Trial 10 finished with value: 0.3842264386989157 and parameters: {'input_dim': 194, 'hidden_dim': 23, 'window_size': 5, 'b_size': 33, 'learning_rate': 0.13527769084615443}. Best is trial 4 with value: 0.38645051431748684.\n",
      "[I 2023-12-22 13:16:48,406] Trial 11 finished with value: 0.3808729496802892 and parameters: {'input_dim': 187, 'hidden_dim': 23, 'window_size': 5, 'b_size': 38, 'learning_rate': 0.12689081933149193}. Best is trial 4 with value: 0.38645051431748684.\n",
      "[I 2023-12-22 13:17:19,960] Trial 12 finished with value: 0.3889004726160689 and parameters: {'input_dim': 200, 'hidden_dim': 21, 'window_size': 5, 'b_size': 60, 'learning_rate': 0.10954467894569535}. Best is trial 12 with value: 0.3889004726160689.\n",
      "[I 2023-12-22 13:17:48,401] Trial 13 finished with value: 0.38957812065610226 and parameters: {'input_dim': 115, 'hidden_dim': 20, 'window_size': 5, 'b_size': 65, 'learning_rate': 0.06713824792641308}. Best is trial 13 with value: 0.38957812065610226.\n",
      "[I 2023-12-22 13:18:18,470] Trial 14 finished with value: 0.38592924659438416 and parameters: {'input_dim': 111, 'hidden_dim': 21, 'window_size': 5, 'b_size': 58, 'learning_rate': 0.061064672010183216}. Best is trial 13 with value: 0.38957812065610226.\n",
      "[I 2023-12-22 13:18:50,031] Trial 15 finished with value: 0.38876146788990823 and parameters: {'input_dim': 104, 'hidden_dim': 18, 'window_size': 4, 'b_size': 50, 'learning_rate': 0.20975457910271644}. Best is trial 13 with value: 0.38957812065610226.\n",
      "[I 2023-12-22 13:19:20,275] Trial 16 finished with value: 0.3831839032527106 and parameters: {'input_dim': 132, 'hidden_dim': 27, 'window_size': 6, 'b_size': 65, 'learning_rate': 0.054552282223754536}. Best is trial 13 with value: 0.38957812065610226.\n",
      "[I 2023-12-22 13:19:54,829] Trial 17 finished with value: 0.3893696135668613 and parameters: {'input_dim': 119, 'hidden_dim': 20, 'window_size': 6, 'b_size': 45, 'learning_rate': 0.2335962038670087}. Best is trial 13 with value: 0.38957812065610226.\n",
      "[I 2023-12-22 13:20:28,138] Trial 18 finished with value: 0.38351403947734225 and parameters: {'input_dim': 93, 'hidden_dim': 16, 'window_size': 6, 'b_size': 44, 'learning_rate': 0.30360322629674164}. Best is trial 13 with value: 0.38957812065610226.\n",
      "[I 2023-12-22 13:20:57,276] Trial 19 finished with value: 0.387892688351404 and parameters: {'input_dim': 121, 'hidden_dim': 25, 'window_size': 10, 'b_size': 73, 'learning_rate': 0.4257750977865393}. Best is trial 13 with value: 0.38957812065610226.\n",
      "[I 2023-12-22 13:21:31,343] Trial 20 finished with value: 0.3788747567417292 and parameters: {'input_dim': 90, 'hidden_dim': 17, 'window_size': 4, 'b_size': 43, 'learning_rate': 0.1711278085758797}. Best is trial 13 with value: 0.38957812065610226.\n",
      "[I 2023-12-22 13:22:02,787] Trial 21 finished with value: 0.3854427300528218 and parameters: {'input_dim': 124, 'hidden_dim': 20, 'window_size': 6, 'b_size': 56, 'learning_rate': 0.10766071937007392}. Best is trial 13 with value: 0.38957812065610226.\n",
      "[I 2023-12-22 13:22:32,669] Trial 22 finished with value: 0.3839484292465944 and parameters: {'input_dim': 159, 'hidden_dim': 21, 'window_size': 4, 'b_size': 66, 'learning_rate': 0.10844763985014531}. Best is trial 13 with value: 0.38957812065610226.\n",
      "[I 2023-12-22 13:22:59,422] Trial 23 finished with value: 0.3857381150959133 and parameters: {'input_dim': 117, 'hidden_dim': 24, 'window_size': 6, 'b_size': 77, 'learning_rate': 0.17380905305512573}. Best is trial 13 with value: 0.38957812065610226.\n",
      "[I 2023-12-22 13:23:29,154] Trial 24 finished with value: 0.38745829858215175 and parameters: {'input_dim': 132, 'hidden_dim': 20, 'window_size': 4, 'b_size': 61, 'learning_rate': 0.0790207050135058}. Best is trial 13 with value: 0.38957812065610226.\n",
      "[I 2023-12-22 13:24:04,644] Trial 25 finished with value: 0.3908465387823186 and parameters: {'input_dim': 98, 'hidden_dim': 26, 'window_size': 5, 'b_size': 45, 'learning_rate': 0.05219948621698273}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:24:41,087] Trial 26 finished with value: 0.38511259382819013 and parameters: {'input_dim': 94, 'hidden_dim': 27, 'window_size': 8, 'b_size': 46, 'learning_rate': 0.0400000916727017}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:25:20,988] Trial 27 finished with value: 0.38910897970531 and parameters: {'input_dim': 85, 'hidden_dim': 15, 'window_size': 6, 'b_size': 34, 'learning_rate': 0.06255759461368385}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:25:45,452] Trial 28 finished with value: 0.38419168751737565 and parameters: {'input_dim': 104, 'hidden_dim': 27, 'window_size': 5, 'b_size': 108, 'learning_rate': 0.057998220294673955}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:26:23,090] Trial 29 finished with value: 0.38612037809285515 and parameters: {'input_dim': 110, 'hidden_dim': 25, 'window_size': 8, 'b_size': 39, 'learning_rate': 0.04704271678092943}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:26:55,920] Trial 30 finished with value: 0.38940436474840145 and parameters: {'input_dim': 56, 'hidden_dim': 23, 'window_size': 7, 'b_size': 50, 'learning_rate': 0.029108728172289045}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:27:28,550] Trial 31 finished with value: 0.38448707256046705 and parameters: {'input_dim': 50, 'hidden_dim': 23, 'window_size': 7, 'b_size': 51, 'learning_rate': 0.029561947825290986}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:28:01,427] Trial 32 finished with value: 0.3847998331943286 and parameters: {'input_dim': 66, 'hidden_dim': 28, 'window_size': 6, 'b_size': 48, 'learning_rate': 0.04302000163085837}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:28:32,470] Trial 33 finished with value: 0.3847998331943286 and parameters: {'input_dim': 61, 'hidden_dim': 19, 'window_size': 8, 'b_size': 55, 'learning_rate': 0.02821739382128452}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:29:09,199] Trial 34 finished with value: 0.3848172087850987 and parameters: {'input_dim': 81, 'hidden_dim': 25, 'window_size': 9, 'b_size': 40, 'learning_rate': 0.01607482073869239}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:29:41,589] Trial 35 finished with value: 0.38208924103419517 and parameters: {'input_dim': 99, 'hidden_dim': 30, 'window_size': 7, 'b_size': 52, 'learning_rate': 0.01804522706138418}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:30:09,432] Trial 36 finished with value: 0.38547748123436193 and parameters: {'input_dim': 133, 'hidden_dim': 22, 'window_size': 7, 'b_size': 72, 'learning_rate': 0.03372011290401057}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:30:36,204] Trial 37 finished with value: 0.38973450097303314 and parameters: {'input_dim': 58, 'hidden_dim': 6, 'window_size': 5, 'b_size': 63, 'learning_rate': 0.0804384372555013}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:31:00,676] Trial 38 finished with value: 0.3837051709758132 and parameters: {'input_dim': 60, 'hidden_dim': 6, 'window_size': 4, 'b_size': 79, 'learning_rate': 0.0766981514535702}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:31:25,729] Trial 39 finished with value: 0.3870412844036697 and parameters: {'input_dim': 75, 'hidden_dim': 8, 'window_size': 5, 'b_size': 69, 'learning_rate': 0.04568393736069084}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:31:50,116] Trial 40 finished with value: 0.377224075618571 and parameters: {'input_dim': 57, 'hidden_dim': 14, 'window_size': 4, 'b_size': 86, 'learning_rate': 0.02238986365128022}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:32:17,719] Trial 41 finished with value: 0.38598137336669447 and parameters: {'input_dim': 69, 'hidden_dim': 19, 'window_size': 5, 'b_size': 62, 'learning_rate': 0.08543559855390456}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:32:47,390] Trial 42 finished with value: 0.38603350013900467 and parameters: {'input_dim': 114, 'hidden_dim': 10, 'window_size': 6, 'b_size': 55, 'learning_rate': 0.06743143235518523}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:33:19,943] Trial 43 finished with value: 0.3873192938559912 and parameters: {'input_dim': 82, 'hidden_dim': 24, 'window_size': 5, 'b_size': 46, 'learning_rate': 0.0480029111098745}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:33:56,691] Trial 44 finished with value: 0.38910897970531 and parameters: {'input_dim': 140, 'hidden_dim': 12, 'window_size': 6, 'b_size': 37, 'learning_rate': 0.09306801910210123}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:34:30,891] Trial 45 finished with value: 0.38559911036975264 and parameters: {'input_dim': 53, 'hidden_dim': 17, 'window_size': 7, 'b_size': 42, 'learning_rate': 0.03651210826938197}. Best is trial 25 with value: 0.3908465387823186.\n",
      "[I 2023-12-22 13:34:56,023] Trial 46 finished with value: 0.3916110647762024 and parameters: {'input_dim': 99, 'hidden_dim': 22, 'window_size': 5, 'b_size': 94, 'learning_rate': 0.07016309281476811}. Best is trial 46 with value: 0.3916110647762024.\n",
      "[I 2023-12-22 13:35:19,450] Trial 47 finished with value: 0.3875625521267723 and parameters: {'input_dim': 72, 'hidden_dim': 22, 'window_size': 3, 'b_size': 104, 'learning_rate': 0.052087311566062555}. Best is trial 46 with value: 0.3916110647762024.\n",
      "[I 2023-12-22 13:35:44,670] Trial 48 finished with value: 0.38182860717264383 and parameters: {'input_dim': 98, 'hidden_dim': 26, 'window_size': 5, 'b_size': 91, 'learning_rate': 0.06765501772121818}. Best is trial 46 with value: 0.3916110647762024.\n",
      "[I 2023-12-22 13:36:09,251] Trial 49 finished with value: 0.37976091187100364 and parameters: {'input_dim': 86, 'hidden_dim': 22, 'window_size': 4, 'b_size': 104, 'learning_rate': 0.027530780686585384}. Best is trial 46 with value: 0.3916110647762024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 99, 'hidden_dim': 22, 'window_size': 5, 'b_size': 94, 'learning_rate': 0.07016309281476811}\n",
      "Best Accuracy: 0.3916110647762024\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, H3, H4, H5, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.bn1 = nn.BatchNorm1d(H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.bn2 = nn.BatchNorm1d(H2)\n",
    "        self.linear3 = nn.Linear(H2, H3)\n",
    "        self.bn3 = nn.BatchNorm1d(H3)\n",
    "        self.linear4 = nn.Linear(H3, H4)\n",
    "        self.bn4 = nn.BatchNorm1d(H4)\n",
    "        self.linear5 = nn.Linear(H4, H5)\n",
    "        self.bn5 = nn.BatchNorm1d(H5)\n",
    "        self.linear6 = nn.Linear(H5, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.linear1(x)))\n",
    "        x = F.relu(self.bn2(self.linear2(x)))\n",
    "        x = F.relu(self.bn3(self.linear3(x)))\n",
    "        x = F.relu(self.bn4(self.linear4(x)))\n",
    "        x = F.relu(self.bn5(self.linear5(x)))\n",
    "        x = self.linear6(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, trainloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    for x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model.forward(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def evaluate_model(model, x_val, y_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z_val = model.forward(x_val)\n",
    "        max_indexes = torch.argmax(z_val, dim=1)\n",
    "        y_pred = max_indexes.numpy()\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 6, 30)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    model = Net(input_dim, 5 * hidden_dim, 4 * hidden_dim, 3*hidden_dim, 2 * hidden_dim, hidden_dim, 3)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)  # Dynamic learning rate\n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    accuracy_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_model(model, trainloader, optimizer, criterion)\n",
    "        scheduler.step()  # Adjust the learning rate dynamically\n",
    "        accuracy = evaluate_model(model, torch.from_numpy(x_val), y_val)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    return np.mean(accuracy_list)\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c88c79",
   "metadata": {
    "papermill": {
     "duration": 0.061179,
     "end_time": "2023-12-22T13:36:09.444403",
     "exception": false,
     "start_time": "2023-12-22T13:36:09.383224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Interesting, the best results were with the first approach with just one hidden layer that was using sigmoid, lets try relu with one layer to check which is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f621af2",
   "metadata": {
    "papermill": {
     "duration": 0.061362,
     "end_time": "2023-12-22T13:36:09.567518",
     "exception": false,
     "start_time": "2023-12-22T13:36:09.506156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the examples with 3 and 5 hidden layers relu was used, perhaps the fact that we didnt get any benefit using more layers was due to using relu instead of sigmoid, lets check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2388e6f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T13:36:09.695939Z",
     "iopub.status.busy": "2023-12-22T13:36:09.694628Z",
     "iopub.status.idle": "2023-12-22T13:53:13.977847Z",
     "shell.execute_reply": "2023-12-22T13:53:13.976743Z"
    },
    "papermill": {
     "duration": 1024.417611,
     "end_time": "2023-12-22T13:53:14.047418",
     "exception": false,
     "start_time": "2023-12-22T13:36:09.629807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 13:36:09,718] A new study created in memory with name: no-name-17adffe1-3adc-4191-bee2-c2c3f4bec499\n",
      "[I 2023-12-22 13:36:27,975] Trial 0 finished with value: 0.3876146788990826 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502}. Best is trial 0 with value: 0.3876146788990826.\n",
      "[I 2023-12-22 13:36:45,749] Trial 1 finished with value: 0.3797782874617737 and parameters: {'input_dim': 73, 'hidden_dim': 12, 'window_size': 9, 'b_size': 90, 'learning_rate': 0.2607024758370766}. Best is trial 0 with value: 0.3876146788990826.\n",
      "[I 2023-12-22 13:37:06,874] Trial 2 finished with value: 0.3849388379204893 and parameters: {'input_dim': 53, 'hidden_dim': 49, 'window_size': 9, 'b_size': 52, 'learning_rate': 0.02310201887845294}. Best is trial 0 with value: 0.3876146788990826.\n",
      "[I 2023-12-22 13:37:25,735] Trial 3 finished with value: 0.38952599388379205 and parameters: {'input_dim': 77, 'hidden_dim': 22, 'window_size': 7, 'b_size': 73, 'learning_rate': 0.038234752246751866}. Best is trial 3 with value: 0.38952599388379205.\n",
      "[I 2023-12-22 13:37:45,783] Trial 4 finished with value: 0.3916284403669725 and parameters: {'input_dim': 142, 'hidden_dim': 15, 'window_size': 5, 'b_size': 67, 'learning_rate': 0.08168455894760163}. Best is trial 4 with value: 0.3916284403669725.\n",
      "[I 2023-12-22 13:38:05,147] Trial 5 finished with value: 0.389717125382263 and parameters: {'input_dim': 168, 'hidden_dim': 18, 'window_size': 7, 'b_size': 89, 'learning_rate': 0.012385137298860933}. Best is trial 4 with value: 0.3916284403669725.\n",
      "[I 2023-12-22 13:38:22,609] Trial 6 finished with value: 0.386085626911315 and parameters: {'input_dim': 141, 'hidden_dim': 16, 'window_size': 3, 'b_size': 124, 'learning_rate': 0.8536189862866826}. Best is trial 4 with value: 0.3916284403669725.\n",
      "[I 2023-12-22 13:38:41,588] Trial 7 finished with value: 0.3893348623853211 and parameters: {'input_dim': 172, 'hidden_dim': 22, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695}. Best is trial 4 with value: 0.3916284403669725.\n",
      "[I 2023-12-22 13:38:58,157] Trial 8 finished with value: 0.38799694189602446 and parameters: {'input_dim': 68, 'hidden_dim': 30, 'window_size': 3, 'b_size': 120, 'learning_rate': 0.032927591344236166}. Best is trial 4 with value: 0.3916284403669725.\n",
      "[I 2023-12-22 13:39:18,100] Trial 9 finished with value: 0.3929663608562691 and parameters: {'input_dim': 150, 'hidden_dim': 22, 'window_size': 7, 'b_size': 85, 'learning_rate': 0.02342658105820405}. Best is trial 9 with value: 0.3929663608562691.\n",
      "[I 2023-12-22 13:39:43,927] Trial 10 finished with value: 0.3889525993883792 and parameters: {'input_dim': 195, 'hidden_dim': 38, 'window_size': 5, 'b_size': 33, 'learning_rate': 0.010786531858393435}. Best is trial 9 with value: 0.3929663608562691.\n",
      "[I 2023-12-22 13:40:04,587] Trial 11 finished with value: 0.3937308868501529 and parameters: {'input_dim': 127, 'hidden_dim': 29, 'window_size': 5, 'b_size': 64, 'learning_rate': 0.07738934781109344}. Best is trial 11 with value: 0.3937308868501529.\n",
      "[I 2023-12-22 13:40:26,089] Trial 12 finished with value: 0.3952599388379205 and parameters: {'input_dim': 124, 'hidden_dim': 31, 'window_size': 5, 'b_size': 55, 'learning_rate': 0.16140659244842917}. Best is trial 12 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 13:40:46,807] Trial 13 finished with value: 0.38914373088685017 and parameters: {'input_dim': 111, 'hidden_dim': 33, 'window_size': 5, 'b_size': 54, 'learning_rate': 0.18503079208668316}. Best is trial 12 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 13:41:07,729] Trial 14 finished with value: 0.3878058103975535 and parameters: {'input_dim': 111, 'hidden_dim': 30, 'window_size': 5, 'b_size': 53, 'learning_rate': 0.18000554787310746}. Best is trial 12 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 13:41:30,856] Trial 15 finished with value: 0.3912461773700306 and parameters: {'input_dim': 95, 'hidden_dim': 41, 'window_size': 4, 'b_size': 39, 'learning_rate': 0.060420377563302465}. Best is trial 12 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 13:41:50,922] Trial 16 finished with value: 0.39659785932721714 and parameters: {'input_dim': 131, 'hidden_dim': 36, 'window_size': 6, 'b_size': 65, 'learning_rate': 0.11522822110599186}. Best is trial 16 with value: 0.39659785932721714.\n",
      "[I 2023-12-22 13:42:13,691] Trial 17 finished with value: 0.38474770642201833 and parameters: {'input_dim': 125, 'hidden_dim': 38, 'window_size': 6, 'b_size': 45, 'learning_rate': 0.13123321676423902}. Best is trial 16 with value: 0.39659785932721714.\n",
      "[I 2023-12-22 13:42:32,261] Trial 18 finished with value: 0.3893348623853211 and parameters: {'input_dim': 165, 'hidden_dim': 42, 'window_size': 6, 'b_size': 108, 'learning_rate': 0.30860431163770413}. Best is trial 16 with value: 0.39659785932721714.\n",
      "[I 2023-12-22 13:42:51,856] Trial 19 finished with value: 0.39239296636085624 and parameters: {'input_dim': 128, 'hidden_dim': 34, 'window_size': 10, 'b_size': 75, 'learning_rate': 0.12460075487121523}. Best is trial 16 with value: 0.39659785932721714.\n",
      "[I 2023-12-22 13:43:11,965] Trial 20 finished with value: 0.38837920489296635 and parameters: {'input_dim': 90, 'hidden_dim': 25, 'window_size': 4, 'b_size': 60, 'learning_rate': 0.4140253444831962}. Best is trial 16 with value: 0.39659785932721714.\n",
      "[I 2023-12-22 13:43:32,458] Trial 21 finished with value: 0.3973623853211009 and parameters: {'input_dim': 125, 'hidden_dim': 28, 'window_size': 6, 'b_size': 66, 'learning_rate': 0.0965474226825717}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:43:52,781] Trial 22 finished with value: 0.3948776758409786 and parameters: {'input_dim': 150, 'hidden_dim': 26, 'window_size': 6, 'b_size': 71, 'learning_rate': 0.11877829104899512}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:44:13,804] Trial 23 finished with value: 0.39105504587155965 and parameters: {'input_dim': 121, 'hidden_dim': 35, 'window_size': 4, 'b_size': 60, 'learning_rate': 0.04544512681300563}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:44:33,689] Trial 24 finished with value: 0.3912461773700306 and parameters: {'input_dim': 138, 'hidden_dim': 27, 'window_size': 8, 'b_size': 78, 'learning_rate': 0.05675340745421163}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:44:55,413] Trial 25 finished with value: 0.38876146788990823 and parameters: {'input_dim': 100, 'hidden_dim': 43, 'window_size': 6, 'b_size': 45, 'learning_rate': 0.09240538757372135}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:45:17,949] Trial 26 finished with value: 0.37366207951070335 and parameters: {'input_dim': 118, 'hidden_dim': 37, 'window_size': 7, 'b_size': 47, 'learning_rate': 0.172241909955884}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:45:39,101] Trial 27 finished with value: 0.3876146788990826 and parameters: {'input_dim': 160, 'hidden_dim': 32, 'window_size': 8, 'b_size': 60, 'learning_rate': 0.11882482196604924}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:45:58,612] Trial 28 finished with value: 0.39258409785932724 and parameters: {'input_dim': 134, 'hidden_dim': 44, 'window_size': 6, 'b_size': 82, 'learning_rate': 0.06431873710461321}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:46:18,453] Trial 29 finished with value: 0.39392201834862384 and parameters: {'input_dim': 182, 'hidden_dim': 45, 'window_size': 4, 'b_size': 101, 'learning_rate': 0.09743689832086842}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:46:38,040] Trial 30 finished with value: 0.38685015290519875 and parameters: {'input_dim': 104, 'hidden_dim': 40, 'window_size': 5, 'b_size': 66, 'learning_rate': 0.05457202467709749}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:46:58,512] Trial 31 finished with value: 0.3916284403669725 and parameters: {'input_dim': 150, 'hidden_dim': 25, 'window_size': 6, 'b_size': 69, 'learning_rate': 0.11513484054950815}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:47:19,283] Trial 32 finished with value: 0.38952599388379205 and parameters: {'input_dim': 155, 'hidden_dim': 27, 'window_size': 6, 'b_size': 72, 'learning_rate': 0.15253238039948888}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:47:40,848] Trial 33 finished with value: 0.39105504587155965 and parameters: {'input_dim': 114, 'hidden_dim': 31, 'window_size': 7, 'b_size': 56, 'learning_rate': 0.09423089840612471}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:48:00,689] Trial 34 finished with value: 0.3841743119266055 and parameters: {'input_dim': 147, 'hidden_dim': 27, 'window_size': 8, 'b_size': 79, 'learning_rate': 0.15292155925490447}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:48:20,212] Trial 35 finished with value: 0.38876146788990823 and parameters: {'input_dim': 133, 'hidden_dim': 35, 'window_size': 6, 'b_size': 71, 'learning_rate': 0.21783889161071032}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:48:41,230] Trial 36 finished with value: 0.38952599388379205 and parameters: {'input_dim': 177, 'hidden_dim': 11, 'window_size': 7, 'b_size': 63, 'learning_rate': 0.25921841896205583}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:49:02,623] Trial 37 finished with value: 0.39506880733944955 and parameters: {'input_dim': 91, 'hidden_dim': 20, 'window_size': 5, 'b_size': 49, 'learning_rate': 0.1096312469185232}. Best is trial 21 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 13:49:24,063] Trial 38 finished with value: 0.39755351681957185 and parameters: {'input_dim': 86, 'hidden_dim': 19, 'window_size': 4, 'b_size': 50, 'learning_rate': 0.07995387492123815}. Best is trial 38 with value: 0.39755351681957185.\n",
      "[I 2023-12-22 13:49:45,566] Trial 39 finished with value: 0.3912461773700306 and parameters: {'input_dim': 50, 'hidden_dim': 14, 'window_size': 4, 'b_size': 41, 'learning_rate': 0.08047372442470038}. Best is trial 38 with value: 0.39755351681957185.\n",
      "[I 2023-12-22 13:50:08,862] Trial 40 finished with value: 0.389717125382263 and parameters: {'input_dim': 81, 'hidden_dim': 50, 'window_size': 3, 'b_size': 37, 'learning_rate': 0.041973792297606546}. Best is trial 38 with value: 0.39755351681957185.\n",
      "[I 2023-12-22 13:50:30,170] Trial 41 finished with value: 0.3885703363914373 and parameters: {'input_dim': 86, 'hidden_dim': 18, 'window_size': 5, 'b_size': 47, 'learning_rate': 0.07594690858880133}. Best is trial 38 with value: 0.39755351681957185.\n",
      "[I 2023-12-22 13:50:50,587] Trial 42 finished with value: 0.3881880733944954 and parameters: {'input_dim': 66, 'hidden_dim': 20, 'window_size': 5, 'b_size': 50, 'learning_rate': 0.09586830817557215}. Best is trial 38 with value: 0.39755351681957185.\n",
      "[I 2023-12-22 13:51:11,009] Trial 43 finished with value: 0.3983180428134557 and parameters: {'input_dim': 60, 'hidden_dim': 23, 'window_size': 4, 'b_size': 56, 'learning_rate': 0.1375385552240261}. Best is trial 43 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 13:51:31,585] Trial 44 finished with value: 0.3977446483180428 and parameters: {'input_dim': 59, 'hidden_dim': 23, 'window_size': 4, 'b_size': 55, 'learning_rate': 0.13737618375898308}. Best is trial 43 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 13:51:51,462] Trial 45 finished with value: 0.3885703363914373 and parameters: {'input_dim': 60, 'hidden_dim': 23, 'window_size': 3, 'b_size': 57, 'learning_rate': 0.06692146345929242}. Best is trial 43 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 13:52:10,913] Trial 46 finished with value: 0.3881880733944954 and parameters: {'input_dim': 59, 'hidden_dim': 18, 'window_size': 4, 'b_size': 64, 'learning_rate': 0.13891286406471676}. Best is trial 43 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 13:52:34,521] Trial 47 finished with value: 0.38436544342507645 and parameters: {'input_dim': 72, 'hidden_dim': 20, 'window_size': 9, 'b_size': 34, 'learning_rate': 0.09495270776908882}. Best is trial 43 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 13:52:52,124] Trial 48 finished with value: 0.39048165137614677 and parameters: {'input_dim': 57, 'hidden_dim': 24, 'window_size': 3, 'b_size': 89, 'learning_rate': 0.034436326019107955}. Best is trial 43 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 13:53:13,972] Trial 49 finished with value: 0.37844036697247707 and parameters: {'input_dim': 78, 'hidden_dim': 14, 'window_size': 4, 'b_size': 43, 'learning_rate': 0.20227164484761093}. Best is trial 43 with value: 0.3983180428134557.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 60, 'hidden_dim': 23, 'window_size': 4, 'b_size': 56, 'learning_rate': 0.1375385552240261}\n",
      "Best Accuracy: 0.3983180428134557\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    model = Net(input_dim, hidden_dim, output_dim)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e63b25",
   "metadata": {
    "papermill": {
     "duration": 0.140755,
     "end_time": "2023-12-22T13:53:14.256193",
     "exception": false,
     "start_time": "2023-12-22T13:53:14.115438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We got an even better result using relu and one hidden layer, so using this NN we will try to use adam optimizer instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1fe33bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T13:53:14.395306Z",
     "iopub.status.busy": "2023-12-22T13:53:14.394502Z",
     "iopub.status.idle": "2023-12-22T14:12:53.627017Z",
     "shell.execute_reply": "2023-12-22T14:12:53.625808Z"
    },
    "papermill": {
     "duration": 1179.304994,
     "end_time": "2023-12-22T14:12:53.629896",
     "exception": false,
     "start_time": "2023-12-22T13:53:14.324902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 13:53:14,418] A new study created in memory with name: no-name-9159c315-acd8-40d6-a8a4-8fb8ff1abd24\n",
      "[I 2023-12-22 13:53:34,946] Trial 0 finished with value: 0.3900993883792049 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:53:56,386] Trial 1 finished with value: 0.3333333333333333 and parameters: {'input_dim': 73, 'hidden_dim': 12, 'window_size': 9, 'b_size': 90, 'learning_rate': 0.2607024758370766}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:54:21,749] Trial 2 finished with value: 0.3486238532110092 and parameters: {'input_dim': 53, 'hidden_dim': 49, 'window_size': 9, 'b_size': 52, 'learning_rate': 0.02310201887845294}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:54:43,397] Trial 3 finished with value: 0.3830275229357798 and parameters: {'input_dim': 77, 'hidden_dim': 22, 'window_size': 7, 'b_size': 73, 'learning_rate': 0.038234752246751866}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:55:07,820] Trial 4 finished with value: 0.3333333333333333 and parameters: {'input_dim': 142, 'hidden_dim': 15, 'window_size': 5, 'b_size': 67, 'learning_rate': 0.08168455894760163}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:55:29,155] Trial 5 finished with value: 0.3795871559633027 and parameters: {'input_dim': 168, 'hidden_dim': 18, 'window_size': 7, 'b_size': 89, 'learning_rate': 0.012385137298860933}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:55:49,975] Trial 6 finished with value: 0.3333333333333333 and parameters: {'input_dim': 141, 'hidden_dim': 16, 'window_size': 3, 'b_size': 124, 'learning_rate': 0.8536189862866826}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:56:12,636] Trial 7 finished with value: 0.3511085626911315 and parameters: {'input_dim': 172, 'hidden_dim': 22, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:56:30,697] Trial 8 finished with value: 0.3862767584097859 and parameters: {'input_dim': 68, 'hidden_dim': 30, 'window_size': 3, 'b_size': 120, 'learning_rate': 0.032927591344236166}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:56:53,118] Trial 9 finished with value: 0.3878058103975535 and parameters: {'input_dim': 150, 'hidden_dim': 22, 'window_size': 7, 'b_size': 85, 'learning_rate': 0.02342658105820405}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:57:25,381] Trial 10 finished with value: 0.3811162079510703 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 10, 'b_size': 33, 'learning_rate': 0.010733354530413287}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:57:45,707] Trial 11 finished with value: 0.37576452599388377 and parameters: {'input_dim': 110, 'hidden_dim': 40, 'window_size': 6, 'b_size': 104, 'learning_rate': 0.022055995370478948}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:58:13,338] Trial 12 finished with value: 0.3333333333333333 and parameters: {'input_dim': 198, 'hidden_dim': 32, 'window_size': 8, 'b_size': 63, 'learning_rate': 0.04842080300729569}. Best is trial 0 with value: 0.3900993883792049.\n",
      "[I 2023-12-22 13:58:33,708] Trial 13 finished with value: 0.39353975535168195 and parameters: {'input_dim': 120, 'hidden_dim': 33, 'window_size': 5, 'b_size': 108, 'learning_rate': 0.01648801454235388}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 13:58:53,541] Trial 14 finished with value: 0.3881880733944954 and parameters: {'input_dim': 104, 'hidden_dim': 41, 'window_size': 5, 'b_size': 109, 'learning_rate': 0.010999357277432746}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 13:59:13,842] Trial 15 finished with value: 0.378631498470948 and parameters: {'input_dim': 121, 'hidden_dim': 34, 'window_size': 5, 'b_size': 114, 'learning_rate': 0.018679044572377956}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 13:59:34,355] Trial 16 finished with value: 0.35493119266055045 and parameters: {'input_dim': 100, 'hidden_dim': 42, 'window_size': 6, 'b_size': 98, 'learning_rate': 0.04211820672276467}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 13:59:54,345] Trial 17 finished with value: 0.3333333333333333 and parameters: {'input_dim': 85, 'hidden_dim': 28, 'window_size': 4, 'b_size': 127, 'learning_rate': 0.14835093170359046}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:00:15,735] Trial 18 finished with value: 0.38589449541284404 and parameters: {'input_dim': 129, 'hidden_dim': 37, 'window_size': 8, 'b_size': 78, 'learning_rate': 0.016222808246876625}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:00:36,480] Trial 19 finished with value: 0.39105504587155965 and parameters: {'input_dim': 89, 'hidden_dim': 45, 'window_size': 8, 'b_size': 100, 'learning_rate': 0.010548215882091913}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:00:57,262] Trial 20 finished with value: 0.3900993883792049 and parameters: {'input_dim': 90, 'hidden_dim': 45, 'window_size': 10, 'b_size': 112, 'learning_rate': 0.0102206905470606}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:01:18,575] Trial 21 finished with value: 0.38990825688073394 and parameters: {'input_dim': 121, 'hidden_dim': 46, 'window_size': 8, 'b_size': 98, 'learning_rate': 0.018211861070960393}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:01:39,886] Trial 22 finished with value: 0.38742354740061163 and parameters: {'input_dim': 92, 'hidden_dim': 50, 'window_size': 9, 'b_size': 104, 'learning_rate': 0.015735914962698546}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:02:01,740] Trial 23 finished with value: 0.38742354740061163 and parameters: {'input_dim': 58, 'hidden_dim': 37, 'window_size': 6, 'b_size': 93, 'learning_rate': 0.028327552509944367}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:02:24,514] Trial 24 finished with value: 0.3853211009174312 and parameters: {'input_dim': 125, 'hidden_dim': 44, 'window_size': 8, 'b_size': 82, 'learning_rate': 0.012693198965765463}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:02:44,162] Trial 25 finished with value: 0.382262996941896 and parameters: {'input_dim': 113, 'hidden_dim': 26, 'window_size': 4, 'b_size': 118, 'learning_rate': 0.028728382367882388}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:03:03,994] Trial 26 finished with value: 0.3849388379204893 and parameters: {'input_dim': 96, 'hidden_dim': 37, 'window_size': 7, 'b_size': 106, 'learning_rate': 0.017375625535568567}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:03:26,418] Trial 27 finished with value: 0.39048165137614677 and parameters: {'input_dim': 136, 'hidden_dim': 47, 'window_size': 9, 'b_size': 76, 'learning_rate': 0.014952143233335212}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:03:50,596] Trial 28 finished with value: 0.39353975535168195 and parameters: {'input_dim': 160, 'hidden_dim': 43, 'window_size': 9, 'b_size': 64, 'learning_rate': 0.01319674454886737}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:04:20,083] Trial 29 finished with value: 0.3902905198776758 and parameters: {'input_dim': 159, 'hidden_dim': 34, 'window_size': 10, 'b_size': 44, 'learning_rate': 0.010008934834977149}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:04:47,158] Trial 30 finished with value: 0.39201070336391436 and parameters: {'input_dim': 193, 'hidden_dim': 39, 'window_size': 9, 'b_size': 53, 'learning_rate': 0.013962593037234945}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:05:13,138] Trial 31 finished with value: 0.389717125382263 and parameters: {'input_dim': 197, 'hidden_dim': 39, 'window_size': 9, 'b_size': 58, 'learning_rate': 0.014403461828998853}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:05:45,403] Trial 32 finished with value: 0.37882262996941896 and parameters: {'input_dim': 187, 'hidden_dim': 44, 'window_size': 8, 'b_size': 48, 'learning_rate': 0.022913875620685337}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:06:13,318] Trial 33 finished with value: 0.3837920489296636 and parameters: {'input_dim': 182, 'hidden_dim': 42, 'window_size': 9, 'b_size': 56, 'learning_rate': 0.013431681460981913}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:06:38,371] Trial 34 finished with value: 0.3774847094801223 and parameters: {'input_dim': 155, 'hidden_dim': 34, 'window_size': 10, 'b_size': 69, 'learning_rate': 0.020591233059887297}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:07:13,680] Trial 35 finished with value: 0.3541666666666667 and parameters: {'input_dim': 170, 'hidden_dim': 39, 'window_size': 9, 'b_size': 41, 'learning_rate': 0.02745066289027628}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:07:39,729] Trial 36 finished with value: 0.3755733944954128 and parameters: {'input_dim': 183, 'hidden_dim': 43, 'window_size': 7, 'b_size': 61, 'learning_rate': 0.013952981893814649}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:08:05,701] Trial 37 finished with value: 0.35646024464831805 and parameters: {'input_dim': 162, 'hidden_dim': 10, 'window_size': 9, 'b_size': 53, 'learning_rate': 0.038087411276609966}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:08:28,672] Trial 38 finished with value: 0.3809250764525994 and parameters: {'input_dim': 78, 'hidden_dim': 36, 'window_size': 8, 'b_size': 69, 'learning_rate': 0.010100496340564487}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:08:51,308] Trial 39 finished with value: 0.34938837920489296 and parameters: {'input_dim': 145, 'hidden_dim': 31, 'window_size': 4, 'b_size': 89, 'learning_rate': 0.053674752075069776}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:09:21,419] Trial 40 finished with value: 0.36009174311926606 and parameters: {'input_dim': 134, 'hidden_dim': 27, 'window_size': 10, 'b_size': 37, 'learning_rate': 0.013039496560884371}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:09:44,241] Trial 41 finished with value: 0.386085626911315 and parameters: {'input_dim': 136, 'hidden_dim': 48, 'window_size': 9, 'b_size': 75, 'learning_rate': 0.017021418270848212}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:10:08,261] Trial 42 finished with value: 0.38914373088685017 and parameters: {'input_dim': 115, 'hidden_dim': 45, 'window_size': 9, 'b_size': 64, 'learning_rate': 0.013531074302126456}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:10:32,458] Trial 43 finished with value: 0.3862767584097859 and parameters: {'input_dim': 177, 'hidden_dim': 47, 'window_size': 9, 'b_size': 74, 'learning_rate': 0.020411766358293015}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:11:02,764] Trial 44 finished with value: 0.3878058103975535 and parameters: {'input_dim': 147, 'hidden_dim': 50, 'window_size': 8, 'b_size': 50, 'learning_rate': 0.025080460325888242}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:11:23,447] Trial 45 finished with value: 0.38551223241590216 and parameters: {'input_dim': 65, 'hidden_dim': 39, 'window_size': 10, 'b_size': 80, 'learning_rate': 0.016123356366734266}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:11:44,932] Trial 46 finished with value: 0.3866590214067278 and parameters: {'input_dim': 138, 'hidden_dim': 47, 'window_size': 7, 'b_size': 94, 'learning_rate': 0.01166302629976407}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:12:08,328] Trial 47 finished with value: 0.38990825688073394 and parameters: {'input_dim': 190, 'hidden_dim': 41, 'window_size': 5, 'b_size': 87, 'learning_rate': 0.02079531741257105}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:12:28,864] Trial 48 finished with value: 0.36964831804281345 and parameters: {'input_dim': 153, 'hidden_dim': 43, 'window_size': 6, 'b_size': 119, 'learning_rate': 0.03238792490482239}. Best is trial 13 with value: 0.39353975535168195.\n",
      "[I 2023-12-22 14:12:53,620] Trial 49 finished with value: 0.38398318042813456 and parameters: {'input_dim': 168, 'hidden_dim': 35, 'window_size': 8, 'b_size': 59, 'learning_rate': 0.011945123264255987}. Best is trial 13 with value: 0.39353975535168195.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 120, 'hidden_dim': 33, 'window_size': 5, 'b_size': 108, 'learning_rate': 0.01648801454235388}\n",
      "Best Accuracy: 0.39353975535168195\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    model = Net(input_dim, hidden_dim, output_dim)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00caab4",
   "metadata": {
    "papermill": {
     "duration": 0.074376,
     "end_time": "2023-12-22T14:12:53.778619",
     "exception": false,
     "start_time": "2023-12-22T14:12:53.704243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Very close to SGD but not better, perhaps we should increase number of epochs for better convergance, but since we dont care about time but precision, we keep SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f676e20a",
   "metadata": {
    "papermill": {
     "duration": 0.073277,
     "end_time": "2023-12-22T14:12:53.928245",
     "exception": false,
     "start_time": "2023-12-22T14:12:53.854968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will try NLLLoss, we need to also adapt our network to use log softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d70da711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T14:12:54.077144Z",
     "iopub.status.busy": "2023-12-22T14:12:54.076766Z",
     "iopub.status.idle": "2023-12-22T14:29:46.675243Z",
     "shell.execute_reply": "2023-12-22T14:29:46.674120Z"
    },
    "papermill": {
     "duration": 1012.749824,
     "end_time": "2023-12-22T14:29:46.753155",
     "exception": false,
     "start_time": "2023-12-22T14:12:54.003331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 14:12:54,101] A new study created in memory with name: no-name-aa094965-b52d-4b2e-90a2-092756220e72\n",
      "[I 2023-12-22 14:13:12,968] Trial 0 finished with value: 0.39506880733944955 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502}. Best is trial 0 with value: 0.39506880733944955.\n",
      "[I 2023-12-22 14:13:30,741] Trial 1 finished with value: 0.3881880733944954 and parameters: {'input_dim': 73, 'hidden_dim': 12, 'window_size': 9, 'b_size': 90, 'learning_rate': 0.2607024758370766}. Best is trial 0 with value: 0.39506880733944955.\n",
      "[I 2023-12-22 14:13:51,486] Trial 2 finished with value: 0.389717125382263 and parameters: {'input_dim': 53, 'hidden_dim': 49, 'window_size': 9, 'b_size': 52, 'learning_rate': 0.02310201887845294}. Best is trial 0 with value: 0.39506880733944955.\n",
      "[I 2023-12-22 14:14:10,425] Trial 3 finished with value: 0.38952599388379205 and parameters: {'input_dim': 77, 'hidden_dim': 22, 'window_size': 7, 'b_size': 73, 'learning_rate': 0.038234752246751866}. Best is trial 0 with value: 0.39506880733944955.\n",
      "[I 2023-12-22 14:14:30,603] Trial 4 finished with value: 0.3973623853211009 and parameters: {'input_dim': 142, 'hidden_dim': 15, 'window_size': 5, 'b_size': 67, 'learning_rate': 0.08168455894760163}. Best is trial 4 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 14:14:49,888] Trial 5 finished with value: 0.39105504587155965 and parameters: {'input_dim': 168, 'hidden_dim': 18, 'window_size': 7, 'b_size': 89, 'learning_rate': 0.012385137298860933}. Best is trial 4 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 14:15:07,538] Trial 6 finished with value: 0.3621941896024465 and parameters: {'input_dim': 141, 'hidden_dim': 16, 'window_size': 3, 'b_size': 124, 'learning_rate': 0.8536189862866826}. Best is trial 4 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 14:15:26,650] Trial 7 finished with value: 0.3941131498470948 and parameters: {'input_dim': 172, 'hidden_dim': 22, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695}. Best is trial 4 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 14:15:43,302] Trial 8 finished with value: 0.3948776758409786 and parameters: {'input_dim': 68, 'hidden_dim': 30, 'window_size': 3, 'b_size': 120, 'learning_rate': 0.032927591344236166}. Best is trial 4 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 14:16:03,951] Trial 9 finished with value: 0.3952599388379205 and parameters: {'input_dim': 150, 'hidden_dim': 22, 'window_size': 7, 'b_size': 85, 'learning_rate': 0.02342658105820405}. Best is trial 4 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 14:16:29,218] Trial 10 finished with value: 0.3878058103975535 and parameters: {'input_dim': 194, 'hidden_dim': 38, 'window_size': 5, 'b_size': 33, 'learning_rate': 0.13527769084615443}. Best is trial 4 with value: 0.3973623853211009.\n",
      "[I 2023-12-22 14:16:49,720] Trial 11 finished with value: 0.40061162079510704 and parameters: {'input_dim': 127, 'hidden_dim': 29, 'window_size': 5, 'b_size': 64, 'learning_rate': 0.010339322933113433}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:17:10,985] Trial 12 finished with value: 0.3872324159021407 and parameters: {'input_dim': 124, 'hidden_dim': 32, 'window_size': 5, 'b_size': 60, 'learning_rate': 0.011415599169586366}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:17:30,911] Trial 13 finished with value: 0.3922018348623853 and parameters: {'input_dim': 102, 'hidden_dim': 10, 'window_size': 5, 'b_size': 65, 'learning_rate': 0.0595920613164576}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:17:54,059] Trial 14 finished with value: 0.39048165137614677 and parameters: {'input_dim': 121, 'hidden_dim': 31, 'window_size': 5, 'b_size': 41, 'learning_rate': 0.1451629980059404}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:18:16,163] Trial 15 finished with value: 0.3967889908256881 and parameters: {'input_dim': 151, 'hidden_dim': 41, 'window_size': 4, 'b_size': 50, 'learning_rate': 0.010316663732926088}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:18:35,731] Trial 16 finished with value: 0.38799694189602446 and parameters: {'input_dim': 110, 'hidden_dim': 27, 'window_size': 6, 'b_size': 73, 'learning_rate': 0.054601706188315446}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:18:54,595] Trial 17 finished with value: 0.3889525993883792 and parameters: {'input_dim': 140, 'hidden_dim': 39, 'window_size': 6, 'b_size': 110, 'learning_rate': 0.08768971880238807}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:19:14,424] Trial 18 finished with value: 0.39621559633027525 and parameters: {'input_dim': 90, 'hidden_dim': 16, 'window_size': 4, 'b_size': 73, 'learning_rate': 0.043822823657896484}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:19:37,014] Trial 19 finished with value: 0.3941131498470948 and parameters: {'input_dim': 175, 'hidden_dim': 26, 'window_size': 10, 'b_size': 59, 'learning_rate': 0.015350360870146323}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:20:00,389] Trial 20 finished with value: 0.38512996941896027 and parameters: {'input_dim': 198, 'hidden_dim': 36, 'window_size': 4, 'b_size': 44, 'learning_rate': 0.027927700255475134}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:20:23,210] Trial 21 finished with value: 0.3964067278287462 and parameters: {'input_dim': 146, 'hidden_dim': 44, 'window_size': 4, 'b_size': 51, 'learning_rate': 0.010963655977559399}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:20:44,846] Trial 22 finished with value: 0.3922018348623853 and parameters: {'input_dim': 159, 'hidden_dim': 43, 'window_size': 4, 'b_size': 63, 'learning_rate': 0.01670644979097077}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:21:06,461] Trial 23 finished with value: 0.3937308868501529 and parameters: {'input_dim': 131, 'hidden_dim': 35, 'window_size': 6, 'b_size': 51, 'learning_rate': 0.010955971808075277}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:21:30,884] Trial 24 finished with value: 0.38837920489296635 and parameters: {'input_dim': 155, 'hidden_dim': 42, 'window_size': 5, 'b_size': 38, 'learning_rate': 0.01854271519293862}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:21:50,248] Trial 25 finished with value: 0.39506880733944955 and parameters: {'input_dim': 131, 'hidden_dim': 27, 'window_size': 4, 'b_size': 73, 'learning_rate': 0.028728382367882388}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:22:10,905] Trial 26 finished with value: 0.389717125382263 and parameters: {'input_dim': 182, 'hidden_dim': 34, 'window_size': 6, 'b_size': 80, 'learning_rate': 0.013943118062809798}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:22:32,855] Trial 27 finished with value: 0.3908639143730887 and parameters: {'input_dim': 115, 'hidden_dim': 46, 'window_size': 5, 'b_size': 46, 'learning_rate': 0.017116213964286607}. Best is trial 11 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:22:53,931] Trial 28 finished with value: 0.40424311926605505 and parameters: {'input_dim': 164, 'hidden_dim': 40, 'window_size': 3, 'b_size': 56, 'learning_rate': 0.03942864254943263}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:23:11,353] Trial 29 finished with value: 0.38646788990825687 and parameters: {'input_dim': 98, 'hidden_dim': 24, 'window_size': 8, 'b_size': 101, 'learning_rate': 0.04704271678092943}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:23:31,846] Trial 30 finished with value: 0.4029051987767584 and parameters: {'input_dim': 165, 'hidden_dim': 18, 'window_size': 3, 'b_size': 65, 'learning_rate': 0.0345543523624102}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:23:52,419] Trial 31 finished with value: 0.3967889908256881 and parameters: {'input_dim': 161, 'hidden_dim': 19, 'window_size': 3, 'b_size': 66, 'learning_rate': 0.03502493366238786}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:24:14,046] Trial 32 finished with value: 0.39602446483180426 and parameters: {'input_dim': 183, 'hidden_dim': 12, 'window_size': 3, 'b_size': 56, 'learning_rate': 0.022500542254319824}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:24:34,053] Trial 33 finished with value: 0.3908639143730887 and parameters: {'input_dim': 134, 'hidden_dim': 15, 'window_size': 3, 'b_size': 68, 'learning_rate': 0.061819897600899336}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:24:53,610] Trial 34 finished with value: 0.3973623853211009 and parameters: {'input_dim': 164, 'hidden_dim': 19, 'window_size': 8, 'b_size': 80, 'learning_rate': 0.04629570631499085}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:25:15,916] Trial 35 finished with value: 0.3845565749235474 and parameters: {'input_dim': 186, 'hidden_dim': 49, 'window_size': 4, 'b_size': 56, 'learning_rate': 0.026748554209064895}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:25:35,508] Trial 36 finished with value: 0.40118501529051986 and parameters: {'input_dim': 141, 'hidden_dim': 13, 'window_size': 3, 'b_size': 74, 'learning_rate': 0.03434871033289599}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:25:55,662] Trial 37 finished with value: 0.39545107033639143 and parameters: {'input_dim': 175, 'hidden_dim': 13, 'window_size': 3, 'b_size': 82, 'learning_rate': 0.0216682476516888}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:26:15,039] Trial 38 finished with value: 0.39602446483180426 and parameters: {'input_dim': 138, 'hidden_dim': 10, 'window_size': 3, 'b_size': 69, 'learning_rate': 0.037570360344019366}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:26:33,440] Trial 39 finished with value: 0.40118501529051986 and parameters: {'input_dim': 117, 'hidden_dim': 21, 'window_size': 3, 'b_size': 96, 'learning_rate': 0.020079298680466956}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:26:52,301] Trial 40 finished with value: 0.39946483180428133 and parameters: {'input_dim': 167, 'hidden_dim': 19, 'window_size': 3, 'b_size': 92, 'learning_rate': 0.031182795358152153}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:27:10,810] Trial 41 finished with value: 0.3918195718654434 and parameters: {'input_dim': 117, 'hidden_dim': 24, 'window_size': 3, 'b_size': 106, 'learning_rate': 0.018697910452667537}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:27:29,345] Trial 42 finished with value: 0.3977446483180428 and parameters: {'input_dim': 94, 'hidden_dim': 17, 'window_size': 4, 'b_size': 92, 'learning_rate': 0.014241607483647662}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:27:48,320] Trial 43 finished with value: 0.3948776758409786 and parameters: {'input_dim': 127, 'hidden_dim': 21, 'window_size': 3, 'b_size': 86, 'learning_rate': 0.023117671723022478}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:28:07,452] Trial 44 finished with value: 0.3992737003058104 and parameters: {'input_dim': 110, 'hidden_dim': 25, 'window_size': 4, 'b_size': 77, 'learning_rate': 0.03623320211139654}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:28:28,128] Trial 45 finished with value: 0.38685015290519875 and parameters: {'input_dim': 150, 'hidden_dim': 13, 'window_size': 3, 'b_size': 61, 'learning_rate': 0.02006687213642204}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:28:46,219] Trial 46 finished with value: 0.3922018348623853 and parameters: {'input_dim': 87, 'hidden_dim': 21, 'window_size': 3, 'b_size': 113, 'learning_rate': 0.014383021685579582}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:29:05,050] Trial 47 finished with value: 0.39621559633027525 and parameters: {'input_dim': 143, 'hidden_dim': 30, 'window_size': 4, 'b_size': 97, 'learning_rate': 0.02662359281602302}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:29:26,206] Trial 48 finished with value: 0.3941131498470948 and parameters: {'input_dim': 124, 'hidden_dim': 29, 'window_size': 3, 'b_size': 57, 'learning_rate': 0.012636626388162923}. Best is trial 28 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:29:46,669] Trial 49 finished with value: 0.3929663608562691 and parameters: {'input_dim': 155, 'hidden_dim': 14, 'window_size': 7, 'b_size': 71, 'learning_rate': 0.03204319193536622}. Best is trial 28 with value: 0.40424311926605505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 164, 'hidden_dim': 40, 'window_size': 3, 'b_size': 56, 'learning_rate': 0.03942864254943263}\n",
      "Best Accuracy: 0.40424311926605505\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.NLLLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    model = Net(input_dim, hidden_dim, output_dim)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d2d69",
   "metadata": {
    "papermill": {
     "duration": 0.077553,
     "end_time": "2023-12-22T14:29:46.907902",
     "exception": false,
     "start_time": "2023-12-22T14:29:46.830349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Pretty close but not better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3311bb15",
   "metadata": {
    "papermill": {
     "duration": 0.075795,
     "end_time": "2023-12-22T14:29:47.061654",
     "exception": false,
     "start_time": "2023-12-22T14:29:46.985859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Also try MultiMargin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebfa1ef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T14:29:47.217358Z",
     "iopub.status.busy": "2023-12-22T14:29:47.216942Z",
     "iopub.status.idle": "2023-12-22T14:46:02.954538Z",
     "shell.execute_reply": "2023-12-22T14:46:02.953398Z"
    },
    "papermill": {
     "duration": 975.901439,
     "end_time": "2023-12-22T14:46:03.040130",
     "exception": false,
     "start_time": "2023-12-22T14:29:47.138691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 14:29:47,240] A new study created in memory with name: no-name-3e395dec-cf5b-45b3-a244-b7f1a0987cc6\n",
      "[I 2023-12-22 14:30:05,628] Trial 0 finished with value: 0.4004204892966361 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502}. Best is trial 0 with value: 0.4004204892966361.\n",
      "[I 2023-12-22 14:30:23,230] Trial 1 finished with value: 0.3977446483180428 and parameters: {'input_dim': 73, 'hidden_dim': 12, 'window_size': 9, 'b_size': 90, 'learning_rate': 0.2607024758370766}. Best is trial 0 with value: 0.4004204892966361.\n",
      "[I 2023-12-22 14:30:44,341] Trial 2 finished with value: 0.39793577981651373 and parameters: {'input_dim': 53, 'hidden_dim': 49, 'window_size': 9, 'b_size': 52, 'learning_rate': 0.02310201887845294}. Best is trial 0 with value: 0.4004204892966361.\n",
      "[I 2023-12-22 14:31:03,738] Trial 3 finished with value: 0.40156727828746175 and parameters: {'input_dim': 77, 'hidden_dim': 22, 'window_size': 7, 'b_size': 73, 'learning_rate': 0.038234752246751866}. Best is trial 3 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 14:31:24,226] Trial 4 finished with value: 0.3956422018348624 and parameters: {'input_dim': 142, 'hidden_dim': 15, 'window_size': 5, 'b_size': 67, 'learning_rate': 0.08168455894760163}. Best is trial 3 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 14:31:44,143] Trial 5 finished with value: 0.39793577981651373 and parameters: {'input_dim': 168, 'hidden_dim': 18, 'window_size': 7, 'b_size': 89, 'learning_rate': 0.012385137298860933}. Best is trial 3 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 14:32:02,033] Trial 6 finished with value: 0.40424311926605505 and parameters: {'input_dim': 141, 'hidden_dim': 16, 'window_size': 3, 'b_size': 124, 'learning_rate': 0.8536189862866826}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:32:21,345] Trial 7 finished with value: 0.39908256880733944 and parameters: {'input_dim': 172, 'hidden_dim': 22, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:32:37,786] Trial 8 finished with value: 0.3944954128440367 and parameters: {'input_dim': 68, 'hidden_dim': 30, 'window_size': 3, 'b_size': 120, 'learning_rate': 0.032927591344236166}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:32:57,925] Trial 9 finished with value: 0.40061162079510704 and parameters: {'input_dim': 150, 'hidden_dim': 22, 'window_size': 7, 'b_size': 85, 'learning_rate': 0.02342658105820405}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:33:16,322] Trial 10 finished with value: 0.3908639143730887 and parameters: {'input_dim': 194, 'hidden_dim': 38, 'window_size': 5, 'b_size': 124, 'learning_rate': 0.9285225829404773}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:33:39,142] Trial 11 finished with value: 0.3866590214067278 and parameters: {'input_dim': 109, 'hidden_dim': 29, 'window_size': 5, 'b_size': 41, 'learning_rate': 0.9808402068828499}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:33:58,083] Trial 12 finished with value: 0.39143730886850153 and parameters: {'input_dim': 102, 'hidden_dim': 10, 'window_size': 6, 'b_size': 70, 'learning_rate': 0.30512027571863104}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:34:16,071] Trial 13 finished with value: 0.39353975535168195 and parameters: {'input_dim': 131, 'hidden_dim': 22, 'window_size': 10, 'b_size': 109, 'learning_rate': 0.058696984223957506}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:34:36,526] Trial 14 finished with value: 0.39717125382262997 and parameters: {'input_dim': 89, 'hidden_dim': 38, 'window_size': 4, 'b_size': 68, 'learning_rate': 0.18000554787310746}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:34:58,237] Trial 15 finished with value: 0.39353975535168195 and parameters: {'input_dim': 121, 'hidden_dim': 26, 'window_size': 6, 'b_size': 55, 'learning_rate': 0.046325091682924216}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:35:16,844] Trial 16 finished with value: 0.3958333333333333 and parameters: {'input_dim': 85, 'hidden_dim': 36, 'window_size': 8, 'b_size': 108, 'learning_rate': 0.10679012120042587}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:35:37,061] Trial 17 finished with value: 0.39621559633027525 and parameters: {'input_dim': 153, 'hidden_dim': 17, 'window_size': 4, 'b_size': 76, 'learning_rate': 0.5508560011452656}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:35:56,981] Trial 18 finished with value: 0.3937308868501529 and parameters: {'input_dim': 200, 'hidden_dim': 26, 'window_size': 8, 'b_size': 105, 'learning_rate': 0.13006266808492892}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:36:21,989] Trial 19 finished with value: 0.39965596330275227 and parameters: {'input_dim': 119, 'hidden_dim': 33, 'window_size': 4, 'b_size': 33, 'learning_rate': 0.44128820809801383}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:36:43,019] Trial 20 finished with value: 0.4009938837920489 and parameters: {'input_dim': 171, 'hidden_dim': 15, 'window_size': 6, 'b_size': 77, 'learning_rate': 0.1532842029355893}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:37:05,347] Trial 21 finished with value: 0.39105504587155965 and parameters: {'input_dim': 174, 'hidden_dim': 14, 'window_size': 6, 'b_size': 59, 'learning_rate': 0.14252739508200016}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:37:25,074] Trial 22 finished with value: 0.3964067278287462 and parameters: {'input_dim': 160, 'hidden_dim': 19, 'window_size': 7, 'b_size': 78, 'learning_rate': 0.19076036757512807}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:37:44,385] Trial 23 finished with value: 0.39602446483180426 and parameters: {'input_dim': 183, 'hidden_dim': 13, 'window_size': 3, 'b_size': 99, 'learning_rate': 0.0503836020865591}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:38:02,094] Trial 24 finished with value: 0.3977446483180428 and parameters: {'input_dim': 137, 'hidden_dim': 20, 'window_size': 5, 'b_size': 117, 'learning_rate': 0.5784411477816304}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:38:21,417] Trial 25 finished with value: 0.3929663608562691 and parameters: {'input_dim': 50, 'hidden_dim': 10, 'window_size': 9, 'b_size': 62, 'learning_rate': 0.09261776016123817}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:38:42,375] Trial 26 finished with value: 0.3967889908256881 and parameters: {'input_dim': 187, 'hidden_dim': 26, 'window_size': 6, 'b_size': 80, 'learning_rate': 0.33149617395002484}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:39:04,787] Trial 27 finished with value: 0.3967889908256881 and parameters: {'input_dim': 146, 'hidden_dim': 16, 'window_size': 7, 'b_size': 48, 'learning_rate': 0.2272640257372144}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:39:25,366] Trial 28 finished with value: 0.3967889908256881 and parameters: {'input_dim': 161, 'hidden_dim': 25, 'window_size': 10, 'b_size': 73, 'learning_rate': 0.12770524043588682}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:39:43,692] Trial 29 finished with value: 0.4025229357798165 and parameters: {'input_dim': 110, 'hidden_dim': 45, 'window_size': 8, 'b_size': 128, 'learning_rate': 0.03951484287134589}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:40:00,987] Trial 30 finished with value: 0.39812691131498473 and parameters: {'input_dim': 104, 'hidden_dim': 45, 'window_size': 8, 'b_size': 127, 'learning_rate': 0.03411599403558146}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:40:19,065] Trial 31 finished with value: 0.39621559633027525 and parameters: {'input_dim': 94, 'hidden_dim': 17, 'window_size': 8, 'b_size': 116, 'learning_rate': 0.06288000824997175}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:40:36,231] Trial 32 finished with value: 0.39392201834862384 and parameters: {'input_dim': 74, 'hidden_dim': 45, 'window_size': 8, 'b_size': 128, 'learning_rate': 0.04302000163085837}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:40:55,705] Trial 33 finished with value: 0.3941131498470948 and parameters: {'input_dim': 130, 'hidden_dim': 43, 'window_size': 9, 'b_size': 84, 'learning_rate': 0.07430413712055188}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:41:13,802] Trial 34 finished with value: 0.39468654434250766 and parameters: {'input_dim': 112, 'hidden_dim': 12, 'window_size': 7, 'b_size': 96, 'learning_rate': 0.09954484192697}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:41:31,770] Trial 35 finished with value: 0.3811162079510703 and parameters: {'input_dim': 63, 'hidden_dim': 20, 'window_size': 9, 'b_size': 112, 'learning_rate': 0.016166232813902334}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:41:51,348] Trial 36 finished with value: 0.3977446483180428 and parameters: {'input_dim': 76, 'hidden_dim': 15, 'window_size': 4, 'b_size': 63, 'learning_rate': 0.01793759767878743}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:42:10,143] Trial 37 finished with value: 0.3941131498470948 and parameters: {'input_dim': 138, 'hidden_dim': 30, 'window_size': 7, 'b_size': 90, 'learning_rate': 0.0269663483835087}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:42:28,752] Trial 38 finished with value: 0.38321865443425074 and parameters: {'input_dim': 62, 'hidden_dim': 50, 'window_size': 8, 'b_size': 93, 'learning_rate': 0.010453437322560048}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:42:45,953] Trial 39 finished with value: 0.39258409785932724 and parameters: {'input_dim': 98, 'hidden_dim': 22, 'window_size': 6, 'b_size': 102, 'learning_rate': 0.03298602572430722}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:43:04,144] Trial 40 finished with value: 0.3973623853211009 and parameters: {'input_dim': 115, 'hidden_dim': 24, 'window_size': 9, 'b_size': 122, 'learning_rate': 0.06406899352855852}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:43:24,037] Trial 41 finished with value: 0.39812691131498473 and parameters: {'input_dim': 150, 'hidden_dim': 23, 'window_size': 7, 'b_size': 82, 'learning_rate': 0.020525637983425195}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:43:44,134] Trial 42 finished with value: 0.3985091743119266 and parameters: {'input_dim': 159, 'hidden_dim': 19, 'window_size': 7, 'b_size': 88, 'learning_rate': 0.028006117405113}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:44:04,218] Trial 43 finished with value: 0.39506880733944955 and parameters: {'input_dim': 170, 'hidden_dim': 28, 'window_size': 5, 'b_size': 73, 'learning_rate': 0.04111022292508895}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:44:22,584] Trial 44 finished with value: 0.4000382262996942 and parameters: {'input_dim': 129, 'hidden_dim': 33, 'window_size': 6, 'b_size': 86, 'learning_rate': 0.024896508995813096}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:44:41,292] Trial 45 finished with value: 0.3958333333333333 and parameters: {'input_dim': 144, 'hidden_dim': 12, 'window_size': 7, 'b_size': 114, 'learning_rate': 0.01534949904588295}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:45:03,809] Trial 46 finished with value: 0.3948776758409786 and parameters: {'input_dim': 179, 'hidden_dim': 22, 'window_size': 3, 'b_size': 49, 'learning_rate': 0.02229290830183817}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:45:21,314] Trial 47 finished with value: 0.39755351681957185 and parameters: {'input_dim': 82, 'hidden_dim': 40, 'window_size': 8, 'b_size': 124, 'learning_rate': 0.037394794240829865}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:45:41,954] Trial 48 finished with value: 0.4036697247706422 and parameters: {'input_dim': 165, 'hidden_dim': 33, 'window_size': 6, 'b_size': 68, 'learning_rate': 0.05222693546666107}. Best is trial 6 with value: 0.40424311926605505.\n",
      "[I 2023-12-22 14:46:02,948] Trial 49 finished with value: 0.39468654434250766 and parameters: {'input_dim': 164, 'hidden_dim': 33, 'window_size': 5, 'b_size': 65, 'learning_rate': 0.05297542470373104}. Best is trial 6 with value: 0.40424311926605505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 141, 'hidden_dim': 16, 'window_size': 3, 'b_size': 124, 'learning_rate': 0.8536189862866826}\n",
      "Best Accuracy: 0.40424311926605505\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.MultiMarginLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    model = Net(input_dim, hidden_dim, output_dim)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335084b2",
   "metadata": {
    "papermill": {
     "duration": 0.081627,
     "end_time": "2023-12-22T14:46:03.203448",
     "exception": false,
     "start_time": "2023-12-22T14:46:03.121821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We got better accuracy using MultiMarginLoss, we keep it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b46559a",
   "metadata": {
    "papermill": {
     "duration": 0.083659,
     "end_time": "2023-12-22T14:46:03.370172",
     "exception": false,
     "start_time": "2023-12-22T14:46:03.286513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next we try to also include weight decay, we will use optuna to tune this hyperaparameter keeping the rest of the hyperparameters as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af2b29af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T14:46:03.552938Z",
     "iopub.status.busy": "2023-12-22T14:46:03.552500Z",
     "iopub.status.idle": "2023-12-22T15:04:14.853126Z",
     "shell.execute_reply": "2023-12-22T15:04:14.851947Z"
    },
    "papermill": {
     "duration": 1091.471665,
     "end_time": "2023-12-22T15:04:14.940786",
     "exception": false,
     "start_time": "2023-12-22T14:46:03.469121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 14:46:03,576] A new study created in memory with name: no-name-10cb47ef-248a-4b61-8f58-46288c9a069c\n",
      "[I 2023-12-22 14:46:22,474] Trial 0 finished with value: 0.3948776758409786 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502, 'weight_decay_new': 0.0004207053950287938}. Best is trial 0 with value: 0.3948776758409786.\n",
      "[I 2023-12-22 14:46:40,781] Trial 1 finished with value: 0.3333333333333333 and parameters: {'input_dim': 58, 'hidden_dim': 45, 'window_size': 7, 'b_size': 100, 'learning_rate': 0.010994335574766204, 'weight_decay_new': 0.7579479953348001}. Best is trial 0 with value: 0.3948776758409786.\n",
      "[I 2023-12-22 14:47:03,925] Trial 2 finished with value: 0.37920489296636084 and parameters: {'input_dim': 175, 'hidden_dim': 18, 'window_size': 4, 'b_size': 49, 'learning_rate': 0.04059611610484305, 'weight_decay_new': 0.012561043700013555}. Best is trial 0 with value: 0.3948776758409786.\n",
      "[I 2023-12-22 14:47:26,212] Trial 3 finished with value: 0.3992737003058104 and parameters: {'input_dim': 115, 'hidden_dim': 21, 'window_size': 7, 'b_size': 45, 'learning_rate': 0.03839629299804171, 'weight_decay_new': 0.002920433847181412}. Best is trial 3 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 14:47:45,852] Trial 4 finished with value: 0.39870030581039756 and parameters: {'input_dim': 118, 'hidden_dim': 42, 'window_size': 4, 'b_size': 81, 'learning_rate': 0.15304852121831464, 'weight_decay_new': 0.00015339162591163628}. Best is trial 3 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 14:48:06,500] Trial 5 finished with value: 0.3333333333333333 and parameters: {'input_dim': 141, 'hidden_dim': 16, 'window_size': 3, 'b_size': 124, 'learning_rate': 0.8536189862866826, 'weight_decay_new': 0.17123375973163968}. Best is trial 3 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 14:48:26,416] Trial 6 finished with value: 0.389717125382263 and parameters: {'input_dim': 95, 'hidden_dim': 14, 'window_size': 8, 'b_size': 74, 'learning_rate': 0.017541893487450794, 'weight_decay_new': 0.009565499215943823}. Best is trial 3 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 14:48:44,432] Trial 7 finished with value: 0.38837920489296635 and parameters: {'input_dim': 55, 'hidden_dim': 47, 'window_size': 5, 'b_size': 96, 'learning_rate': 0.0420167205437253, 'weight_decay_new': 0.012030178871154668}. Best is trial 3 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 14:49:07,889] Trial 8 finished with value: 0.3333333333333333 and parameters: {'input_dim': 132, 'hidden_dim': 17, 'window_size': 10, 'b_size': 107, 'learning_rate': 0.7568292060167615, 'weight_decay_new': 0.3795853142670636}. Best is trial 3 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 14:49:30,341] Trial 9 finished with value: 0.40061162079510704 and parameters: {'input_dim': 140, 'hidden_dim': 47, 'window_size': 3, 'b_size': 51, 'learning_rate': 0.01231557172366602, 'weight_decay_new': 0.0020013420622879987}. Best is trial 9 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:49:56,648] Trial 10 finished with value: 0.3988914373088685 and parameters: {'input_dim': 194, 'hidden_dim': 33, 'window_size': 5, 'b_size': 33, 'learning_rate': 0.01069117090175196, 'weight_decay_new': 0.0014382826835546288}. Best is trial 9 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:50:18,634] Trial 11 finished with value: 0.39105504587155965 and parameters: {'input_dim': 152, 'hidden_dim': 27, 'window_size': 6, 'b_size': 58, 'learning_rate': 0.037071339243328685, 'weight_decay_new': 0.0019851686261147822}. Best is trial 9 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 14:50:43,480] Trial 12 finished with value: 0.40118501529051986 and parameters: {'input_dim': 88, 'hidden_dim': 27, 'window_size': 10, 'b_size': 34, 'learning_rate': 0.08932681364423777, 'weight_decay_new': 0.002054114282603829}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:51:09,309] Trial 13 finished with value: 0.39965596330275227 and parameters: {'input_dim': 82, 'hidden_dim': 36, 'window_size': 10, 'b_size': 32, 'learning_rate': 0.14223599816482116, 'weight_decay_new': 0.0005776887907925771}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:51:30,414] Trial 14 finished with value: 0.3937308868501529 and parameters: {'input_dim': 163, 'hidden_dim': 26, 'window_size': 9, 'b_size': 63, 'learning_rate': 0.07707635340209, 'weight_decay_new': 0.0001060620527658235}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:51:52,104] Trial 15 finished with value: 0.38340978593272174 and parameters: {'input_dim': 79, 'hidden_dim': 36, 'window_size': 3, 'b_size': 47, 'learning_rate': 0.23793537960598532, 'weight_decay_new': 0.004987958170942394}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:52:12,179] Trial 16 finished with value: 0.3333333333333333 and parameters: {'input_dim': 87, 'hidden_dim': 41, 'window_size': 6, 'b_size': 66, 'learning_rate': 0.07561184821551395, 'weight_decay_new': 0.040263518532783656}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:52:35,771] Trial 17 finished with value: 0.38685015290519875 and parameters: {'input_dim': 134, 'hidden_dim': 25, 'window_size': 9, 'b_size': 40, 'learning_rate': 0.374330956124385, 'weight_decay_new': 0.0008804967135301856}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:52:56,361] Trial 18 finished with value: 0.39545107033639143 and parameters: {'input_dim': 69, 'hidden_dim': 30, 'window_size': 8, 'b_size': 53, 'learning_rate': 0.0682511815314189, 'weight_decay_new': 0.00030937247925726867}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:53:15,366] Trial 19 finished with value: 0.3916284403669725 and parameters: {'input_dim': 103, 'hidden_dim': 10, 'window_size': 5, 'b_size': 74, 'learning_rate': 0.021914805291808667, 'weight_decay_new': 0.0012383147843302907}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:53:40,583] Trial 20 finished with value: 0.39201070336391436 and parameters: {'input_dim': 185, 'hidden_dim': 50, 'window_size': 9, 'b_size': 40, 'learning_rate': 0.09914968301092247, 'weight_decay_new': 0.0026560800687350995}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:54:05,074] Trial 21 finished with value: 0.3992737003058104 and parameters: {'input_dim': 73, 'hidden_dim': 36, 'window_size': 10, 'b_size': 33, 'learning_rate': 0.14040382358975978, 'weight_decay_new': 0.000586072117186909}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:54:31,954] Trial 22 finished with value: 0.39105504587155965 and parameters: {'input_dim': 92, 'hidden_dim': 38, 'window_size': 10, 'b_size': 32, 'learning_rate': 0.21137349674595193, 'weight_decay_new': 0.0007054352594811968}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:54:56,119] Trial 23 finished with value: 0.3973623853211009 and parameters: {'input_dim': 148, 'hidden_dim': 31, 'window_size': 9, 'b_size': 41, 'learning_rate': 0.057401220186832067, 'weight_decay_new': 0.0004247852044225959}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:55:18,150] Trial 24 finished with value: 0.39506880733944955 and parameters: {'input_dim': 117, 'hidden_dim': 42, 'window_size': 10, 'b_size': 57, 'learning_rate': 0.11503796004774824, 'weight_decay_new': 0.0002510997947796734}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:55:41,194] Trial 25 finished with value: 0.3820718654434251 and parameters: {'input_dim': 104, 'hidden_dim': 24, 'window_size': 8, 'b_size': 39, 'learning_rate': 0.31336145269393095, 'weight_decay_new': 0.0009126704124098421}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:56:02,193] Trial 26 finished with value: 0.39392201834862384 and parameters: {'input_dim': 65, 'hidden_dim': 29, 'window_size': 4, 'b_size': 50, 'learning_rate': 0.027530476096257004, 'weight_decay_new': 0.004403586012812889}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:56:22,634] Trial 27 finished with value: 0.39965596330275227 and parameters: {'input_dim': 82, 'hidden_dim': 34, 'window_size': 7, 'b_size': 66, 'learning_rate': 0.052266765641731584, 'weight_decay_new': 0.0013812945069281832}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:56:44,582] Trial 28 finished with value: 0.39870030581039756 and parameters: {'input_dim': 160, 'hidden_dim': 38, 'window_size': 9, 'b_size': 56, 'learning_rate': 0.09170495575270589, 'weight_decay_new': 0.00022218910110679955}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:57:03,766] Trial 29 finished with value: 0.396980122324159 and parameters: {'input_dim': 128, 'hidden_dim': 45, 'window_size': 10, 'b_size': 83, 'learning_rate': 0.025807516258396987, 'weight_decay_new': 0.0004443580842215914}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:57:28,391] Trial 30 finished with value: 0.39315749235474007 and parameters: {'input_dim': 101, 'hidden_dim': 21, 'window_size': 6, 'b_size': 32, 'learning_rate': 0.01426366090709401, 'weight_decay_new': 0.0006488614657768919}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:57:48,731] Trial 31 finished with value: 0.39946483180428133 and parameters: {'input_dim': 82, 'hidden_dim': 33, 'window_size': 7, 'b_size': 66, 'learning_rate': 0.054139087398467546, 'weight_decay_new': 0.0017795841334832666}. Best is trial 12 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 14:58:11,440] Trial 32 finished with value: 0.40214067278287463 and parameters: {'input_dim': 77, 'hidden_dim': 33, 'window_size': 8, 'b_size': 43, 'learning_rate': 0.013672602041970959, 'weight_decay_new': 0.0012868593371167642}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 14:58:34,199] Trial 33 finished with value: 0.39659785932721714 and parameters: {'input_dim': 62, 'hidden_dim': 28, 'window_size': 8, 'b_size': 44, 'learning_rate': 0.01423074987583923, 'weight_decay_new': 0.0035647886744112228}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 14:58:57,796] Trial 34 finished with value: 0.3944954128440367 and parameters: {'input_dim': 50, 'hidden_dim': 22, 'window_size': 9, 'b_size': 37, 'learning_rate': 0.013953552832617754, 'weight_decay_new': 0.0009064059267801794}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 14:59:20,077] Trial 35 finished with value: 0.3893348623853211 and parameters: {'input_dim': 112, 'hidden_dim': 45, 'window_size': 8, 'b_size': 48, 'learning_rate': 0.029569022683342508, 'weight_decay_new': 0.002204814107938837}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 14:59:42,997] Trial 36 finished with value: 0.39659785932721714 and parameters: {'input_dim': 93, 'hidden_dim': 40, 'window_size': 10, 'b_size': 45, 'learning_rate': 0.010390159160537364, 'weight_decay_new': 0.005768045138331805}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:00:03,839] Trial 37 finished with value: 0.3937308868501529 and parameters: {'input_dim': 74, 'hidden_dim': 31, 'window_size': 3, 'b_size': 51, 'learning_rate': 0.02050168767955149, 'weight_decay_new': 0.0003444571620743398}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:00:22,364] Trial 38 finished with value: 0.39659785932721714 and parameters: {'input_dim': 123, 'hidden_dim': 44, 'window_size': 7, 'b_size': 111, 'learning_rate': 0.018534425336699, 'weight_decay_new': 0.0024693207948723755}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:00:46,352] Trial 39 finished with value: 0.39258409785932724 and parameters: {'input_dim': 111, 'hidden_dim': 50, 'window_size': 4, 'b_size': 36, 'learning_rate': 0.01372326732466002, 'weight_decay_new': 0.0065610218691256154}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:01:09,901] Trial 40 finished with value: 0.39468654434250766 and parameters: {'input_dim': 140, 'hidden_dim': 23, 'window_size': 9, 'b_size': 43, 'learning_rate': 0.010052906961011554, 'weight_decay_new': 0.0032639746357419116}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:01:30,788] Trial 41 finished with value: 0.39353975535168195 and parameters: {'input_dim': 82, 'hidden_dim': 34, 'window_size': 6, 'b_size': 61, 'learning_rate': 0.047614303488279004, 'weight_decay_new': 0.0011508530343510347}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:01:50,631] Trial 42 finished with value: 0.3948776758409786 and parameters: {'input_dim': 87, 'hidden_dim': 35, 'window_size': 8, 'b_size': 75, 'learning_rate': 0.0327558041799918, 'weight_decay_new': 0.0015594834043457996}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:02:10,900] Trial 43 finished with value: 0.3952599388379205 and parameters: {'input_dim': 61, 'hidden_dim': 38, 'window_size': 7, 'b_size': 68, 'learning_rate': 0.04204680987117971, 'weight_decay_new': 0.0014207896471200064}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:02:31,975] Trial 44 finished with value: 0.39812691131498473 and parameters: {'input_dim': 98, 'hidden_dim': 32, 'window_size': 5, 'b_size': 52, 'learning_rate': 0.023428358401410134, 'weight_decay_new': 0.0005646336170491439}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:02:49,767] Trial 45 finished with value: 0.39659785932721714 and parameters: {'input_dim': 71, 'hidden_dim': 27, 'window_size': 7, 'b_size': 88, 'learning_rate': 0.034781694185237785, 'weight_decay_new': 0.0001805761022320736}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:03:13,368] Trial 46 finished with value: 0.3988914373088685 and parameters: {'input_dim': 56, 'hidden_dim': 47, 'window_size': 7, 'b_size': 37, 'learning_rate': 0.017604767011989264, 'weight_decay_new': 0.0018807973166475723}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:03:33,100] Trial 47 finished with value: 0.3958333333333333 and parameters: {'input_dim': 79, 'hidden_dim': 19, 'window_size': 10, 'b_size': 70, 'learning_rate': 0.11240622968540169, 'weight_decay_new': 0.0010651589448685802}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:03:53,360] Trial 48 finished with value: 0.3872324159021407 and parameters: {'input_dim': 90, 'hidden_dim': 39, 'window_size': 4, 'b_size': 61, 'learning_rate': 0.057610886034295844, 'weight_decay_new': 0.010447859116136425}. Best is trial 32 with value: 0.40214067278287463.\n",
      "[I 2023-12-22 15:04:14,844] Trial 49 finished with value: 0.3878058103975535 and parameters: {'input_dim': 163, 'hidden_dim': 43, 'window_size': 6, 'b_size': 55, 'learning_rate': 0.08407170086460108, 'weight_decay_new': 0.0029280894706420857}. Best is trial 32 with value: 0.40214067278287463.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 77, 'hidden_dim': 33, 'window_size': 8, 'b_size': 43, 'learning_rate': 0.013672602041970959, 'weight_decay_new': 0.0012868593371167642}\n",
      "Best Accuracy: 0.40214067278287463\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.MultiMarginLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    weight_decay_new = trial.suggest_float('weight_decay_new', 1e-4, 1, log=True)\n",
    "    model = Net(input_dim, hidden_dim, output_dim)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate,weight_decay=weight_decay_new)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee1cc6",
   "metadata": {
    "papermill": {
     "duration": 0.086222,
     "end_time": "2023-12-22T15:04:15.115304",
     "exception": false,
     "start_time": "2023-12-22T15:04:15.029082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Pretty close but not better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb582027",
   "metadata": {
    "papermill": {
     "duration": 0.08703,
     "end_time": "2023-12-22T15:04:15.289303",
     "exception": false,
     "start_time": "2023-12-22T15:04:15.202273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next try to use another activation function like LeakyReLU, optimize negative slope using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28d1c926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T15:04:15.467034Z",
     "iopub.status.busy": "2023-12-22T15:04:15.466352Z",
     "iopub.status.idle": "2023-12-22T15:22:01.492684Z",
     "shell.execute_reply": "2023-12-22T15:22:01.491620Z"
    },
    "papermill": {
     "duration": 1066.208586,
     "end_time": "2023-12-22T15:22:01.586209",
     "exception": false,
     "start_time": "2023-12-22T15:04:15.377623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 15:04:15,491] A new study created in memory with name: no-name-3e02754a-e804-420a-9e5d-cd84625f7f6e\n",
      "[I 2023-12-22 15:04:33,796] Trial 0 finished with value: 0.3985091743119266 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502, 'negative_slope': 0.055238410897498764}. Best is trial 0 with value: 0.3985091743119266.\n",
      "[I 2023-12-22 15:04:52,263] Trial 1 finished with value: 0.38589449541284404 and parameters: {'input_dim': 58, 'hidden_dim': 45, 'window_size': 7, 'b_size': 100, 'learning_rate': 0.010994335574766204, 'negative_slope': 0.29127385712697834}. Best is trial 0 with value: 0.3985091743119266.\n",
      "[I 2023-12-22 15:05:14,707] Trial 2 finished with value: 0.3916284403669725 and parameters: {'input_dim': 175, 'hidden_dim': 18, 'window_size': 4, 'b_size': 49, 'learning_rate': 0.04059611610484305, 'negative_slope': 0.16217936517334897}. Best is trial 0 with value: 0.3985091743119266.\n",
      "[I 2023-12-22 15:05:36,688] Trial 3 finished with value: 0.39908256880733944 and parameters: {'input_dim': 115, 'hidden_dim': 21, 'window_size': 7, 'b_size': 45, 'learning_rate': 0.03839629299804171, 'negative_slope': 0.11624493455517058}. Best is trial 3 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 15:05:56,838] Trial 4 finished with value: 0.3929663608562691 and parameters: {'input_dim': 118, 'hidden_dim': 42, 'window_size': 4, 'b_size': 81, 'learning_rate': 0.15304852121831464, 'negative_slope': 0.02347061968879934}. Best is trial 3 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 15:06:14,561] Trial 5 finished with value: 0.39392201834862384 and parameters: {'input_dim': 141, 'hidden_dim': 16, 'window_size': 3, 'b_size': 124, 'learning_rate': 0.8536189862866826, 'negative_slope': 0.24443523095377373}. Best is trial 3 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 15:06:34,459] Trial 6 finished with value: 0.39048165137614677 and parameters: {'input_dim': 95, 'hidden_dim': 14, 'window_size': 8, 'b_size': 74, 'learning_rate': 0.017541893487450794, 'negative_slope': 0.15360130393226834}. Best is trial 3 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 15:06:52,555] Trial 7 finished with value: 0.3985091743119266 and parameters: {'input_dim': 55, 'hidden_dim': 47, 'window_size': 5, 'b_size': 96, 'learning_rate': 0.0420167205437253, 'negative_slope': 0.16081972614156514}. Best is trial 3 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 15:07:10,902] Trial 8 finished with value: 0.3958333333333333 and parameters: {'input_dim': 132, 'hidden_dim': 17, 'window_size': 10, 'b_size': 107, 'learning_rate': 0.7568292060167615, 'negative_slope': 0.26949993162401814}. Best is trial 3 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 15:07:32,830] Trial 9 finished with value: 0.4009938837920489 and parameters: {'input_dim': 140, 'hidden_dim': 47, 'window_size': 3, 'b_size': 51, 'learning_rate': 0.01231557172366602, 'negative_slope': 0.10434579592134664}. Best is trial 9 with value: 0.4009938837920489.\n",
      "[I 2023-12-22 15:07:58,554] Trial 10 finished with value: 0.3973623853211009 and parameters: {'input_dim': 194, 'hidden_dim': 33, 'window_size': 5, 'b_size': 33, 'learning_rate': 0.01069117090175196, 'negative_slope': 0.09394370824993133}. Best is trial 9 with value: 0.4009938837920489.\n",
      "[I 2023-12-22 15:08:20,123] Trial 11 finished with value: 0.3983180428134557 and parameters: {'input_dim': 152, 'hidden_dim': 27, 'window_size': 6, 'b_size': 58, 'learning_rate': 0.037071339243328685, 'negative_slope': 0.10409031171229594}. Best is trial 9 with value: 0.4009938837920489.\n",
      "[I 2023-12-22 15:08:44,568] Trial 12 finished with value: 0.39545107033639143 and parameters: {'input_dim': 88, 'hidden_dim': 27, 'window_size': 10, 'b_size': 34, 'learning_rate': 0.08932681364423777, 'negative_slope': 0.1051652836682307}. Best is trial 9 with value: 0.4009938837920489.\n",
      "[I 2023-12-22 15:09:06,761] Trial 13 finished with value: 0.400802752293578 and parameters: {'input_dim': 154, 'hidden_dim': 36, 'window_size': 7, 'b_size': 56, 'learning_rate': 0.022016589777937627, 'negative_slope': 0.07282520082495694}. Best is trial 9 with value: 0.4009938837920489.\n",
      "[I 2023-12-22 15:09:27,744] Trial 14 finished with value: 0.3988914373088685 and parameters: {'input_dim': 165, 'hidden_dim': 37, 'window_size': 8, 'b_size': 65, 'learning_rate': 0.01932468820491489, 'negative_slope': 0.011853102056576734}. Best is trial 9 with value: 0.4009938837920489.\n",
      "[I 2023-12-22 15:09:48,950] Trial 15 finished with value: 0.40118501529051986 and parameters: {'input_dim': 200, 'hidden_dim': 40, 'window_size': 3, 'b_size': 59, 'learning_rate': 0.011440652293717107, 'negative_slope': 0.056263960508985536}. Best is trial 15 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:10:09,539] Trial 16 finished with value: 0.3927752293577982 and parameters: {'input_dim': 197, 'hidden_dim': 41, 'window_size': 3, 'b_size': 69, 'learning_rate': 0.011503135097893302, 'negative_slope': 0.047965626381121174}. Best is trial 15 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:10:33,281] Trial 17 finished with value: 0.3988914373088685 and parameters: {'input_dim': 179, 'hidden_dim': 50, 'window_size': 3, 'b_size': 43, 'learning_rate': 0.010999279145288376, 'negative_slope': 0.043181344625117704}. Best is trial 15 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:10:51,244] Trial 18 finished with value: 0.39392201834862384 and parameters: {'input_dim': 69, 'hidden_dim': 41, 'window_size': 4, 'b_size': 81, 'learning_rate': 0.07394452856341444, 'negative_slope': 0.07337311103826519}. Best is trial 15 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:11:13,519] Trial 19 finished with value: 0.39717125382262997 and parameters: {'input_dim': 185, 'hidden_dim': 10, 'window_size': 5, 'b_size': 59, 'learning_rate': 0.18140837457893846, 'negative_slope': 0.12812863990990958}. Best is trial 15 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:11:35,252] Trial 20 finished with value: 0.39965596330275227 and parameters: {'input_dim': 136, 'hidden_dim': 37, 'window_size': 3, 'b_size': 50, 'learning_rate': 0.02784150538546708, 'negative_slope': 0.07415064282136179}. Best is trial 15 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:11:57,358] Trial 21 finished with value: 0.3985091743119266 and parameters: {'input_dim': 158, 'hidden_dim': 35, 'window_size': 6, 'b_size': 58, 'learning_rate': 0.01531325258822313, 'negative_slope': 0.07521305234789757}. Best is trial 15 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:12:19,747] Trial 22 finished with value: 0.39048165137614677 and parameters: {'input_dim': 146, 'hidden_dim': 30, 'window_size': 9, 'b_size': 54, 'learning_rate': 0.02304525419065275, 'negative_slope': 0.030913068887929773}. Best is trial 15 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:12:43,657] Trial 23 finished with value: 0.39870030581039756 and parameters: {'input_dim': 164, 'hidden_dim': 43, 'window_size': 4, 'b_size': 40, 'learning_rate': 0.015229369277448149, 'negative_slope': 0.05741004392852052}. Best is trial 15 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:13:04,452] Trial 24 finished with value: 0.3918195718654434 and parameters: {'input_dim': 127, 'hidden_dim': 39, 'window_size': 6, 'b_size': 66, 'learning_rate': 0.02568750058564725, 'negative_slope': 0.08508032482984254}. Best is trial 15 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:13:25,002] Trial 25 finished with value: 0.39258409785932724 and parameters: {'input_dim': 171, 'hidden_dim': 32, 'window_size': 7, 'b_size': 74, 'learning_rate': 0.014746402245549767, 'negative_slope': 0.1328587039107384}. Best is trial 15 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:13:46,965] Trial 26 finished with value: 0.40672782874617736 and parameters: {'input_dim': 185, 'hidden_dim': 45, 'window_size': 5, 'b_size': 64, 'learning_rate': 0.010615964911199536, 'negative_slope': 0.015426354211159066}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:14:08,708] Trial 27 finished with value: 0.39984709480122327 and parameters: {'input_dim': 190, 'hidden_dim': 46, 'window_size': 4, 'b_size': 63, 'learning_rate': 0.01075594701209919, 'negative_slope': 0.011646269336681832}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:14:29,504] Trial 28 finished with value: 0.3941131498470948 and parameters: {'input_dim': 184, 'hidden_dim': 49, 'window_size': 5, 'b_size': 84, 'learning_rate': 0.014875821789496488, 'negative_slope': 0.034797770660315905}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:14:48,944] Trial 29 finished with value: 0.39468654434250766 and parameters: {'input_dim': 103, 'hidden_dim': 45, 'window_size': 3, 'b_size': 73, 'learning_rate': 0.02688858778376758, 'negative_slope': 0.056960648713996566}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:15:08,618] Trial 30 finished with value: 0.3973623853211009 and parameters: {'input_dim': 200, 'hidden_dim': 50, 'window_size': 4, 'b_size': 89, 'learning_rate': 0.01918759419612378, 'negative_slope': 0.04458673793792212}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:15:31,515] Trial 31 finished with value: 0.39793577981651373 and parameters: {'input_dim': 155, 'hidden_dim': 38, 'window_size': 6, 'b_size': 49, 'learning_rate': 0.01369274366487654, 'negative_slope': 0.06324622885297765}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:15:55,836] Trial 32 finished with value: 0.3988914373088685 and parameters: {'input_dim': 171, 'hidden_dim': 43, 'window_size': 7, 'b_size': 40, 'learning_rate': 0.010065429963501245, 'negative_slope': 0.08956720126597244}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:16:17,800] Trial 33 finished with value: 0.3944954128440367 and parameters: {'input_dim': 149, 'hidden_dim': 47, 'window_size': 9, 'b_size': 54, 'learning_rate': 0.02113731453003587, 'negative_slope': 0.027458025233070033}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:16:39,777] Trial 34 finished with value: 0.3992737003058104 and parameters: {'input_dim': 179, 'hidden_dim': 44, 'window_size': 5, 'b_size': 61, 'learning_rate': 0.013488961342056448, 'negative_slope': 0.05741319699255525}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:17:01,641] Trial 35 finished with value: 0.3973623853211009 and parameters: {'input_dim': 160, 'hidden_dim': 35, 'window_size': 7, 'b_size': 53, 'learning_rate': 0.018000271229064, 'negative_slope': 0.010846949394121355}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:17:21,349] Trial 36 finished with value: 0.3908639143730887 and parameters: {'input_dim': 116, 'hidden_dim': 40, 'window_size': 3, 'b_size': 70, 'learning_rate': 0.010161988769654606, 'negative_slope': 0.0364985690973257}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:17:43,917] Trial 37 finished with value: 0.39659785932721714 and parameters: {'input_dim': 142, 'hidden_dim': 22, 'window_size': 4, 'b_size': 48, 'learning_rate': 0.013260621085596731, 'negative_slope': 0.07150789162591517}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:18:04,782] Trial 38 finished with value: 0.3952599388379205 and parameters: {'input_dim': 188, 'hidden_dim': 45, 'window_size': 3, 'b_size': 77, 'learning_rate': 0.018534425336699, 'negative_slope': 0.11452823915247468}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:18:23,766] Trial 39 finished with value: 0.39717125382262997 and parameters: {'input_dim': 170, 'hidden_dim': 35, 'window_size': 8, 'b_size': 107, 'learning_rate': 0.03350535121359918, 'negative_slope': 0.08732443171715593}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:18:47,391] Trial 40 finished with value: 0.3973623853211009 and parameters: {'input_dim': 124, 'hidden_dim': 48, 'window_size': 5, 'b_size': 43, 'learning_rate': 0.022689212191253826, 'negative_slope': 0.027186018907510386}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:19:09,504] Trial 41 finished with value: 0.39870030581039756 and parameters: {'input_dim': 191, 'hidden_dim': 46, 'window_size': 4, 'b_size': 63, 'learning_rate': 0.011649148463495455, 'negative_slope': 0.01735341354743375}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:19:31,200] Trial 42 finished with value: 0.4019495412844037 and parameters: {'input_dim': 192, 'hidden_dim': 42, 'window_size': 4, 'b_size': 55, 'learning_rate': 0.010008865849083705, 'negative_slope': 0.01030186018530269}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:19:53,217] Trial 43 finished with value: 0.40022935779816515 and parameters: {'input_dim': 200, 'hidden_dim': 42, 'window_size': 3, 'b_size': 55, 'learning_rate': 0.015908050225273033, 'negative_slope': 0.03920395851044788}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:20:17,599] Trial 44 finished with value: 0.39984709480122327 and parameters: {'input_dim': 179, 'hidden_dim': 39, 'window_size': 4, 'b_size': 38, 'learning_rate': 0.013270960172752002, 'negative_slope': 0.047711928728885286}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:20:40,304] Trial 45 finished with value: 0.39908256880733944 and parameters: {'input_dim': 194, 'hidden_dim': 43, 'window_size': 4, 'b_size': 47, 'learning_rate': 0.017653957521695726, 'negative_slope': 0.02494421154785481}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:20:58,092] Trial 46 finished with value: 0.39048165137614677 and parameters: {'input_dim': 138, 'hidden_dim': 32, 'window_size': 3, 'b_size': 124, 'learning_rate': 0.012541525417801064, 'negative_slope': 0.02162269059291804}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:21:17,895] Trial 47 finished with value: 0.40022935779816515 and parameters: {'input_dim': 107, 'hidden_dim': 41, 'window_size': 6, 'b_size': 69, 'learning_rate': 0.01061069917563599, 'negative_slope': 0.05153027839533614}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:21:39,984] Trial 48 finished with value: 0.3988914373088685 and parameters: {'input_dim': 180, 'hidden_dim': 48, 'window_size': 5, 'b_size': 58, 'learning_rate': 0.016935609916534602, 'negative_slope': 0.06658864692705334}. Best is trial 26 with value: 0.40672782874617736.\n",
      "[I 2023-12-22 15:22:01,486] Trial 49 finished with value: 0.3958333333333333 and parameters: {'input_dim': 165, 'hidden_dim': 27, 'window_size': 3, 'b_size': 51, 'learning_rate': 0.012573622240689674, 'negative_slope': 0.10131796573334897}. Best is trial 26 with value: 0.40672782874617736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 185, 'hidden_dim': 45, 'window_size': 5, 'b_size': 64, 'learning_rate': 0.010615964911199536, 'negative_slope': 0.015426354211159066}\n",
      "Best Accuracy: 0.40672782874617736\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.MultiMarginLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out,negative_slope):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    negative_slope = trial.suggest_float('negative_slope', 0.01, 0.3)\n",
    "    model = Net(input_dim, hidden_dim, output_dim,negative_slope=negative_slope)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7a0d6",
   "metadata": {
    "papermill": {
     "duration": 0.091309,
     "end_time": "2023-12-22T15:22:01.769950",
     "exception": false,
     "start_time": "2023-12-22T15:22:01.678641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Slightly better, we keep it "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab386941",
   "metadata": {
    "papermill": {
     "duration": 0.092355,
     "end_time": "2023-12-22T15:22:01.953630",
     "exception": false,
     "start_time": "2023-12-22T15:22:01.861275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will also check Tanh activattion function and stop with activation functions so we can proceed to next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df6b2693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T15:22:02.225816Z",
     "iopub.status.busy": "2023-12-22T15:22:02.225050Z",
     "iopub.status.idle": "2023-12-22T15:37:57.645978Z",
     "shell.execute_reply": "2023-12-22T15:37:57.644877Z"
    },
    "papermill": {
     "duration": 955.695022,
     "end_time": "2023-12-22T15:37:57.740367",
     "exception": false,
     "start_time": "2023-12-22T15:22:02.045345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 15:22:02,250] A new study created in memory with name: no-name-24d25c39-bf25-4535-b265-80fe40733d2b\n",
      "[I 2023-12-22 15:22:20,904] Trial 0 finished with value: 0.39965596330275227 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502}. Best is trial 0 with value: 0.39965596330275227.\n",
      "[I 2023-12-22 15:22:38,747] Trial 1 finished with value: 0.3988914373088685 and parameters: {'input_dim': 73, 'hidden_dim': 12, 'window_size': 9, 'b_size': 90, 'learning_rate': 0.2607024758370766}. Best is trial 0 with value: 0.39965596330275227.\n",
      "[I 2023-12-22 15:23:00,002] Trial 2 finished with value: 0.39659785932721714 and parameters: {'input_dim': 53, 'hidden_dim': 49, 'window_size': 9, 'b_size': 52, 'learning_rate': 0.02310201887845294}. Best is trial 0 with value: 0.39965596330275227.\n",
      "[I 2023-12-22 15:23:19,581] Trial 3 finished with value: 0.40061162079510704 and parameters: {'input_dim': 77, 'hidden_dim': 22, 'window_size': 7, 'b_size': 73, 'learning_rate': 0.038234752246751866}. Best is trial 3 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 15:23:39,832] Trial 4 finished with value: 0.39392201834862384 and parameters: {'input_dim': 142, 'hidden_dim': 15, 'window_size': 5, 'b_size': 67, 'learning_rate': 0.08168455894760163}. Best is trial 3 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 15:23:59,637] Trial 5 finished with value: 0.39793577981651373 and parameters: {'input_dim': 168, 'hidden_dim': 18, 'window_size': 7, 'b_size': 89, 'learning_rate': 0.012385137298860933}. Best is trial 3 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 15:24:17,379] Trial 6 finished with value: 0.39315749235474007 and parameters: {'input_dim': 141, 'hidden_dim': 16, 'window_size': 3, 'b_size': 124, 'learning_rate': 0.8536189862866826}. Best is trial 3 with value: 0.40061162079510704.\n",
      "[I 2023-12-22 15:24:36,383] Trial 7 finished with value: 0.4009938837920489 and parameters: {'input_dim': 172, 'hidden_dim': 22, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695}. Best is trial 7 with value: 0.4009938837920489.\n",
      "[I 2023-12-22 15:24:53,016] Trial 8 finished with value: 0.39105504587155965 and parameters: {'input_dim': 68, 'hidden_dim': 30, 'window_size': 3, 'b_size': 120, 'learning_rate': 0.032927591344236166}. Best is trial 7 with value: 0.4009938837920489.\n",
      "[I 2023-12-22 15:25:12,909] Trial 9 finished with value: 0.3948776758409786 and parameters: {'input_dim': 150, 'hidden_dim': 22, 'window_size': 7, 'b_size': 85, 'learning_rate': 0.02342658105820405}. Best is trial 7 with value: 0.4009938837920489.\n",
      "[I 2023-12-22 15:25:38,414] Trial 10 finished with value: 0.3956422018348624 and parameters: {'input_dim': 197, 'hidden_dim': 38, 'window_size': 5, 'b_size': 33, 'learning_rate': 0.10745871100472208}. Best is trial 7 with value: 0.4009938837920489.\n",
      "[I 2023-12-22 15:25:56,527] Trial 11 finished with value: 0.40061162079510704 and parameters: {'input_dim': 101, 'hidden_dim': 26, 'window_size': 5, 'b_size': 108, 'learning_rate': 0.057439213796957656}. Best is trial 7 with value: 0.4009938837920489.\n",
      "[I 2023-12-22 15:26:17,622] Trial 12 finished with value: 0.3958333333333333 and parameters: {'input_dim': 199, 'hidden_dim': 36, 'window_size': 6, 'b_size': 64, 'learning_rate': 0.04945171531890114}. Best is trial 7 with value: 0.4009938837920489.\n",
      "[I 2023-12-22 15:26:35,668] Trial 13 finished with value: 0.40118501529051986 and parameters: {'input_dim': 106, 'hidden_dim': 24, 'window_size': 10, 'b_size': 104, 'learning_rate': 0.1270727650677546}. Best is trial 13 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:26:54,203] Trial 14 finished with value: 0.3988914373088685 and parameters: {'input_dim': 113, 'hidden_dim': 33, 'window_size': 10, 'b_size': 106, 'learning_rate': 0.15412527657054517}. Best is trial 13 with value: 0.40118501529051986.\n",
      "[I 2023-12-22 15:27:12,552] Trial 15 finished with value: 0.4023318042813456 and parameters: {'input_dim': 168, 'hidden_dim': 27, 'window_size': 4, 'b_size': 114, 'learning_rate': 0.20975457910271644}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:27:31,679] Trial 16 finished with value: 0.39143730886850153 and parameters: {'input_dim': 172, 'hidden_dim': 42, 'window_size': 4, 'b_size': 113, 'learning_rate': 0.23793537960598532}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:27:50,163] Trial 17 finished with value: 0.3977446483180428 and parameters: {'input_dim': 127, 'hidden_dim': 27, 'window_size': 10, 'b_size': 128, 'learning_rate': 0.40495190030897776}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:28:07,737] Trial 18 finished with value: 0.3967889908256881 and parameters: {'input_dim': 99, 'hidden_dim': 30, 'window_size': 6, 'b_size': 100, 'learning_rate': 0.12605752505371942}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:28:25,897] Trial 19 finished with value: 0.3992737003058104 and parameters: {'input_dim': 89, 'hidden_dim': 42, 'window_size': 8, 'b_size': 114, 'learning_rate': 0.1798428501995498}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:28:45,273] Trial 20 finished with value: 0.3985091743119266 and parameters: {'input_dim': 124, 'hidden_dim': 26, 'window_size': 4, 'b_size': 99, 'learning_rate': 0.3552045917659078}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:29:04,533] Trial 21 finished with value: 0.3956422018348624 and parameters: {'input_dim': 174, 'hidden_dim': 21, 'window_size': 4, 'b_size': 101, 'learning_rate': 0.07648064181631282}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:29:22,995] Trial 22 finished with value: 0.3977446483180428 and parameters: {'input_dim': 159, 'hidden_dim': 24, 'window_size': 3, 'b_size': 115, 'learning_rate': 0.09825379992951781}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:29:42,721] Trial 23 finished with value: 0.3977446483180428 and parameters: {'input_dim': 186, 'hidden_dim': 19, 'window_size': 4, 'b_size': 96, 'learning_rate': 0.14553947669174958}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:30:02,284] Trial 24 finished with value: 0.3948776758409786 and parameters: {'input_dim': 127, 'hidden_dim': 30, 'window_size': 3, 'b_size': 77, 'learning_rate': 0.06926892181306116}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:30:21,656] Trial 25 finished with value: 0.39468654434250766 and parameters: {'input_dim': 184, 'hidden_dim': 11, 'window_size': 5, 'b_size': 108, 'learning_rate': 0.09544550637614692}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:30:41,548] Trial 26 finished with value: 0.3956422018348624 and parameters: {'input_dim': 156, 'hidden_dim': 34, 'window_size': 9, 'b_size': 118, 'learning_rate': 0.18878488862835482}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:31:00,980] Trial 27 finished with value: 0.39602446483180426 and parameters: {'input_dim': 136, 'hidden_dim': 27, 'window_size': 6, 'b_size': 82, 'learning_rate': 0.13040227125969808}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:31:20,335] Trial 28 finished with value: 0.3885703363914373 and parameters: {'input_dim': 184, 'hidden_dim': 14, 'window_size': 4, 'b_size': 96, 'learning_rate': 0.056910368056209186}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:31:39,006] Trial 29 finished with value: 0.39793577981651373 and parameters: {'input_dim': 113, 'hidden_dim': 20, 'window_size': 8, 'b_size': 92, 'learning_rate': 0.10398745650170524}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:31:57,338] Trial 30 finished with value: 0.39946483180428133 and parameters: {'input_dim': 160, 'hidden_dim': 24, 'window_size': 3, 'b_size': 107, 'learning_rate': 0.041600355787998596}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:32:17,132] Trial 31 finished with value: 0.39755351681957185 and parameters: {'input_dim': 82, 'hidden_dim': 23, 'window_size': 7, 'b_size': 72, 'learning_rate': 0.04425116126181911}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:32:36,810] Trial 32 finished with value: 0.389717125382263 and parameters: {'input_dim': 70, 'hidden_dim': 18, 'window_size': 10, 'b_size': 56, 'learning_rate': 0.03276359991112298}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:32:56,163] Trial 33 finished with value: 0.39908256880733944 and parameters: {'input_dim': 60, 'hidden_dim': 30, 'window_size': 9, 'b_size': 75, 'learning_rate': 0.06995908614477798}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:33:15,132] Trial 34 finished with value: 0.3952599388379205 and parameters: {'input_dim': 91, 'hidden_dim': 24, 'window_size': 8, 'b_size': 85, 'learning_rate': 0.08362834679684716}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:33:35,383] Trial 35 finished with value: 0.39545107033639143 and parameters: {'input_dim': 84, 'hidden_dim': 17, 'window_size': 5, 'b_size': 59, 'learning_rate': 0.21380318633507323}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:33:57,039] Trial 36 finished with value: 0.393348623853211 and parameters: {'input_dim': 113, 'hidden_dim': 14, 'window_size': 9, 'b_size': 47, 'learning_rate': 0.014792265898564104}. Best is trial 15 with value: 0.4023318042813456.\n",
      "[I 2023-12-22 15:34:15,341] Trial 37 finished with value: 0.40271406727828746 and parameters: {'input_dim': 58, 'hidden_dim': 28, 'window_size': 7, 'b_size': 90, 'learning_rate': 0.2805587308809858}. Best is trial 37 with value: 0.40271406727828746.\n",
      "[I 2023-12-22 15:34:33,415] Trial 38 finished with value: 0.3943042813455658 and parameters: {'input_dim': 54, 'hidden_dim': 33, 'window_size': 6, 'b_size': 91, 'learning_rate': 0.25507188965695315}. Best is trial 37 with value: 0.40271406727828746.\n",
      "[I 2023-12-22 15:34:51,289] Trial 39 finished with value: 0.3988914373088685 and parameters: {'input_dim': 145, 'hidden_dim': 28, 'window_size': 7, 'b_size': 122, 'learning_rate': 0.31725078827146924}. Best is trial 37 with value: 0.40271406727828746.\n",
      "[I 2023-12-22 15:35:10,143] Trial 40 finished with value: 0.3941131498470948 and parameters: {'input_dim': 166, 'hidden_dim': 21, 'window_size': 3, 'b_size': 104, 'learning_rate': 0.5128927959509194}. Best is trial 37 with value: 0.40271406727828746.\n",
      "[I 2023-12-22 15:35:30,219] Trial 41 finished with value: 0.39984709480122327 and parameters: {'input_dim': 62, 'hidden_dim': 25, 'window_size': 8, 'b_size': 69, 'learning_rate': 0.17166945281131032}. Best is trial 37 with value: 0.40271406727828746.\n",
      "[I 2023-12-22 15:35:48,326] Trial 42 finished with value: 0.40386085626911317 and parameters: {'input_dim': 51, 'hidden_dim': 22, 'window_size': 7, 'b_size': 87, 'learning_rate': 0.13253687211275184}. Best is trial 42 with value: 0.40386085626911317.\n",
      "[I 2023-12-22 15:36:06,598] Trial 43 finished with value: 0.39812691131498473 and parameters: {'input_dim': 52, 'hidden_dim': 28, 'window_size': 7, 'b_size': 85, 'learning_rate': 0.1271463289358973}. Best is trial 42 with value: 0.40386085626911317.\n",
      "[I 2023-12-22 15:36:24,907] Trial 44 finished with value: 0.3952599388379205 and parameters: {'input_dim': 62, 'hidden_dim': 22, 'window_size': 7, 'b_size': 92, 'learning_rate': 0.16910366921740955}. Best is trial 42 with value: 0.40386085626911317.\n",
      "[I 2023-12-22 15:36:41,917] Trial 45 finished with value: 0.396980122324159 and parameters: {'input_dim': 71, 'hidden_dim': 32, 'window_size': 8, 'b_size': 112, 'learning_rate': 0.27557712695999936}. Best is trial 42 with value: 0.40386085626911317.\n",
      "[I 2023-12-22 15:37:00,554] Trial 46 finished with value: 0.39602446483180426 and parameters: {'input_dim': 77, 'hidden_dim': 19, 'window_size': 9, 'b_size': 79, 'learning_rate': 0.2382337904704297}. Best is trial 42 with value: 0.40386085626911317.\n",
      "[I 2023-12-22 15:37:20,432] Trial 47 finished with value: 0.39870030581039756 and parameters: {'input_dim': 176, 'hidden_dim': 28, 'window_size': 6, 'b_size': 87, 'learning_rate': 0.11324644609794979}. Best is trial 42 with value: 0.40386085626911317.\n",
      "[I 2023-12-22 15:37:39,051] Trial 48 finished with value: 0.4019495412844037 and parameters: {'input_dim': 135, 'hidden_dim': 36, 'window_size': 4, 'b_size': 95, 'learning_rate': 0.19956862775243375}. Best is trial 42 with value: 0.40386085626911317.\n",
      "[I 2023-12-22 15:37:57,636] Trial 49 finished with value: 0.39984709480122327 and parameters: {'input_dim': 134, 'hidden_dim': 39, 'window_size': 5, 'b_size': 102, 'learning_rate': 0.20321338145176218}. Best is trial 42 with value: 0.40386085626911317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 51, 'hidden_dim': 22, 'window_size': 7, 'b_size': 87, 'learning_rate': 0.13253687211275184}\n",
      "Best Accuracy: 0.40386085626911317\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.MultiMarginLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.bn1(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    model = Net(input_dim, hidden_dim, output_dim)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ca939",
   "metadata": {
    "papermill": {
     "duration": 0.097043,
     "end_time": "2023-12-22T15:37:57.933935",
     "exception": false,
     "start_time": "2023-12-22T15:37:57.836892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Nice try but not better, we keep leaky_relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13733b0d",
   "metadata": {
    "papermill": {
     "duration": 0.096675,
     "end_time": "2023-12-22T15:37:58.128773",
     "exception": false,
     "start_time": "2023-12-22T15:37:58.032098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I really want to give a second try to more hidden layers, lets try 2 now and also include dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6836e8aa",
   "metadata": {
    "papermill": {
     "duration": 0.0961,
     "end_time": "2023-12-22T15:37:58.322913",
     "exception": false,
     "start_time": "2023-12-22T15:37:58.226813",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since we we will use optuna for dropout_rate as well, lets double the trials of optuna to 100, there are many hyperparameters we are tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9517641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T15:37:58.519221Z",
     "iopub.status.busy": "2023-12-22T15:37:58.518841Z",
     "iopub.status.idle": "2023-12-22T16:12:08.057824Z",
     "shell.execute_reply": "2023-12-22T16:12:08.056710Z"
    },
    "papermill": {
     "duration": 2049.746255,
     "end_time": "2023-12-22T16:12:08.166028",
     "exception": false,
     "start_time": "2023-12-22T15:37:58.419773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 15:37:58,545] A new study created in memory with name: no-name-6f2df2bc-9fb8-45c5-9f68-79b1bc72860c\n",
      "[I 2023-12-22 15:38:18,640] Trial 0 finished with value: 0.3941131498470948 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502, 'negative_slope': 0.055238410897498764, 'dropout_rate': 0.12323344486727979}. Best is trial 0 with value: 0.3941131498470948.\n",
      "[I 2023-12-22 15:38:48,958] Trial 1 finished with value: 0.3830275229357798 and parameters: {'input_dim': 180, 'hidden_dim': 34, 'window_size': 8, 'b_size': 33, 'learning_rate': 0.8706020878304853, 'negative_slope': 0.2514083658321223, 'dropout_rate': 0.18493564427131048}. Best is trial 0 with value: 0.3941131498470948.\n",
      "[I 2023-12-22 15:39:09,039] Trial 2 finished with value: 0.39602446483180426 and parameters: {'input_dim': 77, 'hidden_dim': 17, 'window_size': 5, 'b_size': 82, 'learning_rate': 0.0730953983591291, 'negative_slope': 0.09445645065743215, 'dropout_rate': 0.34474115788895177}. Best is trial 2 with value: 0.39602446483180426.\n",
      "[I 2023-12-22 15:39:29,270] Trial 3 finished with value: 0.38914373088685017 and parameters: {'input_dim': 71, 'hidden_dim': 21, 'window_size': 5, 'b_size': 76, 'learning_rate': 0.3718364180573207, 'negative_slope': 0.06790539682592432, 'dropout_rate': 0.3056937753654446}. Best is trial 2 with value: 0.39602446483180426.\n",
      "[I 2023-12-22 15:39:53,837] Trial 4 finished with value: 0.36716360856269115 and parameters: {'input_dim': 139, 'hidden_dim': 11, 'window_size': 7, 'b_size': 48, 'learning_rate': 0.013492834268013254, 'negative_slope': 0.2851768058034666, 'dropout_rate': 0.4862528132298237}. Best is trial 2 with value: 0.39602446483180426.\n",
      "[I 2023-12-22 15:40:14,557] Trial 5 finished with value: 0.38990825688073394 and parameters: {'input_dim': 172, 'hidden_dim': 22, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695, 'negative_slope': 0.045391088104985856, 'dropout_rate': 0.29807076404450805}. Best is trial 2 with value: 0.39602446483180426.\n",
      "[I 2023-12-22 15:40:34,242] Trial 6 finished with value: 0.40577217125382264 and parameters: {'input_dim': 55, 'hidden_dim': 47, 'window_size': 5, 'b_size': 96, 'learning_rate': 0.0420167205437253, 'negative_slope': 0.16081972614156514, 'dropout_rate': 0.31868411173731187}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:40:53,486] Trial 7 finished with value: 0.3853211009174312 and parameters: {'input_dim': 77, 'hidden_dim': 49, 'window_size': 9, 'b_size': 123, 'learning_rate': 0.6161049539380962, 'negative_slope': 0.18339099385521468, 'dropout_rate': 0.4687496940092467}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:41:15,292] Trial 8 finished with value: 0.38914373088685017 and parameters: {'input_dim': 63, 'hidden_dim': 18, 'window_size': 3, 'b_size': 63, 'learning_rate': 0.05989003672254302, 'negative_slope': 0.08869121921442981, 'dropout_rate': 0.43149500366077176}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:41:39,776] Trial 9 finished with value: 0.3826452599388379 and parameters: {'input_dim': 103, 'hidden_dim': 21, 'window_size': 7, 'b_size': 45, 'learning_rate': 0.40215545266902863, 'negative_slope': 0.03161968666713354, 'dropout_rate': 0.4947547746402069}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:41:59,721] Trial 10 finished with value: 0.3902905198776758 and parameters: {'input_dim': 127, 'hidden_dim': 38, 'window_size': 5, 'b_size': 116, 'learning_rate': 0.025489108174540396, 'negative_slope': 0.1592469023006462, 'dropout_rate': 0.24452479857672374}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:42:18,738] Trial 11 finished with value: 0.3956422018348624 and parameters: {'input_dim': 51, 'hidden_dim': 40, 'window_size': 5, 'b_size': 102, 'learning_rate': 0.1574843556253375, 'negative_slope': 0.11917328381404649, 'dropout_rate': 0.37255349472403276}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:42:39,744] Trial 12 finished with value: 0.39201070336391436 and parameters: {'input_dim': 90, 'hidden_dim': 30, 'window_size': 4, 'b_size': 77, 'learning_rate': 0.039402020511114126, 'negative_slope': 0.12197938978716842, 'dropout_rate': 0.37417379261573536}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:42:59,165] Trial 13 finished with value: 0.3872324159021407 and parameters: {'input_dim': 51, 'hidden_dim': 29, 'window_size': 6, 'b_size': 108, 'learning_rate': 0.11262313193542736, 'negative_slope': 0.19651507205494576, 'dropout_rate': 0.32126630574990483}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:43:20,470] Trial 14 finished with value: 0.3845565749235474 and parameters: {'input_dim': 148, 'hidden_dim': 10, 'window_size': 6, 'b_size': 85, 'learning_rate': 0.04308155059962879, 'negative_slope': 0.11186967999407033, 'dropout_rate': 0.2489341568285644}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:43:43,044] Trial 15 finished with value: 0.38321865443425074 and parameters: {'input_dim': 87, 'hidden_dim': 43, 'window_size': 4, 'b_size': 63, 'learning_rate': 0.010292173990777483, 'negative_slope': 0.14961956343492283, 'dropout_rate': 0.38702025634351855}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:44:05,052] Trial 16 finished with value: 0.38990825688073394 and parameters: {'input_dim': 107, 'hidden_dim': 26, 'window_size': 4, 'b_size': 68, 'learning_rate': 0.1442554065073416, 'negative_slope': 0.011703544609800207, 'dropout_rate': 0.33600871683115424}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:44:24,021] Trial 17 finished with value: 0.38474770642201833 and parameters: {'input_dim': 66, 'hidden_dim': 16, 'window_size': 10, 'b_size': 91, 'learning_rate': 0.07702910297259304, 'negative_slope': 0.09480408316874518, 'dropout_rate': 0.43111490378301637}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:44:44,129] Trial 18 finished with value: 0.3943042813455658 and parameters: {'input_dim': 88, 'hidden_dim': 44, 'window_size': 6, 'b_size': 109, 'learning_rate': 0.034148738412207925, 'negative_slope': 0.2140609996510292, 'dropout_rate': 0.26271206003292924}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:45:04,477] Trial 19 finished with value: 0.39392201834862384 and parameters: {'input_dim': 161, 'hidden_dim': 34, 'window_size': 5, 'b_size': 96, 'learning_rate': 0.059997760453506195, 'negative_slope': 0.14060048290833654, 'dropout_rate': 0.3509679306459871}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:45:23,887] Trial 20 finished with value: 0.386085626911315 and parameters: {'input_dim': 198, 'hidden_dim': 15, 'window_size': 4, 'b_size': 125, 'learning_rate': 0.021484679180774693, 'negative_slope': 0.07119622580162063, 'dropout_rate': 0.4060660844026041}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:45:43,265] Trial 21 finished with value: 0.39602446483180426 and parameters: {'input_dim': 52, 'hidden_dim': 41, 'window_size': 5, 'b_size': 103, 'learning_rate': 0.1581512286521428, 'negative_slope': 0.12004356303259253, 'dropout_rate': 0.35834017848019667}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:46:02,293] Trial 22 finished with value: 0.38990825688073394 and parameters: {'input_dim': 54, 'hidden_dim': 45, 'window_size': 5, 'b_size': 109, 'learning_rate': 0.19298826820903908, 'negative_slope': 0.09477205622312229, 'dropout_rate': 0.34679595427966753}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:46:22,621] Trial 23 finished with value: 0.3943042813455658 and parameters: {'input_dim': 76, 'hidden_dim': 38, 'window_size': 6, 'b_size': 83, 'learning_rate': 0.11108936014557426, 'negative_slope': 0.13725482685417528, 'dropout_rate': 0.2893303753671179}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:46:42,208] Trial 24 finished with value: 0.3878058103975535 and parameters: {'input_dim': 60, 'hidden_dim': 34, 'window_size': 3, 'b_size': 102, 'learning_rate': 0.2639938045780487, 'negative_slope': 0.16197332180494725, 'dropout_rate': 0.3378770111003914}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:47:02,131] Trial 25 finished with value: 0.38990825688073394 and parameters: {'input_dim': 80, 'hidden_dim': 49, 'window_size': 7, 'b_size': 91, 'learning_rate': 0.08913763636645204, 'negative_slope': 0.11570097346788388, 'dropout_rate': 0.40570772147725936}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:47:24,487] Trial 26 finished with value: 0.3908639143730887 and parameters: {'input_dim': 118, 'hidden_dim': 46, 'window_size': 4, 'b_size': 70, 'learning_rate': 0.053770479247002324, 'negative_slope': 0.17527258793262468, 'dropout_rate': 0.2796996070589694}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:47:42,820] Trial 27 finished with value: 0.38799694189602446 and parameters: {'input_dim': 65, 'hidden_dim': 41, 'window_size': 5, 'b_size': 118, 'learning_rate': 0.11351458491072668, 'negative_slope': 0.13286806606097717, 'dropout_rate': 0.3133688427162665}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:48:01,374] Trial 28 finished with value: 0.3912461773700306 and parameters: {'input_dim': 100, 'hidden_dim': 26, 'window_size': 6, 'b_size': 115, 'learning_rate': 0.20432361882530498, 'negative_slope': 0.10102079722335412, 'dropout_rate': 0.35108991637578263}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:48:21,494] Trial 29 finished with value: 0.393348623853211 and parameters: {'input_dim': 97, 'hidden_dim': 50, 'window_size': 7, 'b_size': 88, 'learning_rate': 0.029423954879957727, 'negative_slope': 0.0788791015094504, 'dropout_rate': 0.22066043027495436}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:48:42,054] Trial 30 finished with value: 0.3956422018348624 and parameters: {'input_dim': 119, 'hidden_dim': 36, 'window_size': 8, 'b_size': 95, 'learning_rate': 0.047507732244859185, 'negative_slope': 0.06645428469902084, 'dropout_rate': 0.1088017347852453}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:49:00,988] Trial 31 finished with value: 0.3943042813455658 and parameters: {'input_dim': 50, 'hidden_dim': 41, 'window_size': 5, 'b_size': 104, 'learning_rate': 0.15828136257215755, 'negative_slope': 0.12265012938144151, 'dropout_rate': 0.37465588034902464}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:49:20,972] Trial 32 finished with value: 0.39545107033639143 and parameters: {'input_dim': 59, 'hidden_dim': 47, 'window_size': 5, 'b_size': 102, 'learning_rate': 0.07602788881442384, 'negative_slope': 0.1060616654694493, 'dropout_rate': 0.3658586081202694}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:49:41,049] Trial 33 finished with value: 0.3889525993883792 and parameters: {'input_dim': 70, 'hidden_dim': 40, 'window_size': 4, 'b_size': 79, 'learning_rate': 0.14715782258135865, 'negative_slope': 0.1293547881632784, 'dropout_rate': 0.3162303457110284}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:50:00,768] Trial 34 finished with value: 0.39602446483180426 and parameters: {'input_dim': 51, 'hidden_dim': 43, 'window_size': 5, 'b_size': 98, 'learning_rate': 0.09545100162106548, 'negative_slope': 0.14882817010742588, 'dropout_rate': 0.3211891723393816}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:50:20,544] Trial 35 finished with value: 0.38398318042813456 and parameters: {'input_dim': 72, 'hidden_dim': 44, 'window_size': 6, 'b_size': 93, 'learning_rate': 0.06692146345929242, 'negative_slope': 0.1486142932783045, 'dropout_rate': 0.2939186882677918}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:50:41,208] Trial 36 finished with value: 0.38914373088685017 and parameters: {'input_dim': 83, 'hidden_dim': 13, 'window_size': 5, 'b_size': 73, 'learning_rate': 0.09751887339980964, 'negative_slope': 0.16489762285629198, 'dropout_rate': 0.3252368807472718}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:51:01,070] Trial 37 finished with value: 0.3937308868501529 and parameters: {'input_dim': 59, 'hidden_dim': 32, 'window_size': 3, 'b_size': 85, 'learning_rate': 0.04890781411968837, 'negative_slope': 0.19749404293886375, 'dropout_rate': 0.30285362922135234}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:51:24,401] Trial 38 finished with value: 0.3948776758409786 and parameters: {'input_dim': 71, 'hidden_dim': 48, 'window_size': 4, 'b_size': 54, 'learning_rate': 0.017904205896308416, 'negative_slope': 0.14642198789819155, 'dropout_rate': 0.16316109632055684}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:51:43,206] Trial 39 finished with value: 0.39067278287461776 and parameters: {'input_dim': 58, 'hidden_dim': 24, 'window_size': 8, 'b_size': 112, 'learning_rate': 0.03738129763270912, 'negative_slope': 0.08189559335628695, 'dropout_rate': 0.2798822222895726}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:52:02,224] Trial 40 finished with value: 0.3941131498470948 and parameters: {'input_dim': 66, 'hidden_dim': 42, 'window_size': 7, 'b_size': 96, 'learning_rate': 0.06766851237433694, 'negative_slope': 0.053067279748584564, 'dropout_rate': 0.32848537663988864}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:52:21,182] Trial 41 finished with value: 0.39621559633027525 and parameters: {'input_dim': 53, 'hidden_dim': 38, 'window_size': 5, 'b_size': 99, 'learning_rate': 0.09347888798119028, 'negative_slope': 0.11310806436700696, 'dropout_rate': 0.3604798600843503}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:52:40,731] Trial 42 finished with value: 0.38742354740061163 and parameters: {'input_dim': 50, 'hidden_dim': 38, 'window_size': 5, 'b_size': 99, 'learning_rate': 0.08581112764696013, 'negative_slope': 0.10583817513211935, 'dropout_rate': 0.3591904535177924}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:53:00,194] Trial 43 finished with value: 0.3964067278287462 and parameters: {'input_dim': 76, 'hidden_dim': 46, 'window_size': 6, 'b_size': 106, 'learning_rate': 0.05743226260399398, 'negative_slope': 0.13635801400267847, 'dropout_rate': 0.3072805175843469}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:53:18,651] Trial 44 finished with value: 0.3881880733944954 and parameters: {'input_dim': 73, 'hidden_dim': 46, 'window_size': 6, 'b_size': 119, 'learning_rate': 0.05705370762667906, 'negative_slope': 0.1306029478946209, 'dropout_rate': 0.30858778719996616}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:53:38,277] Trial 45 finished with value: 0.3889525993883792 and parameters: {'input_dim': 82, 'hidden_dim': 50, 'window_size': 6, 'b_size': 105, 'learning_rate': 0.04433653691536048, 'negative_slope': 0.090779713028014, 'dropout_rate': 0.3431423212692263}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:54:06,457] Trial 46 finished with value: 0.3841743119266055 and parameters: {'input_dim': 91, 'hidden_dim': 36, 'window_size': 5, 'b_size': 36, 'learning_rate': 0.07008223401561656, 'negative_slope': 0.11625128985558589, 'dropout_rate': 0.36580484146285225}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:54:26,464] Trial 47 finished with value: 0.3900993883792049 and parameters: {'input_dim': 109, 'hidden_dim': 20, 'window_size': 6, 'b_size': 87, 'learning_rate': 0.053510844023892744, 'negative_slope': 0.10697991152292483, 'dropout_rate': 0.38412082450898}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:54:45,635] Trial 48 finished with value: 0.3916284403669725 and parameters: {'input_dim': 138, 'hidden_dim': 39, 'window_size': 4, 'b_size': 128, 'learning_rate': 0.036300803490052325, 'negative_slope': 0.12833754422017152, 'dropout_rate': 0.3389986762536601}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:55:06,350] Trial 49 finished with value: 0.39392201834862384 and parameters: {'input_dim': 63, 'hidden_dim': 29, 'window_size': 4, 'b_size': 82, 'learning_rate': 0.12243099786707418, 'negative_slope': 0.15670370397093508, 'dropout_rate': 0.4000871173924508}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:55:25,350] Trial 50 finished with value: 0.39392201834862384 and parameters: {'input_dim': 57, 'hidden_dim': 47, 'window_size': 5, 'b_size': 112, 'learning_rate': 0.03044468855683701, 'negative_slope': 0.08539158081635749, 'dropout_rate': 0.3046407687945252}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:55:45,367] Trial 51 finished with value: 0.39793577981651373 and parameters: {'input_dim': 54, 'hidden_dim': 43, 'window_size': 5, 'b_size': 99, 'learning_rate': 0.09154130588094501, 'negative_slope': 0.1456543351491575, 'dropout_rate': 0.32411455119680166}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:56:04,020] Trial 52 finished with value: 0.3900993883792049 and parameters: {'input_dim': 67, 'hidden_dim': 44, 'window_size': 6, 'b_size': 105, 'learning_rate': 0.08247097142323245, 'negative_slope': 0.1387953868179314, 'dropout_rate': 0.32949526857064365}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:56:23,603] Trial 53 finished with value: 0.38685015290519875 and parameters: {'input_dim': 56, 'hidden_dim': 42, 'window_size': 5, 'b_size': 99, 'learning_rate': 0.06206245295216873, 'negative_slope': 0.12049789719292943, 'dropout_rate': 0.3547708919244786}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:56:43,350] Trial 54 finished with value: 0.3912461773700306 and parameters: {'input_dim': 76, 'hidden_dim': 36, 'window_size': 5, 'b_size': 91, 'learning_rate': 0.10123512070148263, 'negative_slope': 0.1645902532778556, 'dropout_rate': 0.3823120332165751}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:57:03,289] Trial 55 finished with value: 0.3973623853211009 and parameters: {'input_dim': 93, 'hidden_dim': 46, 'window_size': 7, 'b_size': 107, 'learning_rate': 0.12799859176048653, 'negative_slope': 0.09756279947093244, 'dropout_rate': 0.3620991635879164}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:57:23,453] Trial 56 finished with value: 0.3958333333333333 and parameters: {'input_dim': 93, 'hidden_dim': 46, 'window_size': 7, 'b_size': 107, 'learning_rate': 0.07124080750141269, 'negative_slope': 0.09546914274913623, 'dropout_rate': 0.33098472610018054}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:57:42,507] Trial 57 finished with value: 0.3927752293577982 and parameters: {'input_dim': 84, 'hidden_dim': 48, 'window_size': 7, 'b_size': 112, 'learning_rate': 0.12092259860503214, 'negative_slope': 0.13960087348233705, 'dropout_rate': 0.2964492360270932}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:58:02,982] Trial 58 finished with value: 0.3977446483180428 and parameters: {'input_dim': 79, 'hidden_dim': 45, 'window_size': 9, 'b_size': 94, 'learning_rate': 0.04314259249394138, 'negative_slope': 0.11062318813770738, 'dropout_rate': 0.34662497464297687}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:58:22,451] Trial 59 finished with value: 0.39812691131498473 and parameters: {'input_dim': 76, 'hidden_dim': 44, 'window_size': 10, 'b_size': 99, 'learning_rate': 0.04218389956621727, 'negative_slope': 0.10817441087294617, 'dropout_rate': 0.34280596588346984}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:58:41,184] Trial 60 finished with value: 0.3948776758409786 and parameters: {'input_dim': 96, 'hidden_dim': 45, 'window_size': 10, 'b_size': 109, 'learning_rate': 0.04142331080642771, 'negative_slope': 0.10351903082010078, 'dropout_rate': 0.3167933822916275}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:59:00,915] Trial 61 finished with value: 0.39048165137614677 and parameters: {'input_dim': 78, 'hidden_dim': 43, 'window_size': 9, 'b_size': 101, 'learning_rate': 0.05185546522349405, 'negative_slope': 0.12254114516225792, 'dropout_rate': 0.34197323152267406}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:59:21,664] Trial 62 finished with value: 0.3958333333333333 and parameters: {'input_dim': 63, 'hidden_dim': 45, 'window_size': 9, 'b_size': 93, 'learning_rate': 0.05961422231872383, 'negative_slope': 0.11404911619646421, 'dropout_rate': 0.35743260270500893}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 15:59:41,278] Trial 63 finished with value: 0.3881880733944954 and parameters: {'input_dim': 75, 'hidden_dim': 48, 'window_size': 9, 'b_size': 95, 'learning_rate': 0.040410367345582565, 'negative_slope': 0.09904734681179041, 'dropout_rate': 0.369649669067382}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:00:02,400] Trial 64 finished with value: 0.39621559633027525 and parameters: {'input_dim': 87, 'hidden_dim': 47, 'window_size': 10, 'b_size': 88, 'learning_rate': 0.03328526573254907, 'negative_slope': 0.1328808484301563, 'dropout_rate': 0.34312546621222706}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:00:22,110] Trial 65 finished with value: 0.38704128440366975 and parameters: {'input_dim': 104, 'hidden_dim': 50, 'window_size': 10, 'b_size': 100, 'learning_rate': 0.045212878622317196, 'negative_slope': 0.10973490396325017, 'dropout_rate': 0.28194704518626984}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:00:41,231] Trial 66 finished with value: 0.39143730886850153 and parameters: {'input_dim': 112, 'hidden_dim': 42, 'window_size': 8, 'b_size': 120, 'learning_rate': 0.08349770007655678, 'negative_slope': 0.1544930574447749, 'dropout_rate': 0.3913938687708442}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:01:00,140] Trial 67 finished with value: 0.38876146788990823 and parameters: {'input_dim': 69, 'hidden_dim': 40, 'window_size': 9, 'b_size': 107, 'learning_rate': 0.048471020873649656, 'negative_slope': 0.07437624033187362, 'dropout_rate': 0.312142805576639}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:01:21,426] Trial 68 finished with value: 0.39506880733944955 and parameters: {'input_dim': 184, 'hidden_dim': 44, 'window_size': 10, 'b_size': 113, 'learning_rate': 0.06161883704115612, 'negative_slope': 0.08911083790059998, 'dropout_rate': 0.32326641428075287}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:01:41,463] Trial 69 finished with value: 0.39105504587155965 and parameters: {'input_dim': 55, 'hidden_dim': 49, 'window_size': 8, 'b_size': 97, 'learning_rate': 0.026176977804540112, 'negative_slope': 0.17341511322114989, 'dropout_rate': 0.4134291748088519}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:02:01,361] Trial 70 finished with value: 0.3902905198776758 and parameters: {'input_dim': 62, 'hidden_dim': 45, 'window_size': 9, 'b_size': 116, 'learning_rate': 0.08221602505961033, 'negative_slope': 0.13927333232049394, 'dropout_rate': 0.3503777240388797}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:02:22,396] Trial 71 finished with value: 0.39812691131498473 and parameters: {'input_dim': 86, 'hidden_dim': 47, 'window_size': 10, 'b_size': 88, 'learning_rate': 0.031329654392908614, 'negative_slope': 0.13061089369460216, 'dropout_rate': 0.3395751682834479}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:02:42,953] Trial 72 finished with value: 0.3943042813455658 and parameters: {'input_dim': 83, 'hidden_dim': 46, 'window_size': 10, 'b_size': 93, 'learning_rate': 0.033347769982815224, 'negative_slope': 0.11511923155453457, 'dropout_rate': 0.33461145759745325}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:03:04,400] Trial 73 finished with value: 0.39048165137614677 and parameters: {'input_dim': 80, 'hidden_dim': 47, 'window_size': 10, 'b_size': 78, 'learning_rate': 0.02359363229514314, 'negative_slope': 0.14575265625880116, 'dropout_rate': 0.36681640770958984}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:03:25,668] Trial 74 finished with value: 0.39621559633027525 and parameters: {'input_dim': 95, 'hidden_dim': 43, 'window_size': 10, 'b_size': 90, 'learning_rate': 0.03741312482964636, 'negative_slope': 0.1264283875568924, 'dropout_rate': 0.30560041888684614}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:03:45,529] Trial 75 finished with value: 0.3983180428134557 and parameters: {'input_dim': 86, 'hidden_dim': 49, 'window_size': 9, 'b_size': 104, 'learning_rate': 0.052823340582367095, 'negative_slope': 0.10141862588469239, 'dropout_rate': 0.37740172273329425}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:04:04,716] Trial 76 finished with value: 0.39392201834862384 and parameters: {'input_dim': 101, 'hidden_dim': 49, 'window_size': 9, 'b_size': 105, 'learning_rate': 0.04188595829809645, 'negative_slope': 0.10210470544158078, 'dropout_rate': 0.3743580189466136}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:04:25,410] Trial 77 finished with value: 0.39239296636085624 and parameters: {'input_dim': 87, 'hidden_dim': 48, 'window_size': 8, 'b_size': 85, 'learning_rate': 0.05108707420494219, 'negative_slope': 0.09474166645161801, 'dropout_rate': 0.2911585015905183}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:04:45,794] Trial 78 finished with value: 0.38474770642201833 and parameters: {'input_dim': 88, 'hidden_dim': 50, 'window_size': 10, 'b_size': 110, 'learning_rate': 0.031429350112474636, 'negative_slope': 0.13339986346220833, 'dropout_rate': 0.3226380540954656}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:05:05,615] Trial 79 finished with value: 0.3916284403669725 and parameters: {'input_dim': 73, 'hidden_dim': 46, 'window_size': 9, 'b_size': 94, 'learning_rate': 0.04482207144676104, 'negative_slope': 0.06508115102365661, 'dropout_rate': 0.3487223808382468}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:05:25,129] Trial 80 finished with value: 0.3958333333333333 and parameters: {'input_dim': 98, 'hidden_dim': 44, 'window_size': 9, 'b_size': 102, 'learning_rate': 0.027772493417793847, 'negative_slope': 0.12461732672642387, 'dropout_rate': 0.33644013455651}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:05:46,678] Trial 81 finished with value: 0.3885703363914373 and parameters: {'input_dim': 91, 'hidden_dim': 47, 'window_size': 10, 'b_size': 97, 'learning_rate': 0.07371111065347938, 'negative_slope': 0.11724531011302049, 'dropout_rate': 0.3594385759418388}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:06:06,217] Trial 82 finished with value: 0.3973623853211009 and parameters: {'input_dim': 68, 'hidden_dim': 45, 'window_size': 7, 'b_size': 99, 'learning_rate': 0.05658201803401544, 'negative_slope': 0.11096325717981198, 'dropout_rate': 0.3750036043416974}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:06:25,268] Trial 83 finished with value: 0.39315749235474007 and parameters: {'input_dim': 68, 'hidden_dim': 49, 'window_size': 7, 'b_size': 103, 'learning_rate': 0.054043063543932526, 'negative_slope': 0.10752522478253827, 'dropout_rate': 0.3791719036537874}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:06:45,898] Trial 84 finished with value: 0.39239296636085624 and parameters: {'input_dim': 78, 'hidden_dim': 42, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.03931766094183819, 'negative_slope': 0.08256217680366065, 'dropout_rate': 0.39622101900568113}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:07:05,018] Trial 85 finished with value: 0.38551223241590216 and parameters: {'input_dim': 71, 'hidden_dim': 45, 'window_size': 7, 'b_size': 106, 'learning_rate': 0.033792414791077745, 'negative_slope': 0.1532122990201473, 'dropout_rate': 0.37412599252009027}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:07:25,746] Trial 86 finished with value: 0.39659785932721714 and parameters: {'input_dim': 61, 'hidden_dim': 48, 'window_size': 6, 'b_size': 81, 'learning_rate': 0.06488850342176235, 'negative_slope': 0.1427276150806156, 'dropout_rate': 0.3496638775610194}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:07:47,177] Trial 87 finished with value: 0.3967889908256881 and parameters: {'input_dim': 132, 'hidden_dim': 49, 'window_size': 7, 'b_size': 75, 'learning_rate': 0.06517446172409681, 'negative_slope': 0.08943863720412899, 'dropout_rate': 0.3874850547090332}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:08:10,560] Trial 88 finished with value: 0.38685015290519875 and parameters: {'input_dim': 122, 'hidden_dim': 49, 'window_size': 7, 'b_size': 64, 'learning_rate': 0.047946418612358814, 'negative_slope': 0.09474714310797124, 'dropout_rate': 0.38755625343860595}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:08:32,361] Trial 89 finished with value: 0.393348623853211 and parameters: {'input_dim': 141, 'hidden_dim': 44, 'window_size': 7, 'b_size': 74, 'learning_rate': 0.06700129596521052, 'negative_slope': 0.08962429773525953, 'dropout_rate': 0.38281563798158286}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:08:55,239] Trial 90 finished with value: 0.3885703363914373 and parameters: {'input_dim': 125, 'hidden_dim': 47, 'window_size': 8, 'b_size': 70, 'learning_rate': 0.03686526286340271, 'negative_slope': 0.10974306599595991, 'dropout_rate': 0.4168607074324798}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:09:16,271] Trial 91 finished with value: 0.39468654434250766 and parameters: {'input_dim': 62, 'hidden_dim': 48, 'window_size': 7, 'b_size': 82, 'learning_rate': 0.06479254038453656, 'negative_slope': 0.10026413920229472, 'dropout_rate': 0.3488954107415052}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:09:37,953] Trial 92 finished with value: 0.3872324159021407 and parameters: {'input_dim': 130, 'hidden_dim': 50, 'window_size': 6, 'b_size': 81, 'learning_rate': 0.05640614232768981, 'negative_slope': 0.07864470596326756, 'dropout_rate': 0.3637553508958141}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:09:58,675] Trial 93 finished with value: 0.39870030581039756 and parameters: {'input_dim': 129, 'hidden_dim': 45, 'window_size': 8, 'b_size': 85, 'learning_rate': 0.07807934823107504, 'negative_slope': 0.14530532866684936, 'dropout_rate': 0.3340552924749669}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:10:19,488] Trial 94 finished with value: 0.3929663608562691 and parameters: {'input_dim': 131, 'hidden_dim': 43, 'window_size': 8, 'b_size': 85, 'learning_rate': 0.045876375936918255, 'negative_slope': 0.12554719272293477, 'dropout_rate': 0.33525492447088395}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:10:41,160] Trial 95 finished with value: 0.3922018348623853 and parameters: {'input_dim': 151, 'hidden_dim': 41, 'window_size': 8, 'b_size': 88, 'learning_rate': 0.07569072936320284, 'negative_slope': 0.1195708663791113, 'dropout_rate': 0.32668716273515597}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:11:03,332] Trial 96 finished with value: 0.39353975535168195 and parameters: {'input_dim': 127, 'hidden_dim': 45, 'window_size': 9, 'b_size': 100, 'learning_rate': 0.09683477168895539, 'negative_slope': 0.1497748341727922, 'dropout_rate': 0.3702299833898358}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:11:25,184] Trial 97 finished with value: 0.39201070336391436 and parameters: {'input_dim': 138, 'hidden_dim': 46, 'window_size': 7, 'b_size': 76, 'learning_rate': 0.05123323328668742, 'negative_slope': 0.13155802501612834, 'dropout_rate': 0.35869846792540094}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:11:47,434] Trial 98 finished with value: 0.39239296636085624 and parameters: {'input_dim': 155, 'hidden_dim': 47, 'window_size': 8, 'b_size': 92, 'learning_rate': 0.05783368985797319, 'negative_slope': 0.11039945581991081, 'dropout_rate': 0.3195779917247699}. Best is trial 6 with value: 0.40577217125382264.\n",
      "[I 2023-12-22 16:12:08,051] Trial 99 finished with value: 0.3944954128440367 and parameters: {'input_dim': 112, 'hidden_dim': 45, 'window_size': 9, 'b_size': 96, 'learning_rate': 0.07687987107740596, 'negative_slope': 0.08718537405449306, 'dropout_rate': 0.3945069345273565}. Best is trial 6 with value: 0.40577217125382264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 55, 'hidden_dim': 47, 'window_size': 5, 'b_size': 96, 'learning_rate': 0.0420167205437253, 'negative_slope': 0.16081972614156514, 'dropout_rate': 0.31868411173731187}\n",
      "Best Accuracy: 0.40577217125382264\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.MultiMarginLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, H // 2)  # Additional layer\n",
    "        self.bn2 = nn.BatchNorm1d(H // 2)\n",
    "        self.linear3 = nn.Linear(H // 2, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), negative_slope=self.negative_slope)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.bn2(self.linear2(x)), negative_slope=self.negative_slope)\n",
    "        x = self.linear3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    negative_slope = trial.suggest_float('negative_slope', 0.01, 0.3)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33cf184",
   "metadata": {
    "papermill": {
     "duration": 0.106794,
     "end_time": "2023-12-22T16:12:08.380610",
     "exception": false,
     "start_time": "2023-12-22T16:12:08.273816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I really tried with more hidden layers, results are bad, im out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d081c38",
   "metadata": {
    "papermill": {
     "duration": 0.107262,
     "end_time": "2023-12-22T16:12:08.687679",
     "exception": false,
     "start_time": "2023-12-22T16:12:08.580417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Try also using drop out with just 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d16cdb0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T16:12:08.902341Z",
     "iopub.status.busy": "2023-12-22T16:12:08.901920Z",
     "iopub.status.idle": "2023-12-22T16:28:51.665673Z",
     "shell.execute_reply": "2023-12-22T16:28:51.664922Z"
    },
    "papermill": {
     "duration": 1002.985682,
     "end_time": "2023-12-22T16:28:51.779901",
     "exception": false,
     "start_time": "2023-12-22T16:12:08.794219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 16:12:08,927] A new study created in memory with name: no-name-c52db079-945d-4516-bdf1-f94e50f07519\n",
      "[I 2023-12-22 16:12:27,669] Trial 0 finished with value: 0.39717125382262997 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502, 'negative_slope': 0.055238410897498764, 'dropout_rate': 0.12323344486727979}. Best is trial 0 with value: 0.39717125382262997.\n",
      "[I 2023-12-22 16:12:54,296] Trial 1 finished with value: 0.3881880733944954 and parameters: {'input_dim': 180, 'hidden_dim': 34, 'window_size': 8, 'b_size': 33, 'learning_rate': 0.8706020878304853, 'negative_slope': 0.2514083658321223, 'dropout_rate': 0.18493564427131048}. Best is trial 0 with value: 0.39717125382262997.\n",
      "[I 2023-12-22 16:13:13,332] Trial 2 finished with value: 0.3937308868501529 and parameters: {'input_dim': 77, 'hidden_dim': 17, 'window_size': 5, 'b_size': 82, 'learning_rate': 0.0730953983591291, 'negative_slope': 0.09445645065743215, 'dropout_rate': 0.34474115788895177}. Best is trial 0 with value: 0.39717125382262997.\n",
      "[I 2023-12-22 16:13:31,696] Trial 3 finished with value: 0.3977446483180428 and parameters: {'input_dim': 71, 'hidden_dim': 21, 'window_size': 5, 'b_size': 76, 'learning_rate': 0.3718364180573207, 'negative_slope': 0.06790539682592432, 'dropout_rate': 0.3056937753654446}. Best is trial 3 with value: 0.3977446483180428.\n",
      "[I 2023-12-22 16:13:53,900] Trial 4 finished with value: 0.3929663608562691 and parameters: {'input_dim': 139, 'hidden_dim': 11, 'window_size': 7, 'b_size': 48, 'learning_rate': 0.013492834268013254, 'negative_slope': 0.2851768058034666, 'dropout_rate': 0.4862528132298237}. Best is trial 3 with value: 0.3977446483180428.\n",
      "[I 2023-12-22 16:14:13,367] Trial 5 finished with value: 0.39659785932721714 and parameters: {'input_dim': 172, 'hidden_dim': 22, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695, 'negative_slope': 0.045391088104985856, 'dropout_rate': 0.29807076404450805}. Best is trial 3 with value: 0.3977446483180428.\n",
      "[I 2023-12-22 16:14:31,496] Trial 6 finished with value: 0.3941131498470948 and parameters: {'input_dim': 55, 'hidden_dim': 47, 'window_size': 5, 'b_size': 96, 'learning_rate': 0.0420167205437253, 'negative_slope': 0.16081972614156514, 'dropout_rate': 0.31868411173731187}. Best is trial 3 with value: 0.3977446483180428.\n",
      "[I 2023-12-22 16:14:49,573] Trial 7 finished with value: 0.3857033639143731 and parameters: {'input_dim': 77, 'hidden_dim': 49, 'window_size': 9, 'b_size': 123, 'learning_rate': 0.6161049539380962, 'negative_slope': 0.18339099385521468, 'dropout_rate': 0.4687496940092467}. Best is trial 3 with value: 0.3977446483180428.\n",
      "[I 2023-12-22 16:15:09,521] Trial 8 finished with value: 0.38990825688073394 and parameters: {'input_dim': 63, 'hidden_dim': 18, 'window_size': 3, 'b_size': 63, 'learning_rate': 0.05989003672254302, 'negative_slope': 0.08869121921442981, 'dropout_rate': 0.43149500366077176}. Best is trial 3 with value: 0.3977446483180428.\n",
      "[I 2023-12-22 16:15:31,958] Trial 9 finished with value: 0.3809250764525994 and parameters: {'input_dim': 103, 'hidden_dim': 21, 'window_size': 7, 'b_size': 45, 'learning_rate': 0.40215545266902863, 'negative_slope': 0.03161968666713354, 'dropout_rate': 0.4947547746402069}. Best is trial 3 with value: 0.3977446483180428.\n",
      "[I 2023-12-22 16:15:50,748] Trial 10 finished with value: 0.39984709480122327 and parameters: {'input_dim': 127, 'hidden_dim': 32, 'window_size': 5, 'b_size': 116, 'learning_rate': 0.22281487465952846, 'negative_slope': 0.12028495847302506, 'dropout_rate': 0.23725841938493994}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:16:08,857] Trial 11 finished with value: 0.39602446483180426 and parameters: {'input_dim': 144, 'hidden_dim': 32, 'window_size': 5, 'b_size': 128, 'learning_rate': 0.24629072923500495, 'negative_slope': 0.11809845684219761, 'dropout_rate': 0.23966249844171403}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:16:27,439] Trial 12 finished with value: 0.39105504587155965 and parameters: {'input_dim': 121, 'hidden_dim': 38, 'window_size': 4, 'b_size': 109, 'learning_rate': 0.1872842287572408, 'negative_slope': 0.015572945735357904, 'dropout_rate': 0.23979459064228567}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:16:48,758] Trial 13 finished with value: 0.39946483180428133 and parameters: {'input_dim': 155, 'hidden_dim': 26, 'window_size': 6, 'b_size': 68, 'learning_rate': 0.15363788512374973, 'negative_slope': 0.1253276044480452, 'dropout_rate': 0.3695456595762009}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:17:09,824] Trial 14 finished with value: 0.38685015290519875 and parameters: {'input_dim': 196, 'hidden_dim': 27, 'window_size': 6, 'b_size': 69, 'learning_rate': 0.14670817273054057, 'negative_slope': 0.1323237160210561, 'dropout_rate': 0.38067962835917035}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:17:29,399] Trial 15 finished with value: 0.39258409785932724 and parameters: {'input_dim': 153, 'hidden_dim': 39, 'window_size': 10, 'b_size': 112, 'learning_rate': 0.12097221517186883, 'negative_slope': 0.19301445962629987, 'dropout_rate': 0.40064536992631566}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:17:51,327] Trial 16 finished with value: 0.39048165137614677 and parameters: {'input_dim': 162, 'hidden_dim': 27, 'window_size': 6, 'b_size': 56, 'learning_rate': 0.2349225910294844, 'negative_slope': 0.13183883709807878, 'dropout_rate': 0.36500683939344003}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:18:11,501] Trial 17 finished with value: 0.39258409785932724 and parameters: {'input_dim': 120, 'hidden_dim': 41, 'window_size': 4, 'b_size': 81, 'learning_rate': 0.1257354120439726, 'negative_slope': 0.08916670465793095, 'dropout_rate': 0.2668058939692798}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:18:29,340] Trial 18 finished with value: 0.39143730886850153 and parameters: {'input_dim': 96, 'hidden_dim': 28, 'window_size': 6, 'b_size': 115, 'learning_rate': 0.3420361393331352, 'negative_slope': 0.16462383546979834, 'dropout_rate': 0.4116892727837296}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:18:48,082] Trial 19 finished with value: 0.3941131498470948 and parameters: {'input_dim': 136, 'hidden_dim': 34, 'window_size': 4, 'b_size': 100, 'learning_rate': 0.17904319826816592, 'negative_slope': 0.20950285637099714, 'dropout_rate': 0.3509679306459871}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:19:09,368] Trial 20 finished with value: 0.3943042813455658 and parameters: {'input_dim': 200, 'hidden_dim': 42, 'window_size': 8, 'b_size': 70, 'learning_rate': 0.04135993655558232, 'negative_slope': 0.11981987486076444, 'dropout_rate': 0.19790021357715387}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:19:30,087] Trial 21 finished with value: 0.39353975535168195 and parameters: {'input_dim': 125, 'hidden_dim': 22, 'window_size': 5, 'b_size': 72, 'learning_rate': 0.39354617969913136, 'negative_slope': 0.06695604511087962, 'dropout_rate': 0.28149677391804806}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:19:49,010] Trial 22 finished with value: 0.39048165137614677 and parameters: {'input_dim': 89, 'hidden_dim': 13, 'window_size': 6, 'b_size': 88, 'learning_rate': 0.29199700411335355, 'negative_slope': 0.07666643278714064, 'dropout_rate': 0.32648129836206424}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:20:09,653] Trial 23 finished with value: 0.3977446483180428 and parameters: {'input_dim': 112, 'hidden_dim': 26, 'window_size': 4, 'b_size': 61, 'learning_rate': 0.5171184670689333, 'negative_slope': 0.10326631627115856, 'dropout_rate': 0.3120767541881511}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:20:30,418] Trial 24 finished with value: 0.3983180428134557 and parameters: {'input_dim': 158, 'hidden_dim': 30, 'window_size': 5, 'b_size': 77, 'learning_rate': 0.22563789517822525, 'negative_slope': 0.14134964077733883, 'dropout_rate': 0.34095930412340186}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:20:53,178] Trial 25 finished with value: 0.39717125382262997 and parameters: {'input_dim': 160, 'hidden_dim': 31, 'window_size': 7, 'b_size': 51, 'learning_rate': 0.1766699439426065, 'negative_slope': 0.13884078905789363, 'dropout_rate': 0.37075779299655287}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:21:13,863] Trial 26 finished with value: 0.39143730886850153 and parameters: {'input_dim': 186, 'hidden_dim': 34, 'window_size': 6, 'b_size': 89, 'learning_rate': 0.11493397943954314, 'negative_slope': 0.14819339299114323, 'dropout_rate': 0.346118495168492}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:21:32,801] Trial 27 finished with value: 0.39105504587155965 and parameters: {'input_dim': 149, 'hidden_dim': 24, 'window_size': 4, 'b_size': 105, 'learning_rate': 0.2702395040432948, 'negative_slope': 0.1558964252451396, 'dropout_rate': 0.4437884106748379}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:21:53,984] Trial 28 finished with value: 0.39143730886850153 and parameters: {'input_dim': 132, 'hidden_dim': 37, 'window_size': 5, 'b_size': 63, 'learning_rate': 0.2104329476914224, 'negative_slope': 0.10668364341631031, 'dropout_rate': 0.3960846315456656}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:22:14,657] Trial 29 finished with value: 0.3902905198776758 and parameters: {'input_dim': 169, 'hidden_dim': 45, 'window_size': 7, 'b_size': 81, 'learning_rate': 0.09551979348311994, 'negative_slope': 0.11545219769565969, 'dropout_rate': 0.3307641803275783}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:22:40,468] Trial 30 finished with value: 0.3952599388379205 and parameters: {'input_dim': 158, 'hidden_dim': 29, 'window_size': 3, 'b_size': 35, 'learning_rate': 0.15297437866100547, 'negative_slope': 0.052526418523793944, 'dropout_rate': 0.1088017347852453}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:23:00,129] Trial 31 finished with value: 0.3944954128440367 and parameters: {'input_dim': 115, 'hidden_dim': 18, 'window_size': 5, 'b_size': 75, 'learning_rate': 0.34048342544110705, 'negative_slope': 0.07472265347397156, 'dropout_rate': 0.28112833597578446}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:23:19,677] Trial 32 finished with value: 0.38589449541284404 and parameters: {'input_dim': 129, 'hidden_dim': 24, 'window_size': 5, 'b_size': 76, 'learning_rate': 0.9002691186166594, 'negative_slope': 0.06475675449926076, 'dropout_rate': 0.3118676310190765}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:23:40,321] Trial 33 finished with value: 0.3977446483180428 and parameters: {'input_dim': 182, 'hidden_dim': 30, 'window_size': 6, 'b_size': 88, 'learning_rate': 0.5070455552136922, 'negative_slope': 0.09717871895144635, 'dropout_rate': 0.1427551274106433}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:24:00,669] Trial 34 finished with value: 0.39392201834862384 and parameters: {'input_dim': 144, 'hidden_dim': 14, 'window_size': 5, 'b_size': 85, 'learning_rate': 0.27974225367118527, 'negative_slope': 0.13010586292194248, 'dropout_rate': 0.35219427585710816}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:24:20,198] Trial 35 finished with value: 0.39908256880733944 and parameters: {'input_dim': 86, 'hidden_dim': 20, 'window_size': 8, 'b_size': 95, 'learning_rate': 0.22082938049191592, 'negative_slope': 0.08123192479820895, 'dropout_rate': 0.37764883889186174}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:24:40,130] Trial 36 finished with value: 0.38589449541284404 and parameters: {'input_dim': 175, 'hidden_dim': 24, 'window_size': 8, 'b_size': 95, 'learning_rate': 0.20942189659059857, 'negative_slope': 0.11296134445878088, 'dropout_rate': 0.3797904414809797}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:24:58,492] Trial 37 finished with value: 0.3948776758409786 and parameters: {'input_dim': 85, 'hidden_dim': 32, 'window_size': 9, 'b_size': 117, 'learning_rate': 0.15612889727489895, 'negative_slope': 0.1492021192816726, 'dropout_rate': 0.33330577512680887}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:25:17,008] Trial 38 finished with value: 0.3918195718654434 and parameters: {'input_dim': 106, 'hidden_dim': 34, 'window_size': 9, 'b_size': 103, 'learning_rate': 0.09346835425312003, 'negative_slope': 0.09142294783408156, 'dropout_rate': 0.4146587539995068}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:25:36,402] Trial 39 finished with value: 0.39545107033639143 and parameters: {'input_dim': 141, 'hidden_dim': 16, 'window_size': 7, 'b_size': 96, 'learning_rate': 0.7081887999200552, 'negative_slope': 0.17546996376394056, 'dropout_rate': 0.38504383901646}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:25:56,956] Trial 40 finished with value: 0.3889525993883792 and parameters: {'input_dim': 169, 'hidden_dim': 20, 'window_size': 8, 'b_size': 92, 'learning_rate': 0.23098105067579586, 'negative_slope': 0.08200699862745323, 'dropout_rate': 0.3652561720552401}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:26:15,884] Trial 41 finished with value: 0.39315749235474007 and parameters: {'input_dim': 73, 'hidden_dim': 20, 'window_size': 5, 'b_size': 77, 'learning_rate': 0.32258474162878903, 'negative_slope': 0.04673467963574464, 'dropout_rate': 0.3209610322204016}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:26:35,837] Trial 42 finished with value: 0.3929663608562691 and parameters: {'input_dim': 56, 'hidden_dim': 26, 'window_size': 6, 'b_size': 66, 'learning_rate': 0.4520414356848488, 'negative_slope': 0.09841562271155394, 'dropout_rate': 0.3008988047483208}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:26:52,864] Trial 43 finished with value: 0.3943042813455658 and parameters: {'input_dim': 70, 'hidden_dim': 23, 'window_size': 4, 'b_size': 121, 'learning_rate': 0.39767495683068954, 'negative_slope': 0.06735693891193816, 'dropout_rate': 0.3450690963374249}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:27:12,050] Trial 44 finished with value: 0.39315749235474007 and parameters: {'input_dim': 51, 'hidden_dim': 19, 'window_size': 10, 'b_size': 83, 'learning_rate': 0.26319773251416195, 'negative_slope': 0.03555663005313402, 'dropout_rate': 0.29301674105679815}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:27:32,550] Trial 45 finished with value: 0.393348623853211 and parameters: {'input_dim': 98, 'hidden_dim': 29, 'window_size': 7, 'b_size': 59, 'learning_rate': 0.20767022054135853, 'negative_slope': 0.12500065195931376, 'dropout_rate': 0.2642235549911649}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:27:52,330] Trial 46 finished with value: 0.38551223241590216 and parameters: {'input_dim': 82, 'hidden_dim': 16, 'window_size': 6, 'b_size': 67, 'learning_rate': 0.6499453174690711, 'negative_slope': 0.14391501913817822, 'dropout_rate': 0.3628877900246474}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:28:13,369] Trial 47 finished with value: 0.3918195718654434 and parameters: {'input_dim': 62, 'hidden_dim': 10, 'window_size': 5, 'b_size': 53, 'learning_rate': 0.14024679418900354, 'negative_slope': 0.10697991152292483, 'dropout_rate': 0.33283663403486585}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:28:31,948] Trial 48 finished with value: 0.39468654434250766 and parameters: {'input_dim': 152, 'hidden_dim': 36, 'window_size': 4, 'b_size': 128, 'learning_rate': 0.17587601101851716, 'negative_slope': 0.08718441241123427, 'dropout_rate': 0.4416746480687676}. Best is trial 10 with value: 0.39984709480122327.\n",
      "[I 2023-12-22 16:28:51,660] Trial 49 finished with value: 0.3837920489296636 and parameters: {'input_dim': 90, 'hidden_dim': 26, 'window_size': 3, 'b_size': 72, 'learning_rate': 0.3243342338025429, 'negative_slope': 0.12302974181750631, 'dropout_rate': 0.3879925877726999}. Best is trial 10 with value: 0.39984709480122327.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 127, 'hidden_dim': 32, 'window_size': 5, 'b_size': 116, 'learning_rate': 0.22281487465952846, 'negative_slope': 0.12028495847302506, 'dropout_rate': 0.23725841938493994}\n",
      "Best Accuracy: 0.39984709480122327\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.MultiMarginLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    negative_slope = trial.suggest_float('negative_slope', 0.01, 0.3)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b43f7c",
   "metadata": {
    "papermill": {
     "duration": 0.111401,
     "end_time": "2023-12-22T16:28:52.007026",
     "exception": false,
     "start_time": "2023-12-22T16:28:51.895625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That is an imporvement, the next step is to change the emebdding representation of the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a569592",
   "metadata": {
    "papermill": {
     "duration": 0.111406,
     "end_time": "2023-12-22T16:28:52.229572",
     "exception": false,
     "start_time": "2023-12-22T16:28:52.118166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The best model so far includes a neural network with 1 hidden layer that uses leaky_relu step function and drop out. The criterion/loss function, is MultiMarginLoss and the optimizer is simple SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730288d6",
   "metadata": {
    "papermill": {
     "duration": 0.111184,
     "end_time": "2023-12-22T16:28:52.453094",
     "exception": false,
     "start_time": "2023-12-22T16:28:52.341910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Lets try to use tfidf instead of mean embedding to represent text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "907c7025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T16:28:52.680794Z",
     "iopub.status.busy": "2023-12-22T16:28:52.679932Z",
     "iopub.status.idle": "2023-12-22T17:40:18.142259Z",
     "shell.execute_reply": "2023-12-22T17:40:18.141126Z"
    },
    "papermill": {
     "duration": 4285.694736,
     "end_time": "2023-12-22T17:40:18.260770",
     "exception": false,
     "start_time": "2023-12-22T16:28:52.566034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 16:28:52,707] A new study created in memory with name: no-name-ae3dd3e7-a728-4b5a-92cb-1262bb954291\n",
      "[I 2023-12-22 16:30:09,489] Trial 0 finished with value: 0.39659785932721714 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502, 'negative_slope': 0.055238410897498764, 'dropout_rate': 0.12323344486727979}. Best is trial 0 with value: 0.39659785932721714.\n",
      "[I 2023-12-22 16:32:07,346] Trial 1 finished with value: 0.3918195718654434 and parameters: {'input_dim': 180, 'hidden_dim': 34, 'window_size': 8, 'b_size': 33, 'learning_rate': 0.8706020878304853, 'negative_slope': 0.2514083658321223, 'dropout_rate': 0.18493564427131048}. Best is trial 0 with value: 0.39659785932721714.\n",
      "[I 2023-12-22 16:33:23,956] Trial 2 finished with value: 0.39506880733944955 and parameters: {'input_dim': 77, 'hidden_dim': 17, 'window_size': 5, 'b_size': 82, 'learning_rate': 0.0730953983591291, 'negative_slope': 0.09445645065743215, 'dropout_rate': 0.34474115788895177}. Best is trial 0 with value: 0.39659785932721714.\n",
      "[I 2023-12-22 16:34:40,376] Trial 3 finished with value: 0.39258409785932724 and parameters: {'input_dim': 71, 'hidden_dim': 21, 'window_size': 5, 'b_size': 76, 'learning_rate': 0.3718364180573207, 'negative_slope': 0.06790539682592432, 'dropout_rate': 0.3056937753654446}. Best is trial 0 with value: 0.39659785932721714.\n",
      "[I 2023-12-22 16:36:05,314] Trial 4 finished with value: 0.3988914373088685 and parameters: {'input_dim': 139, 'hidden_dim': 11, 'window_size': 7, 'b_size': 48, 'learning_rate': 0.013492834268013254, 'negative_slope': 0.2851768058034666, 'dropout_rate': 0.4862528132298237}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:37:50,742] Trial 5 finished with value: 0.39239296636085624 and parameters: {'input_dim': 172, 'hidden_dim': 22, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695, 'negative_slope': 0.045391088104985856, 'dropout_rate': 0.29807076404450805}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:39:07,041] Trial 6 finished with value: 0.39659785932721714 and parameters: {'input_dim': 55, 'hidden_dim': 47, 'window_size': 5, 'b_size': 96, 'learning_rate': 0.0420167205437253, 'negative_slope': 0.16081972614156514, 'dropout_rate': 0.31868411173731187}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:40:23,034] Trial 7 finished with value: 0.39545107033639143 and parameters: {'input_dim': 77, 'hidden_dim': 49, 'window_size': 9, 'b_size': 123, 'learning_rate': 0.6161049539380962, 'negative_slope': 0.18339099385521468, 'dropout_rate': 0.4687496940092467}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:41:41,911] Trial 8 finished with value: 0.38990825688073394 and parameters: {'input_dim': 63, 'hidden_dim': 18, 'window_size': 3, 'b_size': 63, 'learning_rate': 0.05989003672254302, 'negative_slope': 0.08869121921442981, 'dropout_rate': 0.43149500366077176}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:43:02,852] Trial 9 finished with value: 0.3885703363914373 and parameters: {'input_dim': 103, 'hidden_dim': 21, 'window_size': 7, 'b_size': 45, 'learning_rate': 0.40215545266902863, 'negative_slope': 0.03161968666713354, 'dropout_rate': 0.4947547746402069}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:44:28,270] Trial 10 finished with value: 0.38685015290519875 and parameters: {'input_dim': 146, 'hidden_dim': 10, 'window_size': 10, 'b_size': 56, 'learning_rate': 0.010692561339316916, 'negative_slope': 0.27322279063193006, 'dropout_rate': 0.39214675808280386}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:45:46,799] Trial 11 finished with value: 0.3872324159021407 and parameters: {'input_dim': 127, 'hidden_dim': 35, 'window_size': 7, 'b_size': 112, 'learning_rate': 0.010528385612815407, 'negative_slope': 0.2105003192818426, 'dropout_rate': 0.12422866359360898}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:47:05,490] Trial 12 finished with value: 0.3964067278287462 and parameters: {'input_dim': 112, 'hidden_dim': 41, 'window_size': 8, 'b_size': 77, 'learning_rate': 0.02537015019599844, 'negative_slope': 0.1254218475621345, 'dropout_rate': 0.2358910227739615}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:48:34,942] Trial 13 finished with value: 0.3908639143730887 and parameters: {'input_dim': 154, 'hidden_dim': 28, 'window_size': 6, 'b_size': 95, 'learning_rate': 0.02119291765534235, 'negative_slope': 0.016064739851258274, 'dropout_rate': 0.13795772267185238}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:49:56,311] Trial 14 finished with value: 0.3918195718654434 and parameters: {'input_dim': 132, 'hidden_dim': 11, 'window_size': 9, 'b_size': 63, 'learning_rate': 0.14670817273054057, 'negative_slope': 0.28678132175505255, 'dropout_rate': 0.22836536101420077}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:52:06,410] Trial 15 finished with value: 0.38952599388379205 and parameters: {'input_dim': 199, 'hidden_dim': 44, 'window_size': 8, 'b_size': 34, 'learning_rate': 0.01996936386016766, 'negative_slope': 0.227062346983365, 'dropout_rate': 0.40064536992631566}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:53:28,231] Trial 16 finished with value: 0.389717125382263 and parameters: {'input_dim': 94, 'hidden_dim': 27, 'window_size': 6, 'b_size': 47, 'learning_rate': 0.014736435748746465, 'negative_slope': 0.13275038560103333, 'dropout_rate': 0.10439567569750852}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:54:52,200] Trial 17 finished with value: 0.3918195718654434 and parameters: {'input_dim': 146, 'hidden_dim': 39, 'window_size': 10, 'b_size': 85, 'learning_rate': 0.036698799728242394, 'negative_slope': 0.18551794052734072, 'dropout_rate': 0.2557794581926886}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:56:11,734] Trial 18 finished with value: 0.3952599388379205 and parameters: {'input_dim': 118, 'hidden_dim': 35, 'window_size': 9, 'b_size': 115, 'learning_rate': 0.031579757216480334, 'negative_slope': 0.2863545640568072, 'dropout_rate': 0.1683886491275018}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:57:31,281] Trial 19 finished with value: 0.386085626911315 and parameters: {'input_dim': 91, 'hidden_dim': 14, 'window_size': 7, 'b_size': 67, 'learning_rate': 0.016133098470034017, 'negative_slope': 0.2995114351453413, 'dropout_rate': 0.3614838463376575}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 16:59:11,042] Trial 20 finished with value: 0.3845565749235474 and parameters: {'input_dim': 166, 'hidden_dim': 25, 'window_size': 4, 'b_size': 109, 'learning_rate': 0.026738645677080442, 'negative_slope': 0.010120897633292388, 'dropout_rate': 0.4455223403899253}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 17:00:28,847] Trial 21 finished with value: 0.3908639143730887 and parameters: {'input_dim': 60, 'hidden_dim': 49, 'window_size': 5, 'b_size': 97, 'learning_rate': 0.03580565953564178, 'negative_slope': 0.16828874655772044, 'dropout_rate': 0.3012711099265405}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 17:01:50,672] Trial 22 finished with value: 0.393348623853211 and parameters: {'input_dim': 139, 'hidden_dim': 45, 'window_size': 6, 'b_size': 93, 'learning_rate': 0.04039914060872902, 'negative_slope': 0.14195805340821738, 'dropout_rate': 0.20079761019147185}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 17:03:07,524] Trial 23 finished with value: 0.3809250764525994 and parameters: {'input_dim': 50, 'hidden_dim': 45, 'window_size': 4, 'b_size': 102, 'learning_rate': 0.015462637600397374, 'negative_slope': 0.246431379762103, 'dropout_rate': 0.4925252347033175}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 17:04:26,809] Trial 24 finished with value: 0.39659785932721714 and parameters: {'input_dim': 107, 'hidden_dim': 50, 'window_size': 8, 'b_size': 88, 'learning_rate': 0.04666910229985853, 'negative_slope': 0.10992291684647573, 'dropout_rate': 0.2702288567851148}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 17:05:46,675] Trial 25 finished with value: 0.39353975535168195 and parameters: {'input_dim': 93, 'hidden_dim': 39, 'window_size': 7, 'b_size': 75, 'learning_rate': 0.02291969017889503, 'negative_slope': 0.16370452102213298, 'dropout_rate': 0.3402119509267012}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 17:07:05,703] Trial 26 finished with value: 0.39143730886850153 and parameters: {'input_dim': 124, 'hidden_dim': 32, 'window_size': 4, 'b_size': 128, 'learning_rate': 0.013844785409486629, 'negative_slope': 0.06086259728057486, 'dropout_rate': 0.16023352713261477}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 17:08:23,523] Trial 27 finished with value: 0.38952599388379205 and parameters: {'input_dim': 85, 'hidden_dim': 46, 'window_size': 6, 'b_size': 105, 'learning_rate': 0.010303135102685369, 'negative_slope': 0.20994240318260732, 'dropout_rate': 0.1974040046404777}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 17:09:59,110] Trial 28 finished with value: 0.3900993883792049 and parameters: {'input_dim': 159, 'hidden_dim': 40, 'window_size': 5, 'b_size': 89, 'learning_rate': 0.02907044328503912, 'negative_slope': 0.15265007952405119, 'dropout_rate': 0.420663939504624}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 17:12:04,139] Trial 29 finished with value: 0.39353975535168195 and parameters: {'input_dim': 182, 'hidden_dim': 31, 'window_size': 8, 'b_size': 32, 'learning_rate': 0.049198398882327514, 'negative_slope': 0.2575354333787142, 'dropout_rate': 0.37778994277027306}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 17:13:23,142] Trial 30 finished with value: 0.38876146788990823 and parameters: {'input_dim': 103, 'hidden_dim': 43, 'window_size': 9, 'b_size': 69, 'learning_rate': 0.018957062849157918, 'negative_slope': 0.120816458189623, 'dropout_rate': 0.4651113789794461}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 17:14:43,111] Trial 31 finished with value: 0.39201070336391436 and parameters: {'input_dim': 115, 'hidden_dim': 50, 'window_size': 8, 'b_size': 87, 'learning_rate': 0.0486917281104816, 'negative_slope': 0.09840646209194681, 'dropout_rate': 0.27348221377385273}. Best is trial 4 with value: 0.3988914373088685.\n",
      "[I 2023-12-22 17:16:02,113] Trial 32 finished with value: 0.40156727828746175 and parameters: {'input_dim': 105, 'hidden_dim': 47, 'window_size': 8, 'b_size': 82, 'learning_rate': 0.10908003496412438, 'negative_slope': 0.10917775372421132, 'dropout_rate': 0.3268718885505423}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:17:23,973] Trial 33 finished with value: 0.39908256880733944 and parameters: {'input_dim': 135, 'hidden_dim': 46, 'window_size': 7, 'b_size': 79, 'learning_rate': 0.11539203976033631, 'negative_slope': 0.08043730446281899, 'dropout_rate': 0.3432623109185402}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:18:45,422] Trial 34 finished with value: 0.38952599388379205 and parameters: {'input_dim': 135, 'hidden_dim': 42, 'window_size': 7, 'b_size': 81, 'learning_rate': 0.10288588298519605, 'negative_slope': 0.08330011058782139, 'dropout_rate': 0.342450445676754}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:20:09,211] Trial 35 finished with value: 0.3948776758409786 and parameters: {'input_dim': 120, 'hidden_dim': 47, 'window_size': 8, 'b_size': 54, 'learning_rate': 0.14108105129176912, 'negative_slope': 0.06131581059645671, 'dropout_rate': 0.3254607644652825}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:21:34,406] Trial 36 finished with value: 0.39602446483180426 and parameters: {'input_dim': 127, 'hidden_dim': 37, 'window_size': 7, 'b_size': 41, 'learning_rate': 0.10900336730830368, 'negative_slope': 0.07883200632215215, 'dropout_rate': 0.37146665458655737}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:23:00,837] Trial 37 finished with value: 0.39659785932721714 and parameters: {'input_dim': 144, 'hidden_dim': 48, 'window_size': 9, 'b_size': 75, 'learning_rate': 0.07121679788252107, 'negative_slope': 0.1002821934945418, 'dropout_rate': 0.2905345013043657}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:24:21,081] Trial 38 finished with value: 0.39239296636085624 and parameters: {'input_dim': 79, 'hidden_dim': 24, 'window_size': 7, 'b_size': 70, 'learning_rate': 0.1675980399528943, 'negative_slope': 0.04555883687626797, 'dropout_rate': 0.31553211009267423}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:25:42,466] Trial 39 finished with value: 0.3948776758409786 and parameters: {'input_dim': 109, 'hidden_dim': 18, 'window_size': 8, 'b_size': 58, 'learning_rate': 0.07916385977724778, 'negative_slope': 0.11077347658508001, 'dropout_rate': 0.35141668992508457}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:27:12,987] Trial 40 finished with value: 0.3916284403669725 and parameters: {'input_dim': 156, 'hidden_dim': 15, 'window_size': 6, 'b_size': 81, 'learning_rate': 0.21671920749675838, 'negative_slope': 0.07094216054168075, 'dropout_rate': 0.4109055855966608}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:28:30,025] Trial 41 finished with value: 0.38512996941896027 and parameters: {'input_dim': 100, 'hidden_dim': 47, 'window_size': 5, 'b_size': 101, 'learning_rate': 0.06940692062402451, 'negative_slope': 0.08515077651084887, 'dropout_rate': 0.32270355507038095}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:29:47,470] Trial 42 finished with value: 0.39105504587155965 and parameters: {'input_dim': 70, 'hidden_dim': 42, 'window_size': 7, 'b_size': 91, 'learning_rate': 0.06214743298605205, 'negative_slope': 0.09895410880304584, 'dropout_rate': 0.39180733273098445}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:31:06,765] Trial 43 finished with value: 0.3956422018348624 and parameters: {'input_dim': 132, 'hidden_dim': 47, 'window_size': 6, 'b_size': 118, 'learning_rate': 0.026766365930097458, 'negative_slope': 0.04393524107658395, 'dropout_rate': 0.33109497748111283}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:32:23,961] Trial 44 finished with value: 0.39067278287461776 and parameters: {'input_dim': 55, 'hidden_dim': 44, 'window_size': 8, 'b_size': 84, 'learning_rate': 0.08855545533024409, 'negative_slope': 0.11893063927002487, 'dropout_rate': 0.30821451396674004}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:33:40,283] Trial 45 finished with value: 0.38321865443425074 and parameters: {'input_dim': 68, 'hidden_dim': 37, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.012274328161302474, 'negative_slope': 0.0736247546248259, 'dropout_rate': 0.36783974848975964}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:35:03,898] Trial 46 finished with value: 0.38837920489296635 and parameters: {'input_dim': 148, 'hidden_dim': 48, 'window_size': 9, 'b_size': 106, 'learning_rate': 0.018876193924145176, 'negative_slope': 0.0901981673429775, 'dropout_rate': 0.4405814918807886}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:36:22,353] Trial 47 finished with value: 0.3916284403669725 and parameters: {'input_dim': 84, 'hidden_dim': 20, 'window_size': 10, 'b_size': 77, 'learning_rate': 0.023086668635509143, 'negative_slope': 0.12963801008409884, 'dropout_rate': 0.28918665866310744}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:38:19,740] Trial 48 finished with value: 0.39965596330275227 and parameters: {'input_dim': 180, 'hidden_dim': 33, 'window_size': 7, 'b_size': 49, 'learning_rate': 0.05691150572060188, 'negative_slope': 0.13485665630939664, 'dropout_rate': 0.34774360337742244}. Best is trial 32 with value: 0.40156727828746175.\n",
      "[I 2023-12-22 17:40:18,135] Trial 49 finished with value: 0.3943042813455658 and parameters: {'input_dim': 179, 'hidden_dim': 33, 'window_size': 7, 'b_size': 48, 'learning_rate': 0.031706569007969504, 'negative_slope': 0.14328061544836207, 'dropout_rate': 0.3902388848886077}. Best is trial 32 with value: 0.40156727828746175.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 105, 'hidden_dim': 47, 'window_size': 8, 'b_size': 82, 'learning_rate': 0.10908003496412438, 'negative_slope': 0.10917775372421132, 'dropout_rate': 0.3268718885505423}\n",
      "Best Accuracy: 0.40156727828746175\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.MultiMarginLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "def tfidf_weighted_embedding(tokens, model, tfidf):\n",
    "    word_ids = [model.wv.key_to_index[word] for word in tokens if word in model.wv]\n",
    "    word_tfidf = tfidf.transform([' '.join(tokens)]).toarray()[0, word_ids]\n",
    "    word_vectors = np.array([model.wv[word] for word in tokens if word in model.wv])\n",
    "    return np.dot(word_tfidf, word_vectors) / np.sum(word_tfidf)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    negative_slope = trial.suggest_float('negative_slope', 0.01, 0.3)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    tfidf = TfidfVectorizer(vocabulary=word2vec_model.wv.key_to_index)\n",
    "    tfidf.fit(data['tokenized_text'].apply(lambda x: ' '.join(x)))\n",
    "    data['tfidf_embedding'] = data['tokenized_text'].apply(lambda tokens: tfidf_weighted_embedding(tokens, word2vec_model, tfidf))\n",
    "    valid['tfidf_embedding'] = valid['tokenized_text'].apply(lambda tokens: tfidf_weighted_embedding(tokens, word2vec_model, tfidf))\n",
    "\n",
    "\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(data['tfidf_embedding']).astype(np.float32)\n",
    "    x_val = np.vstack(valid['tfidf_embedding']).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bbdee4",
   "metadata": {
    "papermill": {
     "duration": 0.117122,
     "end_time": "2023-12-22T17:40:18.495341",
     "exception": false,
     "start_time": "2023-12-22T17:40:18.378219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Also try CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04fecfbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T17:40:18.733043Z",
     "iopub.status.busy": "2023-12-22T17:40:18.732621Z",
     "iopub.status.idle": "2023-12-22T18:09:53.624709Z",
     "shell.execute_reply": "2023-12-22T18:09:53.623636Z"
    },
    "papermill": {
     "duration": 1775.134158,
     "end_time": "2023-12-22T18:09:53.747740",
     "exception": false,
     "start_time": "2023-12-22T17:40:18.613582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 17:40:18,763] A new study created in memory with name: no-name-a248a987-9dd2-49ef-bec7-37ae90a2f8f6\n",
      "[I 2023-12-22 17:40:50,480] Trial 0 finished with value: 0.39105504587155965 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502, 'negative_slope': 0.055238410897498764, 'dropout_rate': 0.12323344486727979}. Best is trial 0 with value: 0.39105504587155965.\n",
      "[I 2023-12-22 17:41:47,419] Trial 1 finished with value: 0.38990825688073394 and parameters: {'input_dim': 180, 'hidden_dim': 34, 'window_size': 8, 'b_size': 33, 'learning_rate': 0.8706020878304853, 'negative_slope': 0.2514083658321223, 'dropout_rate': 0.18493564427131048}. Best is trial 0 with value: 0.39105504587155965.\n",
      "[I 2023-12-22 17:42:18,865] Trial 2 finished with value: 0.3944954128440367 and parameters: {'input_dim': 77, 'hidden_dim': 17, 'window_size': 5, 'b_size': 82, 'learning_rate': 0.0730953983591291, 'negative_slope': 0.09445645065743215, 'dropout_rate': 0.34474115788895177}. Best is trial 2 with value: 0.3944954128440367.\n",
      "[I 2023-12-22 17:42:50,195] Trial 3 finished with value: 0.3927752293577982 and parameters: {'input_dim': 71, 'hidden_dim': 21, 'window_size': 5, 'b_size': 76, 'learning_rate': 0.3718364180573207, 'negative_slope': 0.06790539682592432, 'dropout_rate': 0.3056937753654446}. Best is trial 2 with value: 0.3944954128440367.\n",
      "[I 2023-12-22 17:43:29,136] Trial 4 finished with value: 0.38398318042813456 and parameters: {'input_dim': 139, 'hidden_dim': 11, 'window_size': 7, 'b_size': 48, 'learning_rate': 0.013492834268013254, 'negative_slope': 0.2851768058034666, 'dropout_rate': 0.4862528132298237}. Best is trial 2 with value: 0.3944954128440367.\n",
      "[I 2023-12-22 17:44:16,483] Trial 5 finished with value: 0.3918195718654434 and parameters: {'input_dim': 172, 'hidden_dim': 22, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695, 'negative_slope': 0.045391088104985856, 'dropout_rate': 0.29807076404450805}. Best is trial 2 with value: 0.3944954128440367.\n",
      "[I 2023-12-22 17:44:46,986] Trial 6 finished with value: 0.3912461773700306 and parameters: {'input_dim': 55, 'hidden_dim': 47, 'window_size': 5, 'b_size': 96, 'learning_rate': 0.0420167205437253, 'negative_slope': 0.16081972614156514, 'dropout_rate': 0.31868411173731187}. Best is trial 2 with value: 0.3944954128440367.\n",
      "[I 2023-12-22 17:45:17,609] Trial 7 finished with value: 0.39048165137614677 and parameters: {'input_dim': 77, 'hidden_dim': 49, 'window_size': 9, 'b_size': 123, 'learning_rate': 0.6161049539380962, 'negative_slope': 0.18339099385521468, 'dropout_rate': 0.4687496940092467}. Best is trial 2 with value: 0.3944954128440367.\n",
      "[I 2023-12-22 17:45:50,799] Trial 8 finished with value: 0.38914373088685017 and parameters: {'input_dim': 63, 'hidden_dim': 18, 'window_size': 3, 'b_size': 63, 'learning_rate': 0.05989003672254302, 'negative_slope': 0.08869121921442981, 'dropout_rate': 0.43149500366077176}. Best is trial 2 with value: 0.3944954128440367.\n",
      "[I 2023-12-22 17:46:26,242] Trial 9 finished with value: 0.3922018348623853 and parameters: {'input_dim': 103, 'hidden_dim': 21, 'window_size': 7, 'b_size': 45, 'learning_rate': 0.40215545266902863, 'negative_slope': 0.03161968666713354, 'dropout_rate': 0.4947547746402069}. Best is trial 2 with value: 0.3944954128440367.\n",
      "[I 2023-12-22 17:46:59,470] Trial 10 finished with value: 0.3958333333333333 and parameters: {'input_dim': 127, 'hidden_dim': 32, 'window_size': 5, 'b_size': 122, 'learning_rate': 0.19062374828215087, 'negative_slope': 0.1160557590537364, 'dropout_rate': 0.3858492968184316}. Best is trial 10 with value: 0.3958333333333333.\n",
      "[I 2023-12-22 17:47:35,654] Trial 11 finished with value: 0.3964067278287462 and parameters: {'input_dim': 144, 'hidden_dim': 33, 'window_size': 5, 'b_size': 128, 'learning_rate': 0.17040176261680165, 'negative_slope': 0.12265021256853384, 'dropout_rate': 0.3856739056082168}. Best is trial 11 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 17:48:13,195] Trial 12 finished with value: 0.39353975535168195 and parameters: {'input_dim': 148, 'hidden_dim': 35, 'window_size': 4, 'b_size': 128, 'learning_rate': 0.20065250453364522, 'negative_slope': 0.12240231917854862, 'dropout_rate': 0.3898019929480497}. Best is trial 11 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 17:48:55,654] Trial 13 finished with value: 0.3952599388379205 and parameters: {'input_dim': 154, 'hidden_dim': 29, 'window_size': 6, 'b_size': 115, 'learning_rate': 0.13046152819870183, 'negative_slope': 0.13220221376156296, 'dropout_rate': 0.3847911208853647}. Best is trial 11 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 17:49:28,323] Trial 14 finished with value: 0.393348623853211 and parameters: {'input_dim': 118, 'hidden_dim': 37, 'window_size': 6, 'b_size': 111, 'learning_rate': 0.18766870441105787, 'negative_slope': 0.20238786429747493, 'dropout_rate': 0.4191979476316069}. Best is trial 11 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 17:50:17,270] Trial 15 finished with value: 0.3902905198776758 and parameters: {'input_dim': 200, 'hidden_dim': 41, 'window_size': 4, 'b_size': 110, 'learning_rate': 0.1501360276561791, 'negative_slope': 0.11731610762439251, 'dropout_rate': 0.2683643198127197}. Best is trial 11 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 17:50:49,469] Trial 16 finished with value: 0.3878058103975535 and parameters: {'input_dim': 129, 'hidden_dim': 27, 'window_size': 4, 'b_size': 105, 'learning_rate': 0.2715834954634817, 'negative_slope': 0.012621324695200872, 'dropout_rate': 0.36500683939344003}. Best is trial 11 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 17:51:33,888] Trial 17 finished with value: 0.39239296636085624 and parameters: {'input_dim': 164, 'hidden_dim': 41, 'window_size': 10, 'b_size': 121, 'learning_rate': 0.11646587652315103, 'negative_slope': 0.15130797806824625, 'dropout_rate': 0.43111490378301637}. Best is trial 11 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 17:52:03,702] Trial 18 finished with value: 0.3916284403669725 and parameters: {'input_dim': 96, 'hidden_dim': 27, 'window_size': 6, 'b_size': 125, 'learning_rate': 0.27790154491502844, 'negative_slope': 0.09161013527789819, 'dropout_rate': 0.24335611391621678}. Best is trial 11 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 17:52:37,802] Trial 19 finished with value: 0.3902905198776758 and parameters: {'input_dim': 122, 'hidden_dim': 39, 'window_size': 5, 'b_size': 77, 'learning_rate': 0.10351029070280382, 'negative_slope': 0.19879256145076668, 'dropout_rate': 0.3509679306459871}. Best is trial 11 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 17:53:12,103] Trial 20 finished with value: 0.39717125382262997 and parameters: {'input_dim': 136, 'hidden_dim': 31, 'window_size': 4, 'b_size': 103, 'learning_rate': 0.0451167090868405, 'negative_slope': 0.07013616616930574, 'dropout_rate': 0.40905056948670704}. Best is trial 20 with value: 0.39717125382262997.\n",
      "[I 2023-12-22 17:53:46,093] Trial 21 finished with value: 0.39258409785932724 and parameters: {'input_dim': 139, 'hidden_dim': 32, 'window_size': 4, 'b_size': 116, 'learning_rate': 0.03797683778191321, 'negative_slope': 0.07699283618477598, 'dropout_rate': 0.4045256816738272}. Best is trial 20 with value: 0.39717125382262997.\n",
      "[I 2023-12-22 17:54:19,948] Trial 22 finished with value: 0.39392201834862384 and parameters: {'input_dim': 135, 'hidden_dim': 31, 'window_size': 3, 'b_size': 103, 'learning_rate': 0.1854463390377112, 'negative_slope': 0.11100889207449866, 'dropout_rate': 0.4504479174645276}. Best is trial 20 with value: 0.39717125382262997.\n",
      "[I 2023-12-22 17:54:51,288] Trial 23 finished with value: 0.389717125382263 and parameters: {'input_dim': 111, 'hidden_dim': 27, 'window_size': 5, 'b_size': 128, 'learning_rate': 0.09490430902713652, 'negative_slope': 0.06488183386166738, 'dropout_rate': 0.39716457927190196}. Best is trial 20 with value: 0.39717125382262997.\n",
      "[I 2023-12-22 17:55:22,586] Trial 24 finished with value: 0.3983180428134557 and parameters: {'input_dim': 91, 'hidden_dim': 45, 'window_size': 4, 'b_size': 117, 'learning_rate': 0.04238416901495402, 'negative_slope': 0.1422395473272309, 'dropout_rate': 0.44024685305652084}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 17:55:54,247] Trial 25 finished with value: 0.389717125382263 and parameters: {'input_dim': 90, 'hidden_dim': 43, 'window_size': 4, 'b_size': 91, 'learning_rate': 0.03375313617982862, 'negative_slope': 0.1458991421264751, 'dropout_rate': 0.46131953878597376}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 17:56:32,618] Trial 26 finished with value: 0.39353975535168195 and parameters: {'input_dim': 150, 'hidden_dim': 44, 'window_size': 3, 'b_size': 107, 'learning_rate': 0.05263674780287418, 'negative_slope': 0.09630482402586982, 'dropout_rate': 0.43192821612791854}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 17:57:03,374] Trial 27 finished with value: 0.3893348623853211 and parameters: {'input_dim': 90, 'hidden_dim': 37, 'window_size': 4, 'b_size': 117, 'learning_rate': 0.025008857201090185, 'negative_slope': 0.14374125917315858, 'dropout_rate': 0.462465796380645}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 17:57:53,000] Trial 28 finished with value: 0.38837920489296635 and parameters: {'input_dim': 186, 'hidden_dim': 46, 'window_size': 6, 'b_size': 100, 'learning_rate': 0.05202490206283408, 'negative_slope': 0.17041676338060435, 'dropout_rate': 0.367111829949067}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 17:58:25,319] Trial 29 finished with value: 0.38837920489296635 and parameters: {'input_dim': 108, 'hidden_dim': 50, 'window_size': 7, 'b_size': 91, 'learning_rate': 0.023565568704138465, 'negative_slope': 0.04831672185411271, 'dropout_rate': 0.4104605466352536}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 17:59:10,995] Trial 30 finished with value: 0.3918195718654434 and parameters: {'input_dim': 159, 'hidden_dim': 24, 'window_size': 3, 'b_size': 84, 'learning_rate': 0.01352895003039595, 'negative_slope': 0.13534632023321005, 'dropout_rate': 0.1088017347852453}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 17:59:44,767] Trial 31 finished with value: 0.389717125382263 and parameters: {'input_dim': 127, 'hidden_dim': 33, 'window_size': 5, 'b_size': 119, 'learning_rate': 0.07920694253281309, 'negative_slope': 0.11375052641199153, 'dropout_rate': 0.38658206130818756}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:00:17,443] Trial 32 finished with value: 0.39315749235474007 and parameters: {'input_dim': 116, 'hidden_dim': 36, 'window_size': 4, 'b_size': 110, 'learning_rate': 0.030939456378984365, 'negative_slope': 0.10984552059014907, 'dropout_rate': 0.4433052266865185}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:00:54,146] Trial 33 finished with value: 0.3929663608562691 and parameters: {'input_dim': 144, 'hidden_dim': 30, 'window_size': 5, 'b_size': 120, 'learning_rate': 0.06531337057493755, 'negative_slope': 0.07884022310072877, 'dropout_rate': 0.3353344726311723}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:01:27,918] Trial 34 finished with value: 0.386085626911315 and parameters: {'input_dim': 134, 'hidden_dim': 33, 'window_size': 6, 'b_size': 114, 'learning_rate': 0.08914540211023302, 'negative_slope': 0.06441798867312543, 'dropout_rate': 0.4163723880621538}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:02:16,881] Trial 35 finished with value: 0.39048165137614677 and parameters: {'input_dim': 170, 'hidden_dim': 25, 'window_size': 5, 'b_size': 70, 'learning_rate': 0.04667716492904154, 'negative_slope': 0.10136340148506182, 'dropout_rate': 0.3692664910794978}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:02:47,512] Trial 36 finished with value: 0.38742354740061163 and parameters: {'input_dim': 102, 'hidden_dim': 39, 'window_size': 8, 'b_size': 128, 'learning_rate': 0.018681483729309438, 'negative_slope': 0.12262517978758555, 'dropout_rate': 0.4844344962292921}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:03:18,183] Trial 37 finished with value: 0.3977446483180428 and parameters: {'input_dim': 82, 'hidden_dim': 29, 'window_size': 5, 'b_size': 122, 'learning_rate': 0.06541222383238449, 'negative_slope': 0.08424247156647877, 'dropout_rate': 0.3418085711316908}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:03:49,201] Trial 38 finished with value: 0.39315749235474007 and parameters: {'input_dim': 79, 'hidden_dim': 11, 'window_size': 4, 'b_size': 96, 'learning_rate': 0.06984360101764102, 'negative_slope': 0.07585585917632717, 'dropout_rate': 0.33483167446828344}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:04:18,872] Trial 39 finished with value: 0.3853211009174312 and parameters: {'input_dim': 66, 'hidden_dim': 18, 'window_size': 3, 'b_size': 102, 'learning_rate': 0.044952669993632656, 'negative_slope': 0.08765275309018755, 'dropout_rate': 0.34551826859198653}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:04:48,808] Trial 40 finished with value: 0.3916284403669725 and parameters: {'input_dim': 53, 'hidden_dim': 29, 'window_size': 5, 'b_size': 112, 'learning_rate': 0.06545811539140006, 'negative_slope': 0.06317422946515971, 'dropout_rate': 0.3158111613633311}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:05:19,125] Trial 41 finished with value: 0.3912461773700306 and parameters: {'input_dim': 83, 'hidden_dim': 34, 'window_size': 5, 'b_size': 124, 'learning_rate': 0.09598744732912794, 'negative_slope': 0.13634602735430693, 'dropout_rate': 0.39981596688376}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:05:51,991] Trial 42 finished with value: 0.3952599388379205 and parameters: {'input_dim': 127, 'hidden_dim': 24, 'window_size': 4, 'b_size': 122, 'learning_rate': 0.13589430419224405, 'negative_slope': 0.09929715540738163, 'dropout_rate': 0.37450809319030176}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:06:27,703] Trial 43 finished with value: 0.3956422018348624 and parameters: {'input_dim': 141, 'hidden_dim': 31, 'window_size': 5, 'b_size': 118, 'learning_rate': 0.056448223491781586, 'negative_slope': 0.12652287036709486, 'dropout_rate': 0.3554524396326477}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:06:59,891] Trial 44 finished with value: 0.39067278287461776 and parameters: {'input_dim': 114, 'hidden_dim': 21, 'window_size': 7, 'b_size': 107, 'learning_rate': 0.07801025642872268, 'negative_slope': 0.16026041757036927, 'dropout_rate': 0.38515238429137966}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:07:32,607] Trial 45 finished with value: 0.38589449541284404 and parameters: {'input_dim': 71, 'hidden_dim': 14, 'window_size': 6, 'b_size': 59, 'learning_rate': 0.036705643020170625, 'negative_slope': 0.05344747872446838, 'dropout_rate': 0.4208973523463292}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:08:09,298] Trial 46 finished with value: 0.3952599388379205 and parameters: {'input_dim': 101, 'hidden_dim': 29, 'window_size': 4, 'b_size': 36, 'learning_rate': 0.14771864558701328, 'negative_slope': 0.10266904898337584, 'dropout_rate': 0.4049848657430842}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:08:41,298] Trial 47 finished with value: 0.38914373088685017 and parameters: {'input_dim': 120, 'hidden_dim': 26, 'window_size': 5, 'b_size': 124, 'learning_rate': 0.11780150377422605, 'negative_slope': 0.04043128526675858, 'dropout_rate': 0.4443766130296155}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:09:11,969] Trial 48 finished with value: 0.38742354740061163 and parameters: {'input_dim': 59, 'hidden_dim': 35, 'window_size': 6, 'b_size': 114, 'learning_rate': 0.04670852284119538, 'negative_slope': 0.08247124716427338, 'dropout_rate': 0.3843763220653109}. Best is trial 24 with value: 0.3983180428134557.\n",
      "[I 2023-12-22 18:09:53,615] Trial 49 finished with value: 0.3916284403669725 and parameters: {'input_dim': 152, 'hidden_dim': 40, 'window_size': 3, 'b_size': 85, 'learning_rate': 0.05807269573717298, 'negative_slope': 0.129806968645529, 'dropout_rate': 0.47363005399747676}. Best is trial 24 with value: 0.3983180428134557.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 91, 'hidden_dim': 45, 'window_size': 4, 'b_size': 117, 'learning_rate': 0.04238416901495402, 'negative_slope': 0.1422395473272309, 'dropout_rate': 0.44024685305652084}\n",
      "Best Accuracy: 0.3983180428134557\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.MultiMarginLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "def count_weighted_embedding(tokens, model, count_vectorizer):\n",
    "    word_ids = [model.wv.key_to_index[word] for word in tokens if word in model.wv]\n",
    "    word_counts = count_vectorizer.transform([' '.join(tokens)]).toarray()[0, word_ids]\n",
    "    word_vectors = np.array([model.wv[word] for word in tokens if word in model.wv])\n",
    "    return np.dot(word_counts, word_vectors) / np.sum(word_counts) if np.sum(word_counts) != 0 else np.zeros(model.vector_size)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    negative_slope = trial.suggest_float('negative_slope', 0.01, 0.3)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    count_vectorizer = CountVectorizer(vocabulary=word2vec_model.wv.key_to_index)\n",
    "    count_vectorizer.fit(data['tokenized_text'].apply(lambda x: ' '.join(x)))\n",
    "    data['count_embedding'] = data['tokenized_text'].apply(lambda tokens: count_weighted_embedding(tokens, word2vec_model, count_vectorizer))\n",
    "    valid['count_embedding'] = valid['tokenized_text'].apply(lambda tokens: count_weighted_embedding(tokens, word2vec_model, count_vectorizer))\n",
    "\n",
    "    x_train = np.vstack(data['count_embedding']).astype(np.float32)\n",
    "    x_val = np.vstack(valid['count_embedding']).astype(np.float32)\n",
    "\n",
    "\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e97bc",
   "metadata": {
    "papermill": {
     "duration": 0.120656,
     "end_time": "2023-12-22T18:09:53.990507",
     "exception": false,
     "start_time": "2023-12-22T18:09:53.869851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will stay with mean embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c52697f",
   "metadata": {
    "papermill": {
     "duration": 0.122458,
     "end_time": "2023-12-22T18:09:54.235756",
     "exception": false,
     "start_time": "2023-12-22T18:09:54.113298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will now check CBOW vs skip-gram, since CBOW is the default, just set sg=1 to use skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35bb1f71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T18:09:54.480945Z",
     "iopub.status.busy": "2023-12-22T18:09:54.480527Z",
     "iopub.status.idle": "2023-12-22T18:34:10.362197Z",
     "shell.execute_reply": "2023-12-22T18:34:10.361069Z"
    },
    "papermill": {
     "duration": 1456.007853,
     "end_time": "2023-12-22T18:34:10.364993",
     "exception": false,
     "start_time": "2023-12-22T18:09:54.357140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 18:09:54,507] A new study created in memory with name: no-name-9bacf3e0-3ed6-4261-977a-a5511e52b387\n",
      "[I 2023-12-22 18:10:24,162] Trial 0 finished with value: 0.3964067278287462 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90, 'learning_rate': 0.020513382630874502, 'negative_slope': 0.055238410897498764, 'dropout_rate': 0.12323344486727979}. Best is trial 0 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 18:11:05,680] Trial 1 finished with value: 0.3929663608562691 and parameters: {'input_dim': 180, 'hidden_dim': 34, 'window_size': 8, 'b_size': 33, 'learning_rate': 0.8706020878304853, 'negative_slope': 0.2514083658321223, 'dropout_rate': 0.18493564427131048}. Best is trial 0 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 18:11:31,742] Trial 2 finished with value: 0.39353975535168195 and parameters: {'input_dim': 77, 'hidden_dim': 17, 'window_size': 5, 'b_size': 82, 'learning_rate': 0.0730953983591291, 'negative_slope': 0.09445645065743215, 'dropout_rate': 0.34474115788895177}. Best is trial 0 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 18:11:57,106] Trial 3 finished with value: 0.39659785932721714 and parameters: {'input_dim': 71, 'hidden_dim': 21, 'window_size': 5, 'b_size': 76, 'learning_rate': 0.3718364180573207, 'negative_slope': 0.06790539682592432, 'dropout_rate': 0.3056937753654446}. Best is trial 3 with value: 0.39659785932721714.\n",
      "[I 2023-12-22 18:12:29,504] Trial 4 finished with value: 0.3878058103975535 and parameters: {'input_dim': 139, 'hidden_dim': 11, 'window_size': 7, 'b_size': 48, 'learning_rate': 0.013492834268013254, 'negative_slope': 0.2851768058034666, 'dropout_rate': 0.4862528132298237}. Best is trial 3 with value: 0.39659785932721714.\n",
      "[I 2023-12-22 18:12:53,299] Trial 5 finished with value: 0.39793577981651373 and parameters: {'input_dim': 172, 'hidden_dim': 22, 'window_size': 3, 'b_size': 98, 'learning_rate': 0.07591104805282695, 'negative_slope': 0.045391088104985856, 'dropout_rate': 0.29807076404450805}. Best is trial 5 with value: 0.39793577981651373.\n",
      "[I 2023-12-22 18:13:19,716] Trial 6 finished with value: 0.3977446483180428 and parameters: {'input_dim': 55, 'hidden_dim': 47, 'window_size': 5, 'b_size': 96, 'learning_rate': 0.0420167205437253, 'negative_slope': 0.16081972614156514, 'dropout_rate': 0.31868411173731187}. Best is trial 5 with value: 0.39793577981651373.\n",
      "[I 2023-12-22 18:13:49,129] Trial 7 finished with value: 0.3948776758409786 and parameters: {'input_dim': 77, 'hidden_dim': 49, 'window_size': 9, 'b_size': 123, 'learning_rate': 0.6161049539380962, 'negative_slope': 0.18339099385521468, 'dropout_rate': 0.4687496940092467}. Best is trial 5 with value: 0.39793577981651373.\n",
      "[I 2023-12-22 18:14:14,788] Trial 8 finished with value: 0.39258409785932724 and parameters: {'input_dim': 63, 'hidden_dim': 18, 'window_size': 3, 'b_size': 63, 'learning_rate': 0.05989003672254302, 'negative_slope': 0.08869121921442981, 'dropout_rate': 0.43149500366077176}. Best is trial 5 with value: 0.39793577981651373.\n",
      "[I 2023-12-22 18:14:45,908] Trial 9 finished with value: 0.393348623853211 and parameters: {'input_dim': 103, 'hidden_dim': 21, 'window_size': 7, 'b_size': 45, 'learning_rate': 0.40215545266902863, 'negative_slope': 0.03161968666713354, 'dropout_rate': 0.4947547746402069}. Best is trial 5 with value: 0.39793577981651373.\n",
      "[I 2023-12-22 18:15:09,748] Trial 10 finished with value: 0.39717125382262997 and parameters: {'input_dim': 197, 'hidden_dim': 32, 'window_size': 3, 'b_size': 116, 'learning_rate': 0.19062374828215087, 'negative_slope': 0.021230307988743036, 'dropout_rate': 0.2324184326866336}. Best is trial 5 with value: 0.39793577981651373.\n",
      "[I 2023-12-22 18:15:39,100] Trial 11 finished with value: 0.39353975535168195 and parameters: {'input_dim': 153, 'hidden_dim': 40, 'window_size': 5, 'b_size': 101, 'learning_rate': 0.037371915976610284, 'negative_slope': 0.14407993006227715, 'dropout_rate': 0.3609641605728968}. Best is trial 5 with value: 0.39793577981651373.\n",
      "[I 2023-12-22 18:16:03,941] Trial 12 finished with value: 0.39717125382262997 and parameters: {'input_dim': 164, 'hidden_dim': 26, 'window_size': 4, 'b_size': 102, 'learning_rate': 0.1505863530759576, 'negative_slope': 0.14928549883954612, 'dropout_rate': 0.258340918010901}. Best is trial 5 with value: 0.39793577981651373.\n",
      "[I 2023-12-22 18:16:32,040] Trial 13 finished with value: 0.3985091743119266 and parameters: {'input_dim': 127, 'hidden_dim': 41, 'window_size': 4, 'b_size': 106, 'learning_rate': 0.03475211410449034, 'negative_slope': 0.12087881286355537, 'dropout_rate': 0.3695456595762009}. Best is trial 13 with value: 0.3985091743119266.\n",
      "[I 2023-12-22 18:16:56,764] Trial 14 finished with value: 0.39717125382262997 and parameters: {'input_dim': 121, 'hidden_dim': 38, 'window_size': 3, 'b_size': 112, 'learning_rate': 0.10624164010756049, 'negative_slope': 0.10831410189647292, 'dropout_rate': 0.38067962835917035}. Best is trial 13 with value: 0.3985091743119266.\n",
      "[I 2023-12-22 18:17:20,830] Trial 15 finished with value: 0.3973623853211009 and parameters: {'input_dim': 167, 'hidden_dim': 26, 'window_size': 4, 'b_size': 127, 'learning_rate': 0.026354747293806734, 'negative_slope': 0.026279638076050733, 'dropout_rate': 0.40064536992631566}. Best is trial 13 with value: 0.3985091743119266.\n",
      "[I 2023-12-22 18:17:46,916] Trial 16 finished with value: 0.3943042813455658 and parameters: {'input_dim': 134, 'hidden_dim': 42, 'window_size': 4, 'b_size': 73, 'learning_rate': 0.014121605456755785, 'negative_slope': 0.010788842341495464, 'dropout_rate': 0.2788221602375691}. Best is trial 13 with value: 0.3985091743119266.\n",
      "[I 2023-12-22 18:18:25,641] Trial 17 finished with value: 0.39545107033639143 and parameters: {'input_dim': 187, 'hidden_dim': 27, 'window_size': 10, 'b_size': 109, 'learning_rate': 0.053154792930382395, 'negative_slope': 0.06738381465129724, 'dropout_rate': 0.3335165327336942}. Best is trial 13 with value: 0.3985091743119266.\n",
      "[I 2023-12-22 18:18:51,407] Trial 18 finished with value: 0.382262996941896 and parameters: {'input_dim': 99, 'hidden_dim': 11, 'window_size': 6, 'b_size': 88, 'learning_rate': 0.010065584837123377, 'negative_slope': 0.12008910506907448, 'dropout_rate': 0.4116892727837296}. Best is trial 13 with value: 0.3985091743119266.\n",
      "[I 2023-12-22 18:19:23,747] Trial 19 finished with value: 0.39870030581039756 and parameters: {'input_dim': 148, 'hidden_dim': 37, 'window_size': 6, 'b_size': 66, 'learning_rate': 0.029039974443545228, 'negative_slope': 0.05639719956430627, 'dropout_rate': 0.3648838960603847}. Best is trial 19 with value: 0.39870030581039756.\n",
      "[I 2023-12-22 18:19:54,412] Trial 20 finished with value: 0.3964067278287462 and parameters: {'input_dim': 136, 'hidden_dim': 36, 'window_size': 6, 'b_size': 64, 'learning_rate': 0.029880920724717534, 'negative_slope': 0.08188075914434605, 'dropout_rate': 0.3692880122935688}. Best is trial 19 with value: 0.39870030581039756.\n",
      "[I 2023-12-22 18:20:24,566] Trial 21 finished with value: 0.4032874617737003 and parameters: {'input_dim': 158, 'hidden_dim': 43, 'window_size': 4, 'b_size': 70, 'learning_rate': 0.04248617371725663, 'negative_slope': 0.05375603786528321, 'dropout_rate': 0.3073489423600342}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:20:54,530] Trial 22 finished with value: 0.3941131498470948 and parameters: {'input_dim': 152, 'hidden_dim': 44, 'window_size': 4, 'b_size': 68, 'learning_rate': 0.02416372439062231, 'negative_slope': 0.061780932341202306, 'dropout_rate': 0.340134977750168}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:21:29,984] Trial 23 finished with value: 0.3956422018348624 and parameters: {'input_dim': 120, 'hidden_dim': 45, 'window_size': 6, 'b_size': 53, 'learning_rate': 0.039184471736646145, 'negative_slope': 0.042159795492003035, 'dropout_rate': 0.449256971408749}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:22:00,065] Trial 24 finished with value: 0.39659785932721714 and parameters: {'input_dim': 152, 'hidden_dim': 38, 'window_size': 4, 'b_size': 56, 'learning_rate': 0.01899611023273874, 'negative_slope': 0.11588930251884011, 'dropout_rate': 0.39667097796198697}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:22:28,566] Trial 25 finished with value: 0.39621559633027525 and parameters: {'input_dim': 145, 'hidden_dim': 42, 'window_size': 5, 'b_size': 83, 'learning_rate': 0.03438686707948979, 'negative_slope': 0.0803867450784547, 'dropout_rate': 0.36819742669356237}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:23:00,734] Trial 26 finished with value: 0.39353975535168195 and parameters: {'input_dim': 115, 'hidden_dim': 32, 'window_size': 7, 'b_size': 72, 'learning_rate': 0.048527052104910054, 'negative_slope': 0.048584576019003234, 'dropout_rate': 0.32231596867471834}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:23:33,560] Trial 27 finished with value: 0.3908639143730887 and parameters: {'input_dim': 91, 'hidden_dim': 37, 'window_size': 6, 'b_size': 61, 'learning_rate': 0.027306971046600702, 'negative_slope': 0.012675109977552244, 'dropout_rate': 0.4437884106748379}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:24:04,325] Trial 28 finished with value: 0.39621559633027525 and parameters: {'input_dim': 131, 'hidden_dim': 41, 'window_size': 8, 'b_size': 78, 'learning_rate': 0.05391311240288325, 'negative_slope': 0.103037860535201, 'dropout_rate': 0.4123437805002912}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:24:36,259] Trial 29 finished with value: 0.39105504587155965 and parameters: {'input_dim': 163, 'hidden_dim': 50, 'window_size': 9, 'b_size': 89, 'learning_rate': 0.018263353619814345, 'negative_slope': 0.05470923873846864, 'dropout_rate': 0.35036452495681164}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:25:09,717] Trial 30 finished with value: 0.39315749235474007 and parameters: {'input_dim': 175, 'hidden_dim': 46, 'window_size': 4, 'b_size': 35, 'learning_rate': 0.03336742978531739, 'negative_slope': 0.04073530899776879, 'dropout_rate': 0.1088017347852453}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:25:36,400] Trial 31 finished with value: 0.3918195718654434 and parameters: {'input_dim': 157, 'hidden_dim': 30, 'window_size': 3, 'b_size': 96, 'learning_rate': 0.07678109015514355, 'negative_slope': 0.0425078767341335, 'dropout_rate': 0.2905216331435823}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:26:02,119] Trial 32 finished with value: 0.39602446483180426 and parameters: {'input_dim': 178, 'hidden_dim': 35, 'window_size': 3, 'b_size': 105, 'learning_rate': 0.07454010908034898, 'negative_slope': 0.06743250969434098, 'dropout_rate': 0.30433085623535827}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:26:29,139] Trial 33 finished with value: 0.3958333333333333 and parameters: {'input_dim': 191, 'hidden_dim': 29, 'window_size': 3, 'b_size': 93, 'learning_rate': 0.022574015209238584, 'negative_slope': 0.03225837913320136, 'dropout_rate': 0.26618031995979513}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:26:56,905] Trial 34 finished with value: 0.3977446483180428 and parameters: {'input_dim': 144, 'hidden_dim': 23, 'window_size': 5, 'b_size': 84, 'learning_rate': 0.0417511512488339, 'negative_slope': 0.08670804834256768, 'dropout_rate': 0.32604078760642663}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:27:23,188] Trial 35 finished with value: 0.3941131498470948 and parameters: {'input_dim': 176, 'hidden_dim': 33, 'window_size': 4, 'b_size': 114, 'learning_rate': 0.09504085341125183, 'negative_slope': 0.055317097421617736, 'dropout_rate': 0.2996115567236589}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:27:49,627] Trial 36 finished with value: 0.39048165137614677 and parameters: {'input_dim': 169, 'hidden_dim': 15, 'window_size': 5, 'b_size': 120, 'learning_rate': 0.05379945467655068, 'negative_slope': 0.07320937063414686, 'dropout_rate': 0.3496805064962903}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:28:14,764] Trial 37 finished with value: 0.39392201834862384 and parameters: {'input_dim': 113, 'hidden_dim': 39, 'window_size': 3, 'b_size': 78, 'learning_rate': 0.031165930524292812, 'negative_slope': 0.09535002032895934, 'dropout_rate': 0.23397465698230782}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:28:42,141] Trial 38 finished with value: 0.39793577981651373 and parameters: {'input_dim': 130, 'hidden_dim': 44, 'window_size': 5, 'b_size': 70, 'learning_rate': 0.06518899247116335, 'negative_slope': 0.05432861589993481, 'dropout_rate': 0.38598962064154446}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:29:19,542] Trial 39 finished with value: 0.3967889908256881 and parameters: {'input_dim': 146, 'hidden_dim': 48, 'window_size': 8, 'b_size': 43, 'learning_rate': 0.0470399081628387, 'negative_slope': 0.12244612477197087, 'dropout_rate': 0.31172963692217137}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:29:44,023] Trial 40 finished with value: 0.3912461773700306 and parameters: {'input_dim': 160, 'hidden_dim': 17, 'window_size': 4, 'b_size': 97, 'learning_rate': 0.020267837381956658, 'negative_slope': 0.19756993550044466, 'dropout_rate': 0.16658701374557838}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:30:15,148] Trial 41 finished with value: 0.3922018348623853 and parameters: {'input_dim': 127, 'hidden_dim': 44, 'window_size': 5, 'b_size': 70, 'learning_rate': 0.06852278429414228, 'negative_slope': 0.056257817590950145, 'dropout_rate': 0.3824374073462056}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:30:44,604] Trial 42 finished with value: 0.3929663608562691 and parameters: {'input_dim': 140, 'hidden_dim': 43, 'window_size': 5, 'b_size': 58, 'learning_rate': 0.04169473473232872, 'negative_slope': 0.028755452690044227, 'dropout_rate': 0.3449953656264931}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:31:18,079] Trial 43 finished with value: 0.3958333333333333 and parameters: {'input_dim': 127, 'hidden_dim': 47, 'window_size': 6, 'b_size': 66, 'learning_rate': 0.06063217809929713, 'negative_slope': 0.06965706198671838, 'dropout_rate': 0.3252452702097397}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:31:46,395] Trial 44 finished with value: 0.39258409785932724 and parameters: {'input_dim': 171, 'hidden_dim': 40, 'window_size': 5, 'b_size': 85, 'learning_rate': 0.0865634940111582, 'negative_slope': 0.09501537827109664, 'dropout_rate': 0.38525001418022425}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:32:14,245] Trial 45 finished with value: 0.39755351681957185 and parameters: {'input_dim': 183, 'hidden_dim': 34, 'window_size': 4, 'b_size': 107, 'learning_rate': 0.11095095761547288, 'negative_slope': 0.07605187958046349, 'dropout_rate': 0.35503586243135216}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:32:44,487] Trial 46 finished with value: 0.38990825688073394 and parameters: {'input_dim': 110, 'hidden_dim': 21, 'window_size': 7, 'b_size': 74, 'learning_rate': 0.05910944422429894, 'negative_slope': 0.03960991149377993, 'dropout_rate': 0.3639132271698513}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:33:12,133] Trial 47 finished with value: 0.39067278287461776 and parameters: {'input_dim': 94, 'hidden_dim': 24, 'window_size': 3, 'b_size': 51, 'learning_rate': 0.04337163393820145, 'negative_slope': 0.01994835128199047, 'dropout_rate': 0.28875213266901545}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:33:40,614] Trial 48 finished with value: 0.3929663608562691 and parameters: {'input_dim': 149, 'hidden_dim': 41, 'window_size': 4, 'b_size': 60, 'learning_rate': 0.03548202816485526, 'negative_slope': 0.0547411040998265, 'dropout_rate': 0.31325124139916294}. Best is trial 21 with value: 0.4032874617737003.\n",
      "[I 2023-12-22 18:34:10,356] Trial 49 finished with value: 0.3937308868501529 and parameters: {'input_dim': 199, 'hidden_dim': 14, 'window_size': 6, 'b_size': 102, 'learning_rate': 0.06644408199995129, 'negative_slope': 0.03130833444225966, 'dropout_rate': 0.33754572930438353}. Best is trial 21 with value: 0.4032874617737003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 158, 'hidden_dim': 43, 'window_size': 4, 'b_size': 70, 'learning_rate': 0.04248617371725663, 'negative_slope': 0.05375603786528321, 'dropout_rate': 0.3073489423600342}\n",
      "Best Accuracy: 0.4032874617737003\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.MultiMarginLoss()\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    negative_slope = trial.suggest_float('negative_slope', 0.01, 0.3)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1,sg=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e74e8",
   "metadata": {
    "papermill": {
     "duration": 0.128473,
     "end_time": "2023-12-22T18:34:10.621919",
     "exception": false,
     "start_time": "2023-12-22T18:34:10.493446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ok so CBOW is better, hold the varaibles and model so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c24d96",
   "metadata": {
    "papermill": {
     "duration": 0.128407,
     "end_time": "2023-12-22T18:34:10.878669",
     "exception": false,
     "start_time": "2023-12-22T18:34:10.750262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Calculate scores of our model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8db70368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T18:34:11.139631Z",
     "iopub.status.busy": "2023-12-22T18:34:11.138685Z",
     "iopub.status.idle": "2023-12-22T18:34:31.714659Z",
     "shell.execute_reply": "2023-12-22T18:34:31.713804Z"
    },
    "papermill": {
     "duration": 20.709957,
     "end_time": "2023-12-22T18:34:31.717011",
     "exception": false,
     "start_time": "2023-12-22T18:34:11.007054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38570\n",
      "Precision: 0.39104\n",
      "Recall: 0.38570\n",
      "F1 Score: 0.37479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "input_dim = 79\n",
    "hidden_dim = 13\n",
    "window_size = 3\n",
    "b_size = 60\n",
    "learning_rate = 0.08404865818989572\n",
    "negative_slope = 0.0548250323680545\n",
    "dropout_rate = 0.39062278420204216\n",
    "n_epochs=11\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "criterion=nn.MultiMarginLoss()\n",
    "model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "x_train = data['mean_embedding']\n",
    "x_val = valid['mean_embedding']\n",
    "y_val = valid['Sentiment']\n",
    "y_train = data['Sentiment']\n",
    "    \n",
    "x_train = np.vstack(x_train).astype(np.float32)\n",
    "x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "y_val = y_val.values\n",
    "y_train = y_train.values\n",
    "data_set = Data(x_train, y_train, input_dim)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model.forward(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "x_val_tensor = torch.from_numpy(x_val)\n",
    "z_val = model.forward(x_val_tensor)\n",
    "max_indexes = torch.argmax(z_val, dim=1)\n",
    "\n",
    "y_pred = max_indexes.numpy()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Precision: {precision:.5f}')\n",
    "print(f'Recall: {recall:.5f}')\n",
    "print(f'F1 Score: {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793b4ea4",
   "metadata": {
    "papermill": {
     "duration": 0.129029,
     "end_time": "2023-12-22T18:34:31.975318",
     "exception": false,
     "start_time": "2023-12-22T18:34:31.846289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Some more optuna studies, in the first we keep fixed decimals and in the second we keep fixed integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "971a0866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T18:34:32.234183Z",
     "iopub.status.busy": "2023-12-22T18:34:32.233569Z",
     "iopub.status.idle": "2023-12-22T18:41:21.504302Z",
     "shell.execute_reply": "2023-12-22T18:41:21.502966Z"
    },
    "papermill": {
     "duration": 409.527618,
     "end_time": "2023-12-22T18:41:21.632811",
     "exception": false,
     "start_time": "2023-12-22T18:34:32.105193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 18:34:32,259] A new study created in memory with name: no-name-36e3826c-04a1-42fc-9831-da187be7b13a\n",
      "[I 2023-12-22 18:34:51,896] Trial 0 finished with value: 0.39908256880733944 and parameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:35:09,312] Trial 1 finished with value: 0.39239296636085624 and parameters: {'input_dim': 73, 'hidden_dim': 16, 'window_size': 3, 'b_size': 116}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:35:28,074] Trial 2 finished with value: 0.39315749235474007 and parameters: {'input_dim': 140, 'hidden_dim': 39, 'window_size': 3, 'b_size': 126}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:35:51,310] Trial 3 finished with value: 0.3944954128440367 and parameters: {'input_dim': 175, 'hidden_dim': 18, 'window_size': 4, 'b_size': 49}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:36:13,309] Trial 4 finished with value: 0.39239296636085624 and parameters: {'input_dim': 95, 'hidden_dim': 31, 'window_size': 6, 'b_size': 60}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:36:34,648] Trial 5 finished with value: 0.3958333333333333 and parameters: {'input_dim': 142, 'hidden_dim': 15, 'window_size': 5, 'b_size': 67}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:36:55,231] Trial 6 finished with value: 0.39812691131498473 and parameters: {'input_dim': 118, 'hidden_dim': 42, 'window_size': 4, 'b_size': 81}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:37:17,705] Trial 7 finished with value: 0.3918195718654434 and parameters: {'input_dim': 139, 'hidden_dim': 11, 'window_size': 7, 'b_size': 48}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:37:36,710] Trial 8 finished with value: 0.39258409785932724 and parameters: {'input_dim': 59, 'hidden_dim': 48, 'window_size': 10, 'b_size': 110}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:37:57,275] Trial 9 finished with value: 0.39793577981651373 and parameters: {'input_dim': 95, 'hidden_dim': 14, 'window_size': 8, 'b_size': 74}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:38:17,060] Trial 10 finished with value: 0.39239296636085624 and parameters: {'input_dim': 192, 'hidden_dim': 29, 'window_size': 10, 'b_size': 94}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:38:36,477] Trial 11 finished with value: 0.3956422018348624 and parameters: {'input_dim': 109, 'hidden_dim': 47, 'window_size': 7, 'b_size': 91}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:38:56,235] Trial 12 finished with value: 0.39621559633027525 and parameters: {'input_dim': 114, 'hidden_dim': 40, 'window_size': 8, 'b_size': 89}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:39:15,045] Trial 13 finished with value: 0.38742354740061163 and parameters: {'input_dim': 82, 'hidden_dim': 40, 'window_size': 5, 'b_size': 105}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:39:35,826] Trial 14 finished with value: 0.3956422018348624 and parameters: {'input_dim': 162, 'hidden_dim': 50, 'window_size': 9, 'b_size': 82}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:39:55,376] Trial 15 finished with value: 0.39105504587155965 and parameters: {'input_dim': 126, 'hidden_dim': 35, 'window_size': 6, 'b_size': 99}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:40:16,146] Trial 16 finished with value: 0.3937308868501529 and parameters: {'input_dim': 120, 'hidden_dim': 45, 'window_size': 8, 'b_size': 77}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:40:40,806] Trial 17 finished with value: 0.3878058103975535 and parameters: {'input_dim': 96, 'hidden_dim': 26, 'window_size': 5, 'b_size': 35}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:41:01,482] Trial 18 finished with value: 0.3941131498470948 and parameters: {'input_dim': 53, 'hidden_dim': 43, 'window_size': 4, 'b_size': 62}. Best is trial 0 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 18:41:21,495] Trial 19 finished with value: 0.3902905198776758 and parameters: {'input_dim': 160, 'hidden_dim': 22, 'window_size': 9, 'b_size': 84}. Best is trial 0 with value: 0.39908256880733944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 106, 'hidden_dim': 48, 'window_size': 8, 'b_size': 90}\n",
      "Best Accuracy: 0.39908256880733944\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.MultiMarginLoss()\n",
    "\n",
    "learning_rate = 0.08404865818989572\n",
    "negative_slope = 0.0548250323680545\n",
    "dropout_rate = 0.39062278420204216\n",
    "n_epochs=11\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 50, 200)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)\n",
    "    window_size = trial.suggest_int('window_size', 3, 10)\n",
    "    b_size = trial.suggest_int('b_size', 32, 128)\n",
    "    model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00bc3e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T18:41:22.002997Z",
     "iopub.status.busy": "2023-12-22T18:41:22.002548Z",
     "iopub.status.idle": "2023-12-22T18:57:32.023813Z",
     "shell.execute_reply": "2023-12-22T18:57:32.022588Z"
    },
    "papermill": {
     "duration": 970.40017,
     "end_time": "2023-12-22T18:57:32.161509",
     "exception": false,
     "start_time": "2023-12-22T18:41:21.761339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 18:41:22,029] A new study created in memory with name: no-name-ac2c670d-2c6b-44f1-8117-aceee64109b7\n",
      "[I 2023-12-22 18:41:41,392] Trial 0 finished with value: 0.3885703363914373 and parameters: {'learning_rate': 0.05611516415334506, 'negative_slope': 0.28570714885887566, 'dropout_rate': 0.39279757672456206}. Best is trial 0 with value: 0.3885703363914373.\n",
      "[I 2023-12-22 18:42:00,829] Trial 1 finished with value: 0.3952599388379205 and parameters: {'learning_rate': 0.15751320499779725, 'negative_slope': 0.055245405728306586, 'dropout_rate': 0.16239780813448107}. Best is trial 1 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 18:42:20,312] Trial 2 finished with value: 0.38512996941896027 and parameters: {'learning_rate': 0.01306673923805328, 'negative_slope': 0.2611910822747312, 'dropout_rate': 0.34044600469728353}. Best is trial 1 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 18:42:39,698] Trial 3 finished with value: 0.3780581039755352 and parameters: {'learning_rate': 0.2607024758370766, 'negative_slope': 0.01596950334578271, 'dropout_rate': 0.4879639408647978}. Best is trial 1 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 18:42:58,944] Trial 4 finished with value: 0.3918195718654434 and parameters: {'learning_rate': 0.46225890010208287, 'negative_slope': 0.07157834209670008, 'dropout_rate': 0.17272998688284025}. Best is trial 1 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 18:43:18,689] Trial 5 finished with value: 0.39067278287461776 and parameters: {'learning_rate': 0.023270677083837805, 'negative_slope': 0.09823025045826593, 'dropout_rate': 0.3099025726528951}. Best is trial 1 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 18:43:37,678] Trial 6 finished with value: 0.38876146788990823 and parameters: {'learning_rate': 0.0730953983591291, 'negative_slope': 0.09445645065743215, 'dropout_rate': 0.34474115788895177}. Best is trial 1 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 18:43:57,146] Trial 7 finished with value: 0.3878058103975535 and parameters: {'learning_rate': 0.01901024531987036, 'negative_slope': 0.09472194807521325, 'dropout_rate': 0.2465447373174767}. Best is trial 1 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 18:44:16,318] Trial 8 finished with value: 0.39201070336391436 and parameters: {'learning_rate': 0.08168455894760163, 'negative_slope': 0.23770102880397392, 'dropout_rate': 0.1798695128633439}. Best is trial 1 with value: 0.3952599388379205.\n",
      "[I 2023-12-22 18:44:35,889] Trial 9 finished with value: 0.3992737003058104 and parameters: {'learning_rate': 0.10677482709481352, 'negative_slope': 0.18180022496999232, 'dropout_rate': 0.1185801650879991}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:44:55,246] Trial 10 finished with value: 0.38685015290519875 and parameters: {'learning_rate': 0.7767353816237056, 'negative_slope': 0.17206676049466552, 'dropout_rate': 0.10301892772651725}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:45:14,646] Trial 11 finished with value: 0.39621559633027525 and parameters: {'learning_rate': 0.18865795090233672, 'negative_slope': 0.17837725418509429, 'dropout_rate': 0.11549007998447319}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:45:33,815] Trial 12 finished with value: 0.38704128440366975 and parameters: {'learning_rate': 0.1852672621177597, 'negative_slope': 0.18571925719574572, 'dropout_rate': 0.11372209010541334}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:45:53,132] Trial 13 finished with value: 0.39239296636085624 and parameters: {'learning_rate': 0.2997858219123054, 'negative_slope': 0.20747699127826227, 'dropout_rate': 0.22868553993477786}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:46:12,609] Trial 14 finished with value: 0.3902905198776758 and parameters: {'learning_rate': 0.15130044019859265, 'negative_slope': 0.1496504997489514, 'dropout_rate': 0.10734661789881295}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:46:31,943] Trial 15 finished with value: 0.39353975535168195 and parameters: {'learning_rate': 0.04330843599379615, 'negative_slope': 0.1338625686336662, 'dropout_rate': 0.22331784053423187}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:46:51,012] Trial 16 finished with value: 0.396980122324159 and parameters: {'learning_rate': 0.0949050809991461, 'negative_slope': 0.2203093509900833, 'dropout_rate': 0.15163896751272624}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:47:10,450] Trial 17 finished with value: 0.39506880733944955 and parameters: {'learning_rate': 0.11364695031944959, 'negative_slope': 0.22502113806366736, 'dropout_rate': 0.25553067644681304}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:47:29,653] Trial 18 finished with value: 0.3943042813455658 and parameters: {'learning_rate': 0.049575472370886414, 'negative_slope': 0.2955564274118534, 'dropout_rate': 0.15992888030708413}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:47:49,681] Trial 19 finished with value: 0.3944954128440367 and parameters: {'learning_rate': 0.09920562866268191, 'negative_slope': 0.19927243487263882, 'dropout_rate': 0.2077155921747506}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:48:09,343] Trial 20 finished with value: 0.38990825688073394 and parameters: {'learning_rate': 0.11964440822944998, 'negative_slope': 0.24234130615657012, 'dropout_rate': 0.14016810061617582}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:48:28,583] Trial 21 finished with value: 0.39755351681957185 and parameters: {'learning_rate': 0.21223297272287142, 'negative_slope': 0.16959590857765022, 'dropout_rate': 0.12857740970185821}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:48:47,545] Trial 22 finished with value: 0.3927752293577982 and parameters: {'learning_rate': 0.2881838632933018, 'negative_slope': 0.2106479881234181, 'dropout_rate': 0.134195539427752}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:49:07,023] Trial 23 finished with value: 0.39545107033639143 and parameters: {'learning_rate': 0.07081804930652909, 'negative_slope': 0.1563537250784079, 'dropout_rate': 0.20248103175153623}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:49:26,233] Trial 24 finished with value: 0.3956422018348624 and parameters: {'learning_rate': 0.03955076298081961, 'negative_slope': 0.19256670987668453, 'dropout_rate': 0.14534022205433333}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:49:46,107] Trial 25 finished with value: 0.3985091743119266 and parameters: {'learning_rate': 0.10923612945018499, 'negative_slope': 0.14110580935113937, 'dropout_rate': 0.18564901182329432}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:50:05,193] Trial 26 finished with value: 0.3944954128440367 and parameters: {'learning_rate': 0.13523278059350785, 'negative_slope': 0.13405655646723844, 'dropout_rate': 0.18155049934366374}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:50:24,575] Trial 27 finished with value: 0.38914373088685017 and parameters: {'learning_rate': 0.21666999975733559, 'negative_slope': 0.1582629519150773, 'dropout_rate': 0.18945180230591688}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:50:43,989] Trial 28 finished with value: 0.39468654434250766 and parameters: {'learning_rate': 0.39799202153811797, 'negative_slope': 0.12929893937990938, 'dropout_rate': 0.10039502534910992}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:51:03,237] Trial 29 finished with value: 0.3943042813455658 and parameters: {'learning_rate': 0.06179026754645451, 'negative_slope': 0.1925053131486464, 'dropout_rate': 0.13378108423607632}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:51:22,599] Trial 30 finished with value: 0.3948776758409786 and parameters: {'learning_rate': 0.10236651619064069, 'negative_slope': 0.17087104863641628, 'dropout_rate': 0.2613369045749434}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:51:41,944] Trial 31 finished with value: 0.3958333333333333 and parameters: {'learning_rate': 0.08747327784907895, 'negative_slope': 0.2133465358301562, 'dropout_rate': 0.1529133521377467}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:52:01,497] Trial 32 finished with value: 0.39812691131498473 and parameters: {'learning_rate': 0.14811744538557448, 'negative_slope': 0.27066400891245884, 'dropout_rate': 0.13615613828611883}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:52:20,878] Trial 33 finished with value: 0.3943042813455658 and parameters: {'learning_rate': 0.14923704131628576, 'negative_slope': 0.27779447994787837, 'dropout_rate': 0.16974206816500798}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:52:39,942] Trial 34 finished with value: 0.39545107033639143 and parameters: {'learning_rate': 0.1692666574942089, 'negative_slope': 0.24080165094913614, 'dropout_rate': 0.12482268575986183}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:52:59,294] Trial 35 finished with value: 0.3988914373088685 and parameters: {'learning_rate': 0.1367984408357433, 'negative_slope': 0.2677058216629146, 'dropout_rate': 0.15764285879005982}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:53:18,475] Trial 36 finished with value: 0.3943042813455658 and parameters: {'learning_rate': 0.05968053460603584, 'negative_slope': 0.2704089512270867, 'dropout_rate': 0.1947743349524126}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:53:38,276] Trial 37 finished with value: 0.38876146788990823 and parameters: {'learning_rate': 0.1201957949808941, 'negative_slope': 0.2606421923090539, 'dropout_rate': 0.16461156384562892}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:53:57,979] Trial 38 finished with value: 0.39908256880733944 and parameters: {'learning_rate': 0.13330021019053923, 'negative_slope': 0.2948814203506209, 'dropout_rate': 0.1663125487693532}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:54:17,238] Trial 39 finished with value: 0.39602446483180426 and parameters: {'learning_rate': 0.0761805414526949, 'negative_slope': 0.2979774406896317, 'dropout_rate': 0.17024122718255233}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:54:36,288] Trial 40 finished with value: 0.39353975535168195 and parameters: {'learning_rate': 0.12528721643499596, 'negative_slope': 0.29250762899335964, 'dropout_rate': 0.2777684905857647}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:54:55,630] Trial 41 finished with value: 0.3967889908256881 and parameters: {'learning_rate': 0.1512697800649813, 'negative_slope': 0.2808391908095217, 'dropout_rate': 0.1467626885566937}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:55:14,975] Trial 42 finished with value: 0.3964067278287462 and parameters: {'learning_rate': 0.22117010655438793, 'negative_slope': 0.2583528582005831, 'dropout_rate': 0.184596575227011}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:55:34,865] Trial 43 finished with value: 0.3918195718654434 and parameters: {'learning_rate': 0.09825352069933375, 'negative_slope': 0.2861718111155023, 'dropout_rate': 0.12166778374273593}. Best is trial 9 with value: 0.3992737003058104.\n",
      "[I 2023-12-22 18:55:54,436] Trial 44 finished with value: 0.4004204892966361 and parameters: {'learning_rate': 0.1706362683105582, 'negative_slope': 0.2717541465247187, 'dropout_rate': 0.20659160596227932}. Best is trial 44 with value: 0.4004204892966361.\n",
      "[I 2023-12-22 18:56:13,973] Trial 45 finished with value: 0.3885703363914373 and parameters: {'learning_rate': 0.1752433883301496, 'negative_slope': 0.2491512649089314, 'dropout_rate': 0.2294098783313146}. Best is trial 44 with value: 0.4004204892966361.\n",
      "[I 2023-12-22 18:56:33,104] Trial 46 finished with value: 0.3916284403669725 and parameters: {'learning_rate': 0.0820407015643071, 'negative_slope': 0.23040551990979502, 'dropout_rate': 0.21494366753152577}. Best is trial 44 with value: 0.4004204892966361.\n",
      "[I 2023-12-22 18:56:52,577] Trial 47 finished with value: 0.38685015290519875 and parameters: {'learning_rate': 0.12207453521940012, 'negative_slope': 0.2558408472456802, 'dropout_rate': 0.1997735240645564}. Best is trial 44 with value: 0.4004204892966361.\n",
      "[I 2023-12-22 18:57:12,397] Trial 48 finished with value: 0.39105504587155965 and parameters: {'learning_rate': 0.25190969920898004, 'negative_slope': 0.2722029923928741, 'dropout_rate': 0.1711866899974584}. Best is trial 44 with value: 0.4004204892966361.\n",
      "[I 2023-12-22 18:57:32,018] Trial 49 finished with value: 0.39468654434250766 and parameters: {'learning_rate': 0.18418350672743827, 'negative_slope': 0.23306737766262733, 'dropout_rate': 0.18546882651465596}. Best is trial 44 with value: 0.4004204892966361.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.1706362683105582, 'negative_slope': 0.2717541465247187, 'dropout_rate': 0.20659160596227932}\n",
      "Best Accuracy: 0.4004204892966361\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.MultiMarginLoss()\n",
    "\n",
    "input_dim = 161\n",
    "hidden_dim = 10\n",
    "window_size = 3\n",
    "b_size = 85\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-2, 1, log=True)\n",
    "    negative_slope = trial.suggest_float('negative_slope', 0.01, 0.3)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b68132",
   "metadata": {
    "papermill": {
     "duration": 0.134329,
     "end_time": "2023-12-22T18:57:32.431379",
     "exception": false,
     "start_time": "2023-12-22T18:57:32.297050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "One trial with the results we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1cd7916a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T18:57:32.706250Z",
     "iopub.status.busy": "2023-12-22T18:57:32.705826Z",
     "iopub.status.idle": "2023-12-22T18:57:52.416024Z",
     "shell.execute_reply": "2023-12-22T18:57:52.415206Z"
    },
    "papermill": {
     "duration": 19.850726,
     "end_time": "2023-12-22T18:57:52.418325",
     "exception": false,
     "start_time": "2023-12-22T18:57:32.567599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39717\n",
      "Precision: 0.40147\n",
      "Recall: 0.39717\n",
      "F1 Score: 0.38793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "input_dim = 161\n",
    "hidden_dim = 10\n",
    "window_size = 3\n",
    "b_size = 85\n",
    "learning_rate = 0.021794863937645848\n",
    "negative_slope = 0.2996496033775225\n",
    "dropout_rate = 0.20289531425438015\n",
    "n_epochs=11\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "criterion=nn.MultiMarginLoss()\n",
    "model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "x_train = data['mean_embedding']\n",
    "x_val = valid['mean_embedding']\n",
    "y_val = valid['Sentiment']\n",
    "y_train = data['Sentiment']\n",
    "    \n",
    "x_train = np.vstack(x_train).astype(np.float32)\n",
    "x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "y_val = y_val.values\n",
    "y_train = y_train.values\n",
    "data_set = Data(x_train, y_train, input_dim)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model.forward(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "x_val_tensor = torch.from_numpy(x_val)\n",
    "z_val = model.forward(x_val_tensor)\n",
    "max_indexes = torch.argmax(z_val, dim=1)\n",
    "\n",
    "y_pred = max_indexes.numpy()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Precision: {precision:.5f}')\n",
    "print(f'Recall: {recall:.5f}')\n",
    "print(f'F1 Score: {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8204e9",
   "metadata": {
    "papermill": {
     "duration": 0.134743,
     "end_time": "2023-12-22T18:57:52.689924",
     "exception": false,
     "start_time": "2023-12-22T18:57:52.555181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I think we should try bigger embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e78ce3e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T18:57:52.967265Z",
     "iopub.status.busy": "2023-12-22T18:57:52.966811Z",
     "iopub.status.idle": "2023-12-22T19:16:12.006020Z",
     "shell.execute_reply": "2023-12-22T19:16:12.004916Z"
    },
    "papermill": {
     "duration": 1099.319309,
     "end_time": "2023-12-22T19:16:12.147771",
     "exception": false,
     "start_time": "2023-12-22T18:57:52.828462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 18:57:52,993] A new study created in memory with name: no-name-969505e4-bbaa-42bc-8ccb-a235e3adb60d\n",
      "[I 2023-12-22 18:58:15,834] Trial 0 finished with value: 0.39239296636085624 and parameters: {'input_dim': 500}. Best is trial 0 with value: 0.39239296636085624.\n",
      "[I 2023-12-22 18:58:41,339] Trial 1 finished with value: 0.39392201834862384 and parameters: {'input_dim': 961}. Best is trial 1 with value: 0.39392201834862384.\n",
      "[I 2023-12-22 18:59:06,153] Trial 2 finished with value: 0.3964067278287462 and parameters: {'input_dim': 786}. Best is trial 2 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 18:59:30,100] Trial 3 finished with value: 0.39506880733944955 and parameters: {'input_dim': 679}. Best is trial 2 with value: 0.3964067278287462.\n",
      "[I 2023-12-22 18:59:50,962] Trial 4 finished with value: 0.3985091743119266 and parameters: {'input_dim': 324}. Best is trial 4 with value: 0.3985091743119266.\n",
      "[I 2023-12-22 19:00:11,890] Trial 5 finished with value: 0.3929663608562691 and parameters: {'input_dim': 324}. Best is trial 4 with value: 0.3985091743119266.\n",
      "[I 2023-12-22 19:00:32,778] Trial 6 finished with value: 0.39908256880733944 and parameters: {'input_dim': 246}. Best is trial 6 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 19:00:58,868] Trial 7 finished with value: 0.3937308868501529 and parameters: {'input_dim': 893}. Best is trial 6 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 19:01:22,224] Trial 8 finished with value: 0.39506880733944955 and parameters: {'input_dim': 681}. Best is trial 6 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 19:01:47,247] Trial 9 finished with value: 0.3908639143730887 and parameters: {'input_dim': 767}. Best is trial 6 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 19:02:08,175] Trial 10 finished with value: 0.38876146788990823 and parameters: {'input_dim': 216}. Best is trial 6 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 19:02:30,496] Trial 11 finished with value: 0.39048165137614677 and parameters: {'input_dim': 434}. Best is trial 6 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 19:02:50,815] Trial 12 finished with value: 0.3927752293577982 and parameters: {'input_dim': 206}. Best is trial 6 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 19:03:12,938] Trial 13 finished with value: 0.39353975535168195 and parameters: {'input_dim': 373}. Best is trial 6 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 19:03:35,491] Trial 14 finished with value: 0.39201070336391436 and parameters: {'input_dim': 518}. Best is trial 6 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 19:03:56,921] Trial 15 finished with value: 0.3983180428134557 and parameters: {'input_dim': 313}. Best is trial 6 with value: 0.39908256880733944.\n",
      "[I 2023-12-22 19:04:18,206] Trial 16 finished with value: 0.40309633027522934 and parameters: {'input_dim': 276}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:04:41,151] Trial 17 finished with value: 0.39717125382262997 and parameters: {'input_dim': 552}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:05:02,630] Trial 18 finished with value: 0.3967889908256881 and parameters: {'input_dim': 416}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:05:23,345] Trial 19 finished with value: 0.3944954128440367 and parameters: {'input_dim': 235}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:05:44,399] Trial 20 finished with value: 0.3927752293577982 and parameters: {'input_dim': 271}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:06:05,844] Trial 21 finished with value: 0.3889525993883792 and parameters: {'input_dim': 369}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:06:26,597] Trial 22 finished with value: 0.38952599388379205 and parameters: {'input_dim': 300}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:06:49,096] Trial 23 finished with value: 0.39545107033639143 and parameters: {'input_dim': 446}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:07:10,413] Trial 24 finished with value: 0.39946483180428133 and parameters: {'input_dim': 355}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:07:32,148] Trial 25 finished with value: 0.39717125382262997 and parameters: {'input_dim': 271}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:07:54,247] Trial 26 finished with value: 0.3958333333333333 and parameters: {'input_dim': 393}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:08:17,380] Trial 27 finished with value: 0.39258409785932724 and parameters: {'input_dim': 586}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:08:39,586] Trial 28 finished with value: 0.39545107033639143 and parameters: {'input_dim': 480}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:09:00,666] Trial 29 finished with value: 0.39048165137614677 and parameters: {'input_dim': 355}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:09:21,785] Trial 30 finished with value: 0.3918195718654434 and parameters: {'input_dim': 270}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:09:43,369] Trial 31 finished with value: 0.3929663608562691 and parameters: {'input_dim': 338}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:10:04,419] Trial 32 finished with value: 0.38952599388379205 and parameters: {'input_dim': 250}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:10:26,958] Trial 33 finished with value: 0.39048165137614677 and parameters: {'input_dim': 483}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:10:47,426] Trial 34 finished with value: 0.3943042813455658 and parameters: {'input_dim': 298}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:11:09,793] Trial 35 finished with value: 0.3956422018348624 and parameters: {'input_dim': 399}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:11:30,677] Trial 36 finished with value: 0.39965596330275227 and parameters: {'input_dim': 202}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:11:51,108] Trial 37 finished with value: 0.3922018348623853 and parameters: {'input_dim': 205}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:12:15,417] Trial 38 finished with value: 0.38876146788990823 and parameters: {'input_dim': 670}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:12:41,352] Trial 39 finished with value: 0.38837920489296635 and parameters: {'input_dim': 944}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:13:01,318] Trial 40 finished with value: 0.3992737003058104 and parameters: {'input_dim': 200}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:13:22,529] Trial 41 finished with value: 0.3922018348623853 and parameters: {'input_dim': 246}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:13:42,524] Trial 42 finished with value: 0.3916284403669725 and parameters: {'input_dim': 203}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:14:02,814] Trial 43 finished with value: 0.39545107033639143 and parameters: {'input_dim': 288}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:14:23,938] Trial 44 finished with value: 0.39258409785932724 and parameters: {'input_dim': 245}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:14:44,908] Trial 45 finished with value: 0.39048165137614677 and parameters: {'input_dim': 327}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:15:05,103] Trial 46 finished with value: 0.38704128440366975 and parameters: {'input_dim': 201}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:15:30,230] Trial 47 finished with value: 0.3937308868501529 and parameters: {'input_dim': 814}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:15:50,543] Trial 48 finished with value: 0.3988914373088685 and parameters: {'input_dim': 237}. Best is trial 16 with value: 0.40309633027522934.\n",
      "[I 2023-12-22 19:16:11,999] Trial 49 finished with value: 0.39315749235474007 and parameters: {'input_dim': 342}. Best is trial 16 with value: 0.40309633027522934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'input_dim': 276}\n",
      "Best Accuracy: 0.40309633027522934\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "n_epochs=11\n",
    "criterion=nn.MultiMarginLoss()\n",
    "\n",
    "hidden_dim = 10\n",
    "window_size = 3\n",
    "b_size = 85\n",
    "learning_rate = 0.021794863937645848\n",
    "negative_slope = 0.2996496033775225\n",
    "dropout_rate = 0.20289531425438015\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "def objective(trial):\n",
    "    input_dim = trial.suggest_int('input_dim', 200, 1000)\n",
    "    model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Choose optimizer\n",
    "    \n",
    "    \n",
    "\n",
    "    word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "    \n",
    "    data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "    x_train = data['mean_embedding']\n",
    "    x_val = valid['mean_embedding']\n",
    "    y_val = valid['Sentiment']\n",
    "    y_train = data['Sentiment']\n",
    "    \n",
    "    x_train = np.vstack(x_train).astype(np.float32)\n",
    "    x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    y_val = y_val.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "\n",
    "    data_set = Data(x_train, y_train, input_dim)\n",
    "    trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "    x_val_tensor = torch.from_numpy(x_val)\n",
    "    z_val = model.forward(x_val_tensor)\n",
    "    max_indexes = torch.argmax(z_val, dim=1)\n",
    "    y_pred = max_indexes.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1612f37b",
   "metadata": {
    "papermill": {
     "duration": 0.137266,
     "end_time": "2023-12-22T19:16:12.426614",
     "exception": false,
     "start_time": "2023-12-22T19:16:12.289348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Indeed, that helped, our final model is this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f7890ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:16:12.705219Z",
     "iopub.status.busy": "2023-12-22T19:16:12.704792Z",
     "iopub.status.idle": "2023-12-22T19:16:34.433496Z",
     "shell.execute_reply": "2023-12-22T19:16:34.432228Z"
    },
    "papermill": {
     "duration": 21.870644,
     "end_time": "2023-12-22T19:16:34.435944",
     "exception": false,
     "start_time": "2023-12-22T19:16:12.565300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39144\n",
      "Precision: 0.39674\n",
      "Recall: 0.39144\n",
      "F1 Score: 0.38186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "input_dim = 337\n",
    "hidden_dim = 10\n",
    "window_size = 3\n",
    "b_size = 85\n",
    "learning_rate = 0.021794863937645848\n",
    "negative_slope = 0.2996496033775225\n",
    "dropout_rate = 0.20289531425438015\n",
    "n_epochs=11\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "criterion=nn.MultiMarginLoss()\n",
    "model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "x_train = data['mean_embedding']\n",
    "x_val = valid['mean_embedding']\n",
    "y_val = valid['Sentiment']\n",
    "y_train = data['Sentiment']\n",
    "    \n",
    "x_train = np.vstack(x_train).astype(np.float32)\n",
    "x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "y_val = y_val.values\n",
    "y_train = y_train.values\n",
    "data_set = Data(x_train, y_train, input_dim)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model.forward(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "x_val_tensor = torch.from_numpy(x_val)\n",
    "z_val = model.forward(x_val_tensor)\n",
    "max_indexes = torch.argmax(z_val, dim=1)\n",
    "\n",
    "y_pred = max_indexes.numpy()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Precision: {precision:.5f}')\n",
    "print(f'Recall: {recall:.5f}')\n",
    "print(f'F1 Score: {f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5ad5bb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:16:34.716931Z",
     "iopub.status.busy": "2023-12-22T19:16:34.716485Z",
     "iopub.status.idle": "2023-12-22T19:16:58.252039Z",
     "shell.execute_reply": "2023-12-22T19:16:58.250880Z"
    },
    "papermill": {
     "duration": 23.678552,
     "end_time": "2023-12-22T19:16:58.254453",
     "exception": false,
     "start_time": "2023-12-22T19:16:34.575901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39564\n",
      "Precision: 0.40411\n",
      "Recall: 0.39564\n",
      "F1 Score: 0.38211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "input_dim = 704\n",
    "hidden_dim = 10\n",
    "window_size = 3\n",
    "b_size = 85\n",
    "learning_rate = 0.021794863937645848\n",
    "negative_slope = 0.2996496033775225\n",
    "dropout_rate = 0.20289531425438015\n",
    "n_epochs=11\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "criterion=nn.MultiMarginLoss()\n",
    "model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "x_train = data['mean_embedding']\n",
    "x_val = valid['mean_embedding']\n",
    "y_val = valid['Sentiment']\n",
    "y_train = data['Sentiment']\n",
    "    \n",
    "x_train = np.vstack(x_train).astype(np.float32)\n",
    "x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "y_val = y_val.values\n",
    "y_train = y_train.values\n",
    "data_set = Data(x_train, y_train, input_dim)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model.forward(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "x_val_tensor = torch.from_numpy(x_val)\n",
    "z_val = model.forward(x_val_tensor)\n",
    "max_indexes = torch.argmax(z_val, dim=1)\n",
    "\n",
    "y_pred = max_indexes.numpy()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Precision: {precision:.5f}')\n",
    "print(f'Recall: {recall:.5f}')\n",
    "print(f'F1 Score: {f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33daebf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:16:58.533747Z",
     "iopub.status.busy": "2023-12-22T19:16:58.532938Z",
     "iopub.status.idle": "2023-12-22T19:17:18.092742Z",
     "shell.execute_reply": "2023-12-22T19:17:18.091609Z"
    },
    "papermill": {
     "duration": 19.702288,
     "end_time": "2023-12-22T19:17:18.095104",
     "exception": false,
     "start_time": "2023-12-22T19:16:58.392816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39717\n",
      "Precision: 0.40781\n",
      "Recall: 0.39717\n",
      "F1 Score: 0.38181\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "input_dim = 161\n",
    "hidden_dim = 10\n",
    "window_size = 3\n",
    "b_size = 85\n",
    "learning_rate = 0.021794863937645848\n",
    "negative_slope = 0.2996496033775225\n",
    "dropout_rate = 0.20289531425438015\n",
    "n_epochs=11\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "criterion=nn.MultiMarginLoss()\n",
    "model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "x_train = data['mean_embedding']\n",
    "x_val = valid['mean_embedding']\n",
    "y_val = valid['Sentiment']\n",
    "y_train = data['Sentiment']\n",
    "    \n",
    "x_train = np.vstack(x_train).astype(np.float32)\n",
    "x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "y_val = y_val.values\n",
    "y_train = y_train.values\n",
    "data_set = Data(x_train, y_train, input_dim)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model.forward(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "x_val_tensor = torch.from_numpy(x_val)\n",
    "z_val = model.forward(x_val_tensor)\n",
    "max_indexes = torch.argmax(z_val, dim=1)\n",
    "\n",
    "y_pred = max_indexes.numpy()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Precision: {precision:.5f}')\n",
    "print(f'Recall: {recall:.5f}')\n",
    "print(f'F1 Score: {f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718556fa",
   "metadata": {
    "papermill": {
     "duration": 0.137641,
     "end_time": "2023-12-22T19:17:18.372748",
     "exception": false,
     "start_time": "2023-12-22T19:17:18.235107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The problem with evaluating our models is randomization : many steps include randomization like initialization of weights, ths SGD optimizer we are using, data shuffling in data loaderm dropout in layers, word2vec creation..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db86a12",
   "metadata": {
    "papermill": {
     "duration": 0.136762,
     "end_time": "2023-12-22T19:17:18.647218",
     "exception": false,
     "start_time": "2023-12-22T19:17:18.510456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So it is kinda difficult to decide the best parameters, but with some random restarts I used I came up with thse parameters and im not changing them anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219dae68",
   "metadata": {
    "papermill": {
     "duration": 0.137482,
     "end_time": "2023-12-22T19:17:18.922107",
     "exception": false,
     "start_time": "2023-12-22T19:17:18.784625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As input dim above I used two result I got from two different optuna studies for input dim (337, 704,161), best, or at least the one im keeping, is 704"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f577ef1",
   "metadata": {
    "papermill": {
     "duration": 0.138384,
     "end_time": "2023-12-22T19:17:19.312386",
     "exception": false,
     "start_time": "2023-12-22T19:17:19.174002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Last try with bigger hidden layer and window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "110c51d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:17:19.604397Z",
     "iopub.status.busy": "2023-12-22T19:17:19.603607Z",
     "iopub.status.idle": "2023-12-22T19:17:44.797348Z",
     "shell.execute_reply": "2023-12-22T19:17:44.796221Z"
    },
    "papermill": {
     "duration": 25.349717,
     "end_time": "2023-12-22T19:17:44.799844",
     "exception": false,
     "start_time": "2023-12-22T19:17:19.450127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39258\n",
      "Precision: 0.39744\n",
      "Recall: 0.39258\n",
      "F1 Score: 0.38210\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from collections.abc import Mapping\n",
    "from torch.nn import functional as F\n",
    "input_dim = 704\n",
    "hidden_dim = 45\n",
    "window_size = 6\n",
    "b_size = 85\n",
    "learning_rate = 0.021794863937645848\n",
    "negative_slope = 0.2996496033775225\n",
    "dropout_rate = 0.20289531425438015\n",
    "n_epochs=11\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "criterion=nn.MultiMarginLoss()\n",
    "model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "x_train = data['mean_embedding']\n",
    "x_val = valid['mean_embedding']\n",
    "y_val = valid['Sentiment']\n",
    "y_train = data['Sentiment']\n",
    "    \n",
    "x_train = np.vstack(x_train).astype(np.float32)\n",
    "x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "y_val = y_val.values\n",
    "y_train = y_train.values\n",
    "data_set = Data(x_train, y_train, input_dim)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "   \n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model.forward(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "x_val_tensor = torch.from_numpy(x_val)\n",
    "z_val = model.forward(x_val_tensor)\n",
    "max_indexes = torch.argmax(z_val, dim=1)\n",
    "\n",
    "y_pred = max_indexes.numpy()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Precision: {precision:.5f}')\n",
    "print(f'Recall: {recall:.5f}')\n",
    "print(f'F1 Score: {f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9aa398d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:17:45.078869Z",
     "iopub.status.busy": "2023-12-22T19:17:45.078468Z",
     "iopub.status.idle": "2023-12-22T19:18:00.077674Z",
     "shell.execute_reply": "2023-12-22T19:18:00.076506Z"
    },
    "papermill": {
     "duration": 15.14251,
     "end_time": "2023-12-22T19:18:00.080730",
     "exception": false,
     "start_time": "2023-12-22T19:17:44.938220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "input_dim = 704\n",
    "hidden_dim = 10\n",
    "window_size = 3\n",
    "b_size = 85\n",
    "learning_rate = 0.021794863937645848\n",
    "negative_slope = 0.2996496033775225\n",
    "dropout_rate = 0.20289531425438015\n",
    "criterion=nn.MultiMarginLoss()\n",
    "model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "num_cores = multiprocessing.cpu_count()\n",
    "word2vec_model = Word2Vec(sentences=data['tokenized_text'].tolist(), vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "data['mean_embedding'] = data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "valid['mean_embedding'] = valid['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654ab54",
   "metadata": {
    "papermill": {
     "duration": 0.138777,
     "end_time": "2023-12-22T19:18:00.358992",
     "exception": false,
     "start_time": "2023-12-22T19:18:00.220215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will now try to improve the training phase, we will increase number of epochs but implement early stopping as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7259632",
   "metadata": {
    "papermill": {
     "duration": 0.140003,
     "end_time": "2023-12-22T19:18:00.637938",
     "exception": false,
     "start_time": "2023-12-22T19:18:00.497935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Also we will use a learning rate scheduler to change the value of learning rate during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc131d",
   "metadata": {
    "papermill": {
     "duration": 0.13932,
     "end_time": "2023-12-22T19:18:00.916250",
     "exception": false,
     "start_time": "2023-12-22T19:18:00.776930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Additionally i am creating a validaiton loader as well to evaluate the model even better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f229446",
   "metadata": {
    "papermill": {
     "duration": 0.140006,
     "end_time": "2023-12-22T19:18:01.194719",
     "exception": false,
     "start_time": "2023-12-22T19:18:01.054713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we plot the learning curve and also use early stopping to find a good number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27df17ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:18:01.477392Z",
     "iopub.status.busy": "2023-12-22T19:18:01.476645Z",
     "iopub.status.idle": "2023-12-22T19:18:56.184281Z",
     "shell.execute_reply": "2023-12-22T19:18:56.183017Z"
    },
    "papermill": {
     "duration": 54.853707,
     "end_time": "2023-12-22T19:18:56.187085",
     "exception": false,
     "start_time": "2023-12-22T19:18:01.333378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 53\n",
      "Accuracy: 0.39564\n",
      "Precision: 0.40246\n",
      "Recall: 0.39564\n",
      "F1 Score: 0.38626\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Early stopping parameters\n",
    "x_train = data['mean_embedding']\n",
    "x_val = valid['mean_embedding']\n",
    "y_val = valid['Sentiment']\n",
    "y_train = data['Sentiment']\n",
    "    \n",
    "x_train = np.vstack(x_train).astype(np.float32)\n",
    "x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "y_val = y_val.values\n",
    "y_train = y_train.values\n",
    "    \n",
    "\n",
    "data_set = Data(x_train, y_train, input_dim)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "val_dataset = Data(x_val, y_val, input_dim)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=b_size, shuffle=True)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "n_epochs = 300\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    for x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model(x)  # Forward pass\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        # Gradient clipping (optional, choose max_norm value appropriately)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        \n",
    "    train_loss /= len(trainloader)\n",
    "    train_loss_list.append(train_loss)\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for x_val_batch, y_val_batch in val_loader:\n",
    "            z_val = model(x_val_batch)\n",
    "            val_loss += criterion(z_val, y_val_batch).item()\n",
    "\n",
    "\n",
    "    # Early stopping check\n",
    "    val_loss /= len(val_loader)\n",
    "    val_loss_list.append(val_loss)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    scheduler.step()  # Adjust learning rate\n",
    "\n",
    "# Final model evaluation\n",
    "x_val_tensor = torch.from_numpy(x_val)\n",
    "z_val = model(x_val_tensor)\n",
    "max_indexes = torch.argmax(z_val, dim=1)\n",
    "y_pred = max_indexes.numpy()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Precision: {precision:.5f}')\n",
    "print(f'Recall: {recall:.5f}')\n",
    "print(f'F1 Score: {f1:.5f}')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss_list, label='Training Loss')\n",
    "plt.plot(val_loss_list, label='Validation Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fe0955",
   "metadata": {
    "papermill": {
     "duration": 0.140985,
     "end_time": "2023-12-22T19:18:56.469299",
     "exception": false,
     "start_time": "2023-12-22T19:18:56.328314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17962e1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:18:56.754991Z",
     "iopub.status.busy": "2023-12-22T19:18:56.754541Z",
     "iopub.status.idle": "2023-12-22T19:19:24.225990Z",
     "shell.execute_reply": "2023-12-22T19:19:24.224969Z"
    },
    "papermill": {
     "duration": 27.616442,
     "end_time": "2023-12-22T19:19:24.228643",
     "exception": false,
     "start_time": "2023-12-22T19:18:56.612201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 26\n",
      "Accuracy: 0.39774\n",
      "Precision: 0.40407\n",
      "Recall: 0.39774\n",
      "F1 Score: 0.38879\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Early stopping parameters\n",
    "x_train = data['mean_embedding']\n",
    "x_val = valid['mean_embedding']\n",
    "y_val = valid['Sentiment']\n",
    "y_train = data['Sentiment']\n",
    "    \n",
    "x_train = np.vstack(x_train).astype(np.float32)\n",
    "x_val = np.vstack(x_val).astype(np.float32)\n",
    "    \n",
    "    \n",
    "y_val = y_val.values\n",
    "y_train = y_train.values\n",
    "    \n",
    "\n",
    "data_set = Data(x_train, y_train, input_dim)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "val_dataset = Data(x_val, y_val, input_dim)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=b_size, shuffle=True)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "n_epochs = 300\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    for x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model(x)  # Forward pass\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        # Gradient clipping (optional, choose max_norm value appropriately)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        \n",
    "    train_loss /= len(trainloader)\n",
    "    train_loss_list.append(train_loss)\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for x_val_batch, y_val_batch in val_loader:\n",
    "            z_val = model(x_val_batch)\n",
    "            val_loss += criterion(z_val, y_val_batch).item()\n",
    "\n",
    "\n",
    "    # Early stopping check\n",
    "    val_loss /= len(val_loader)\n",
    "    val_loss_list.append(val_loss)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    scheduler.step()  # Adjust learning rate\n",
    "\n",
    "# Final model evaluation\n",
    "x_val_tensor = torch.from_numpy(x_val)\n",
    "z_val = model(x_val_tensor)\n",
    "max_indexes = torch.argmax(z_val, dim=1)\n",
    "y_pred = max_indexes.numpy()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Precision: {precision:.5f}')\n",
    "print(f'Recall: {recall:.5f}')\n",
    "print(f'F1 Score: {f1:.5f}')\n",
    "\n",
    "\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "probabilities = softmax(z_val)\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize the labels\n",
    "y_val_binarized = label_binarize(y_val, classes=np.unique(y_val))\n",
    "n_classes = y_val_binarized.shape[1]\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_val_binarized[:, i], probabilities.detach().numpy()[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110fc0c",
   "metadata": {
    "papermill": {
     "duration": 0.142793,
     "end_time": "2023-12-22T19:19:24.514750",
     "exception": false,
     "start_time": "2023-12-22T19:19:24.371957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For the ROC curves I converted them to binary form so True Positive Rate equal to 1 is the ideal while 0.5 is random guessing. We see that the scores are close to random guessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb02d96",
   "metadata": {
    "papermill": {
     "duration": 0.143398,
     "end_time": "2023-12-22T19:19:24.800785",
     "exception": false,
     "start_time": "2023-12-22T19:19:24.657387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Cnfusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "845ac38f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:19:25.088003Z",
     "iopub.status.busy": "2023-12-22T19:19:25.087568Z",
     "iopub.status.idle": "2023-12-22T19:19:25.676487Z",
     "shell.execute_reply": "2023-12-22T19:19:25.675376Z"
    },
    "papermill": {
     "duration": 0.735521,
     "end_time": "2023-12-22T19:19:25.678955",
     "exception": false,
     "start_time": "2023-12-22T19:19:24.943434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using Seaborn\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_val), yticklabels=np.unique(y_val))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b6dd2",
   "metadata": {
    "papermill": {
     "duration": 0.143044,
     "end_time": "2023-12-22T19:19:25.964728",
     "exception": false,
     "start_time": "2023-12-22T19:19:25.821684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ok we now proceed with calcualting the output, first of all we load the test set and pre-process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ccc0420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:19:26.254158Z",
     "iopub.status.busy": "2023-12-22T19:19:26.253742Z",
     "iopub.status.idle": "2023-12-22T19:19:32.484651Z",
     "shell.execute_reply": "2023-12-22T19:19:32.483550Z"
    },
    "papermill": {
     "duration": 6.378333,
     "end_time": "2023-12-22T19:19:32.487083",
     "exception": false,
     "start_time": "2023-12-22T19:19:26.108750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   New_ID                                               Text   Party\n",
      "0       1  κυριακ μητσοτακ ξερ εινα μουσει βεργιν μεσω χρ...      ND\n",
      "1       2  συνεντευξ υποψηφι βουλευτ τ νε δημοκρατι βορει...      ND\n",
      "2       3  αυτ τ εκλογ μαθητ φοιτητ ψηφιζουμ τ ιδι τροπ α...     KKE\n",
      "3       4  γεννηματα : κιναλ θ γιν δεκανικ κανενοσ . ενδι...   PASOK\n",
      "4       5  κυριακ εκλογων , οκτωβρ 1993 , ξημερωμ δευτερα...      ND\n",
      "5       6   @ rounick28 @ yanisvaroufakis γιανν εινα σαν ...    DIEM\n",
      "6       7      τσιπρ τελειωνε ! θελ να πα να μαγειρεψ # σκαι  SYRIZA\n",
      "7       8  αποδημ κατα τσιπρ δικαιωμ ψηφου : « ητ δικαι κ...  SYRIZA\n",
      "8       9  μητσοτακ realfm ελληνικο : ακατανοητ εκδοσ κοι...      ND\n",
      "9      10  βουλωσ κοσιωνη . αφησ τ να τελειωσ προταση . α...  SYRIZA\n"
     ]
    }
   ],
   "source": [
    "test_path = \"/kaggle/input/ys19-2023-assignment-2/test_set.csv\"\n",
    "test = pd.read_csv(test_path)\n",
    "test['Text'] = test['Text'].apply(lambda x: x.lower())\n",
    "greek_stopwords = [\n",
    "    'και', 'το', 'η', 'της', 'του', 'τα', 'σε', 'με', 'για', 'ειναι',\n",
    "    'στο', 'απο', 'που', 'οι', 'την', 'ενα', 'μετα', 'εχει', 'δεν',\n",
    "    'ειναι', 'μια', 'αυτο', 'εναν', 'αλλα', 'ο', 'μη', 'οτι', 'πως',\n",
    "    'απο', 'στην', 'στον', 'τι', 'αυτη', 'των', 'αυτα', 'οταν', 'πολυ',\n",
    "    'μας', 'ειναι', 'πριν', 'οτι', 'μονο', 'αυτος', 'τοτε', 'μεταξυ',\n",
    "    'πολλα', 'οποτε', 'παρα', 'εαν', 'γυρω', 'αυτην', 'εκεινος', 'περισσοτερο',\n",
    "    'προς', 'πολυ', 'τελικα', 'ολοι'\n",
    "]\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()  # Split the text into words\n",
    "    words = [word for word in words if word.lower() not in greek_stopwords]\n",
    "    return ' '.join(words)\n",
    "test['Text'] = test['Text'].apply(remove_stopwords)\n",
    "url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "def remove_urls(text):\n",
    "    return re.sub(url_pattern, '', text)\n",
    "test['Text'] = test['Text'].apply(remove_urls)\n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub('ό', 'ο', x))  \n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub('έ', 'ε', x))  \n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub('ί', 'ι', x))  \n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub('ή', 'η', x))  \n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub('ύ', 'υ', x))  \n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub('ώ', 'ω', x))  \n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub('ά', 'α', x))  \n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub('ς', 'σ', x))  \n",
    "\n",
    "from greek_stemmer import stemmer\n",
    "\n",
    "# Define a function to perform stemming on the tweets\n",
    "def stem_greek_text(text):\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem_word(word,\"NNN\") for word in words]\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "    return stemmed_text\n",
    "\n",
    "\n",
    "# Apply the stem_greek_text function to the 'tweets' column\n",
    "test['Text'] = test['Text'].apply(stem_greek_text)\n",
    "test['Text'] = test['Text'].apply(lambda x: x.lower())\n",
    "test['Text'] = test['Text'].str.replace('ς', 'σ')\n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub(r'[^A-Za-zΑ-Ωα-ω0-9 ]', lambda y: ' ' + y.group(0) + ' ', x))\n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "print(test.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e1f65",
   "metadata": {
    "papermill": {
     "duration": 0.14257,
     "end_time": "2023-12-22T19:19:32.774461",
     "exception": false,
     "start_time": "2023-12-22T19:19:32.631891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "create the model by concatenating valdiation and train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db6a7738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:19:33.063701Z",
     "iopub.status.busy": "2023-12-22T19:19:33.063075Z",
     "iopub.status.idle": "2023-12-22T19:19:44.930210Z",
     "shell.execute_reply": "2023-12-22T19:19:44.928938Z"
    },
    "papermill": {
     "duration": 12.015371,
     "end_time": "2023-12-22T19:19:44.932989",
     "exception": false,
     "start_time": "2023-12-22T19:19:32.917618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, x, y, input_dim):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.len = self.x.shape[0]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index, :self.input_dim], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, negative_slope=0.01, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.bn1 = nn.BatchNorm1d(H)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Using LeakyReLU instead of ReLU\n",
    "        x = F.leaky_relu(self.bn1(self.linear1(x)), self.negative_slope)  # default slope is 0.01\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "input_dim = 161\n",
    "hidden_dim = 10\n",
    "window_size = 3\n",
    "b_size = 85\n",
    "learning_rate = 0.021794863937645848\n",
    "negative_slope = 0.2996496033775225\n",
    "dropout_rate = 0.20289531425438015\n",
    "criterion=nn.MultiMarginLoss()\n",
    "model = Net(input_dim, hidden_dim, output_dim, negative_slope=negative_slope, dropout_rate=dropout_rate)\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "num_cores = multiprocessing.cpu_count()\n",
    "all_sentences = data['tokenized_text'].tolist() + valid['tokenized_text'].tolist()\n",
    "combined_data = pd.concat([data, valid]).reset_index(drop=True)\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=all_sentences, vector_size=input_dim, window=window_size, min_count=1, workers=num_cores)\n",
    "combined_data['mean_embedding'] = combined_data['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c2cd9fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:19:45.220599Z",
     "iopub.status.busy": "2023-12-22T19:19:45.220129Z",
     "iopub.status.idle": "2023-12-22T19:19:51.280220Z",
     "shell.execute_reply": "2023-12-22T19:19:51.279069Z"
    },
    "papermill": {
     "duration": 6.205425,
     "end_time": "2023-12-22T19:19:51.282900",
     "exception": false,
     "start_time": "2023-12-22T19:19:45.077475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Party</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>mean_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>κυριακ μητσοτακ ξερ εινα μουσει βεργιν μεσω χρ...</td>\n",
       "      <td>ND</td>\n",
       "      <td>[κυριακ, μητσοτακ, ξερ, εινα, μουσει, βεργιν, ...</td>\n",
       "      <td>[0.019847427, 0.28127038, -0.04799003, 0.71826...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>συνεντευξ υποψηφι βουλευτ τ νε δημοκρατι βορει...</td>\n",
       "      <td>ND</td>\n",
       "      <td>[συνεντευξ, υποψηφι, βουλευτ, τ, νε, δημοκρατι...</td>\n",
       "      <td>[0.12289075, 1.0646344, 0.21053067, 0.58882856...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>αυτ τ εκλογ μαθητ φοιτητ ψηφιζουμ τ ιδι τροπ α...</td>\n",
       "      <td>KKE</td>\n",
       "      <td>[αυτ, τ, εκλογ, μαθητ, φοιτητ, ψηφιζουμ, τ, ιδ...</td>\n",
       "      <td>[0.4198154, 1.2252374, -0.029565567, 0.3218158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>γεννηματα : κιναλ θ γιν δεκανικ κανενοσ . ενδι...</td>\n",
       "      <td>PASOK</td>\n",
       "      <td>[γεννηματα, :, κιναλ, θ, γιν, δεκανικ, κανενοσ...</td>\n",
       "      <td>[0.10063398, 0.83261377, -0.22353573, 0.447583...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>κυριακ εκλογων , οκτωβρ 1993 , ξημερωμ δευτερα...</td>\n",
       "      <td>ND</td>\n",
       "      <td>[κυριακ, εκλογων, ,, οκτωβρ, 1993, ,, ξημερωμ,...</td>\n",
       "      <td>[0.21022655, 1.0172827, -0.20325536, 0.3264842...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   New_ID                                               Text  Party  \\\n",
       "0       1  κυριακ μητσοτακ ξερ εινα μουσει βεργιν μεσω χρ...     ND   \n",
       "1       2  συνεντευξ υποψηφι βουλευτ τ νε δημοκρατι βορει...     ND   \n",
       "2       3  αυτ τ εκλογ μαθητ φοιτητ ψηφιζουμ τ ιδι τροπ α...    KKE   \n",
       "3       4  γεννηματα : κιναλ θ γιν δεκανικ κανενοσ . ενδι...  PASOK   \n",
       "4       5  κυριακ εκλογων , οκτωβρ 1993 , ξημερωμ δευτερα...     ND   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [κυριακ, μητσοτακ, ξερ, εινα, μουσει, βεργιν, ...   \n",
       "1  [συνεντευξ, υποψηφι, βουλευτ, τ, νε, δημοκρατι...   \n",
       "2  [αυτ, τ, εκλογ, μαθητ, φοιτητ, ψηφιζουμ, τ, ιδ...   \n",
       "3  [γεννηματα, :, κιναλ, θ, γιν, δεκανικ, κανενοσ...   \n",
       "4  [κυριακ, εκλογων, ,, οκτωβρ, 1993, ,, ξημερωμ,...   \n",
       "\n",
       "                                      mean_embedding  \n",
       "0  [0.019847427, 0.28127038, -0.04799003, 0.71826...  \n",
       "1  [0.12289075, 1.0646344, 0.21053067, 0.58882856...  \n",
       "2  [0.4198154, 1.2252374, -0.029565567, 0.3218158...  \n",
       "3  [0.10063398, 0.83261377, -0.22353573, 0.447583...  \n",
       "4  [0.21022655, 1.0172827, -0.20325536, 0.3264842...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['tokenized_text'] = test['Text'].apply(word_tokenize)\n",
    "test['mean_embedding'] = test['tokenized_text'].apply(lambda tokens: np.mean([word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv], axis=0))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3b7224a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:19:51.571007Z",
     "iopub.status.busy": "2023-12-22T19:19:51.570249Z",
     "iopub.status.idle": "2023-12-22T19:20:35.448044Z",
     "shell.execute_reply": "2023-12-22T19:20:35.446964Z"
    },
    "papermill": {
     "duration": 44.024777,
     "end_time": "2023-12-22T19:20:35.450968",
     "exception": false,
     "start_time": "2023-12-22T19:19:51.426191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "x_train = combined_data['mean_embedding']\n",
    "y_train = combined_data['Sentiment']\n",
    "x_train = np.vstack(x_train).astype(np.float32)\n",
    "y_train = y_train.values\n",
    "data_set = Data(x_train, y_train, input_dim)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=b_size, shuffle=True)\n",
    "\n",
    "x_test = test['mean_embedding']\n",
    "x_test = np.vstack(x_test).astype(np.float32)\n",
    "n_epochs = 45\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model(x) \n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "x_test_tensor = torch.from_numpy(x_test)\n",
    "z_val = model(x_test_tensor)\n",
    "max_indexes = torch.argmax(z_val, dim=1)\n",
    "y_pred = max_indexes.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f0988a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:20:35.739939Z",
     "iopub.status.busy": "2023-12-22T19:20:35.738800Z",
     "iopub.status.idle": "2023-12-22T19:20:35.757828Z",
     "shell.execute_reply": "2023-12-22T19:20:35.756813Z"
    },
    "papermill": {
     "duration": 0.165267,
     "end_time": "2023-12-22T19:20:35.760179",
     "exception": false,
     "start_time": "2023-12-22T19:20:35.594912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10465</th>\n",
       "      <td>10466</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10466</th>\n",
       "      <td>10467</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10467</th>\n",
       "      <td>10468</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10468</th>\n",
       "      <td>10469</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10469</th>\n",
       "      <td>10470</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10470 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id Predicted\n",
       "0          1  NEGATIVE\n",
       "1          2  POSITIVE\n",
       "2          3  POSITIVE\n",
       "3          4  POSITIVE\n",
       "4          5  NEGATIVE\n",
       "...      ...       ...\n",
       "10465  10466  NEGATIVE\n",
       "10466  10467  NEGATIVE\n",
       "10467  10468  NEGATIVE\n",
       "10468  10469  NEGATIVE\n",
       "10469  10470  POSITIVE\n",
       "\n",
       "[10470 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {0: 'NEGATIVE', 1: 'NEUTRAL', 2: 'POSITIVE'}\n",
    "string_labels = [label_mapping[label] for label in y_pred]\n",
    "result_df = pd.DataFrame({ 'Id' : test['New_ID'],'Predicted': string_labels})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1137c826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T19:20:36.046223Z",
     "iopub.status.busy": "2023-12-22T19:20:36.045834Z",
     "iopub.status.idle": "2023-12-22T19:20:36.079292Z",
     "shell.execute_reply": "2023-12-22T19:20:36.078244Z"
    },
    "papermill": {
     "duration": 0.18053,
     "end_time": "2023-12-22T19:20:36.081938",
     "exception": false,
     "start_time": "2023-12-22T19:20:35.901408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7104041,
     "sourceId": 64789,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24703.075114,
   "end_time": "2023-12-22T19:20:38.212035",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-22T12:28:55.136921",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
